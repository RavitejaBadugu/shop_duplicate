{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:15.447996Z","iopub.status.busy":"2022-06-21T03:57:15.447422Z","iopub.status.idle":"2022-06-21T03:57:21.197901Z","shell.execute_reply":"2022-06-21T03:57:21.197161Z","shell.execute_reply.started":"2022-06-21T03:57:15.447906Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-21 03:57:16.281584: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n","2022-06-21 03:57:16.281739: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]}],"source":["import os\n","import math\n","import pandas as pd\n","from tqdm import tqdm\n","from kaggle_datasets import KaggleDatasets\n","import cv2\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import tensorflow.keras.backend as K"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:21.200077Z","iopub.status.busy":"2022-06-21T03:57:21.199703Z","iopub.status.idle":"2022-06-21T03:57:21.205372Z","shell.execute_reply":"2022-06-21T03:57:21.204434Z","shell.execute_reply.started":"2022-06-21T03:57:21.200033Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:21.207778Z","iopub.status.busy":"2022-06-21T03:57:21.207345Z","iopub.status.idle":"2022-06-21T03:57:27.185727Z","shell.execute_reply":"2022-06-21T03:57:27.184701Z","shell.execute_reply.started":"2022-06-21T03:57:21.207607Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on TPU  grpc://10.0.0.2:8470\n"]},{"name":"stderr","output_type":"stream","text":["2022-06-21 03:57:21.219286: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-06-21 03:57:21.222205: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n","2022-06-21 03:57:21.222235: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n","2022-06-21 03:57:21.222262: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0b1b96f83c6b): /proc/driver/nvidia/version does not exist\n","2022-06-21 03:57:21.224921: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-06-21 03:57:21.226380: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-06-21 03:57:21.230890: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-06-21 03:57:21.263164: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2022-06-21 03:57:21.263218: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30042}\n","2022-06-21 03:57:21.281244: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2022-06-21 03:57:21.281291: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30042}\n","2022-06-21 03:57:21.283160: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30042\n"]},{"name":"stdout","output_type":"stream","text":["REPLICAS:  8\n"]}],"source":["try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.187893Z","iopub.status.busy":"2022-06-21T03:57:27.187666Z","iopub.status.idle":"2022-06-21T03:57:27.192227Z","shell.execute_reply":"2022-06-21T03:57:27.191242Z","shell.execute_reply.started":"2022-06-21T03:57:27.187867Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE=32 * strategy.num_replicas_in_sync\n","IMAGE_SIZE=[512,512]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.193651Z","iopub.status.busy":"2022-06-21T03:57:27.193416Z","iopub.status.idle":"2022-06-21T03:57:27.203657Z","shell.execute_reply":"2022-06-21T03:57:27.202926Z","shell.execute_reply.started":"2022-06-21T03:57:27.193608Z"},"trusted":true},"outputs":[],"source":["def int_feature(int_list):\n","    if isinstance(int_list,type(tf.cast(1,dtype=tf.int32))):\n","        int_list=int_list.numpy()\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[int_list]))\n","\n","def bytes_feature(value):\n","    if isinstance(value,type(tf.cast(1,dtype=tf.float32))):\n","        value=value.numpy()\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.205205Z","iopub.status.busy":"2022-06-21T03:57:27.204993Z","iopub.status.idle":"2022-06-21T03:57:27.216744Z","shell.execute_reply":"2022-06-21T03:57:27.215962Z","shell.execute_reply.started":"2022-06-21T03:57:27.205181Z"},"trusted":true},"outputs":[],"source":["def Searlize_to_string(image_feature,label_feature):\n","    feature={\n","        \"image\":image_feature,\n","        \"label\":label_feature\n","    }\n","    example=tf.train.Example(features=tf.train.Features(feature=feature))\n","    return example.SerializeToString()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.218180Z","iopub.status.busy":"2022-06-21T03:57:27.217808Z","iopub.status.idle":"2022-06-21T03:57:27.227504Z","shell.execute_reply":"2022-06-21T03:57:27.226568Z","shell.execute_reply.started":"2022-06-21T03:57:27.218140Z"},"trusted":true},"outputs":[],"source":["#!python EDA.py --data_path train.csv --images_base_path train_images\n","#!python create_fold.py --data_path \"processed_data/cleaned_data.csv\""]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.228928Z","iopub.status.busy":"2022-06-21T03:57:27.228608Z","iopub.status.idle":"2022-06-21T03:57:27.488070Z","shell.execute_reply":"2022-06-21T03:57:27.487210Z","shell.execute_reply.started":"2022-06-21T03:57:27.228890Z"},"trusted":true},"outputs":[],"source":["df=pd.read_csv(\"../input/shop-tpu-folds/fold_data.csv\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.489499Z","iopub.status.busy":"2022-06-21T03:57:27.489233Z","iopub.status.idle":"2022-06-21T03:57:27.512804Z","shell.execute_reply":"2022-06-21T03:57:27.512033Z","shell.execute_reply.started":"2022-06-21T03:57:27.489471Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>posting_id</th>\n","      <th>image</th>\n","      <th>image_phash</th>\n","      <th>title</th>\n","      <th>label_group</th>\n","      <th>image_path</th>\n","      <th>gfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_129225211</td>\n","      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n","      <td>94974f937d4c2433</td>\n","      <td>Paper Bag Victoria Secret</td>\n","      <td>666</td>\n","      <td>train_images\\0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_3386243561</td>\n","      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n","      <td>af3f9460c2838f0f</td>\n","      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n","      <td>7572</td>\n","      <td>train_images\\00039780dfc94d01db8676fe789ecd05.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_2288590299</td>\n","      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n","      <td>b94cb00ed3e50f78</td>\n","      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n","      <td>6172</td>\n","      <td>train_images\\000a190fdd715a2a36faed16e2c65df7.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_2406599165</td>\n","      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n","      <td>8514fc58eafea283</td>\n","      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n","      <td>10509</td>\n","      <td>train_images\\00117e4fc239b1b641ff08340b429633.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_3369186413</td>\n","      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n","      <td>a6f319f924ad708c</td>\n","      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n","      <td>9425</td>\n","      <td>train_images\\00136d1cf4edede0203f32f05f660588.jpg</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         posting_id                                 image       image_phash  \\\n","0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n","1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n","2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n","3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n","4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n","\n","                                               title  label_group  \\\n","0                          Paper Bag Victoria Secret          666   \n","1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...         7572   \n","2        Maling TTS Canned Pork Luncheon Meat 397 gr         6172   \n","3  Daster Batik Lengan pendek - Motif Acak / Camp...        10509   \n","4                  Nescafe \\xc3\\x89clair Latte 220ml         9425   \n","\n","                                          image_path  gfold  \n","0  train_images\\0000a68812bc7e98c42888dfb1c07da0.jpg      0  \n","1  train_images\\00039780dfc94d01db8676fe789ecd05.jpg      2  \n","2  train_images\\000a190fdd715a2a36faed16e2c65df7.jpg      0  \n","3  train_images\\00117e4fc239b1b641ff08340b429633.jpg      1  \n","4  train_images\\00136d1cf4edede0203f32f05f660588.jpg      3  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.515662Z","iopub.status.busy":"2022-06-21T03:57:27.514866Z","iopub.status.idle":"2022-06-21T03:57:27.541103Z","shell.execute_reply":"2022-06-21T03:57:27.540421Z","shell.execute_reply.started":"2022-06-21T03:57:27.515629Z"},"trusted":true},"outputs":[],"source":["train_steps={}\n","valid_steps={}\n","for fold in range(5):\n","    valid_data=df.loc[df['gfold']==fold].reset_index(drop=True)\n","    valid_steps[fold]=valid_data.shape[0]\n","    train_steps[fold]=df.shape[0]-valid_data.shape[0]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.543555Z","iopub.status.busy":"2022-06-21T03:57:27.542548Z","iopub.status.idle":"2022-06-21T03:57:27.550752Z","shell.execute_reply":"2022-06-21T03:57:27.549837Z","shell.execute_reply.started":"2022-06-21T03:57:27.543509Z"},"trusted":true},"outputs":[{"data":{"text/plain":["({0: 27400, 1: 27400, 2: 27400, 3: 27400, 4: 27400},\n"," {0: 6850, 1: 6850, 2: 6850, 3: 6850, 4: 6850})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_steps,valid_steps"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.552124Z","iopub.status.busy":"2022-06-21T03:57:27.551905Z","iopub.status.idle":"2022-06-21T03:57:27.560644Z","shell.execute_reply":"2022-06-21T03:57:27.559671Z","shell.execute_reply.started":"2022-06-21T03:57:27.552098Z"},"trusted":true},"outputs":[],"source":["#import os\n","#os.mkdir(\"tfrecords\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.562351Z","iopub.status.busy":"2022-06-21T03:57:27.561760Z","iopub.status.idle":"2022-06-21T03:57:27.571682Z","shell.execute_reply":"2022-06-21T03:57:27.570797Z","shell.execute_reply.started":"2022-06-21T03:57:27.562292Z"},"trusted":true},"outputs":[],"source":["#for fold in tqdm(range(5)):\n","#    fold_data=df.loc[df['gfold']==fold].reset_index(drop=True)\n","#    with tf.io.TFRecordWriter(f\"tfrecords/fold_{fold}_512.tfrec\") as writer:\n","#        for i in fold_data.index:\n","#            img=tf.keras.preprocessing.image.load_img(fold_data.loc[i,'image_path'],target_size=IMAGE_SIZE)\n","#            img=tf.keras.preprocessing.image.img_to_array(img)\n","#            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tostring()\n","#            img_bytes_feature=bytes_feature(img)\n","#            label_feature=int_feature(int(fold_data.loc[i,'label_group']))\n","#            example_string=Searlize_to_string(img_bytes_feature,label_feature)\n","#            writer.write(example_string)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:27.572983Z","iopub.status.busy":"2022-06-21T03:57:27.572750Z","iopub.status.idle":"2022-06-21T03:57:28.110370Z","shell.execute_reply":"2022-06-21T03:57:28.109447Z","shell.execute_reply.started":"2022-06-21T03:57:27.572958Z"},"trusted":true},"outputs":[],"source":["GCS_PATH = KaggleDatasets().get_gcs_path('shop-512-size-tfrecords')"]},{"cell_type":"markdown","metadata":{},"source":["# DATA AUG"]},{"cell_type":"markdown","metadata":{},"source":["https://www.kaggle.com/code/cdeotte/rotation-augmentation-gpu-tpu-0-96/notebook"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:28.112334Z","iopub.status.busy":"2022-06-21T03:57:28.111874Z","iopub.status.idle":"2022-06-21T03:57:28.125155Z","shell.execute_reply":"2022-06-21T03:57:28.124283Z","shell.execute_reply.started":"2022-06-21T03:57:28.112264Z"},"trusted":true},"outputs":[],"source":["def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n","    # returns 3x3 transformmatrix which transforms indicies\n","        \n","    # CONVERT DEGREES TO RADIANS\n","    rotation = math.pi * rotation / 180.\n","    shear = math.pi * shear / 180.\n","    \n","    # ROTATION MATRIX\n","    c1 = tf.math.cos(rotation)\n","    s1 = tf.math.sin(rotation)\n","    one = tf.constant([1],dtype='float32')\n","    zero = tf.constant([0],dtype='float32')\n","    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n","        \n","    # SHEAR MATRIX\n","    c2 = tf.math.cos(shear)\n","    s2 = tf.math.sin(shear)\n","    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n","    \n","    # ZOOM MATRIX\n","    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n","    \n","    # SHIFT MATRIX\n","    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n","    \n","    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:28.126599Z","iopub.status.busy":"2022-06-21T03:57:28.126355Z","iopub.status.idle":"2022-06-21T03:57:28.144627Z","shell.execute_reply":"2022-06-21T03:57:28.143602Z","shell.execute_reply.started":"2022-06-21T03:57:28.126572Z"},"trusted":true},"outputs":[],"source":["def SHIFT_ROTATE_ZOOM(image,label):\n","    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n","    # output - image randomly rotated, sheared, zoomed, and shifted\n","    DIM = IMAGE_SIZE[0]\n","    XDIM = DIM%2 #fix for size 331\n","    \n","    rot = 15. * tf.random.normal([1],dtype='float32')\n","    shr = 5. * tf.random.normal([1],dtype='float32') \n","    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n","    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n","    h_shift = 16. * tf.random.normal([1],dtype='float32') \n","    w_shift = 16. * tf.random.normal([1],dtype='float32') \n","  \n","    # GET TRANSFORMATION MATRIX\n","    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n","\n","    # LIST DESTINATION PIXEL INDICES\n","    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n","    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n","    z = tf.ones([DIM*DIM],dtype='int32')\n","    idx = tf.stack( [x,y,z] )\n","    \n","    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n","    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n","    idx2 = K.cast(idx2,dtype='int32')\n","    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n","    \n","    # FIND ORIGIN PIXEL VALUES           \n","    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n","    d = tf.gather_nd(image,tf.transpose(idx3))\n","        \n","    return tf.reshape(d,[DIM,DIM,3]),label"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:57:28.146596Z","iopub.status.busy":"2022-06-21T03:57:28.146064Z","iopub.status.idle":"2022-06-21T03:57:28.160377Z","shell.execute_reply":"2022-06-21T03:57:28.159606Z","shell.execute_reply.started":"2022-06-21T03:57:28.146552Z"},"trusted":true},"outputs":[],"source":["def Desearlize(example):\n","    ex={\n","        \"image\":tf.io.FixedLenFeature([],dtype=tf.string),\n","        \"label\":tf.io.FixedLenFeature([],dtype=tf.int64)\n","    }\n","    features=tf.io.parse_single_example(example,ex)\n","    image,label=features['image'],features['label']\n","    label=tf.cast(label,dtype=tf.int32)\n","    image=tf.image.decode_jpeg(image,channels=3)\n","    image=tf.image.resize(image,IMAGE_SIZE)\n","    image=tf.cast(image,dtype=tf.float32)/255.0\n","    ex={\"image\":image,\"label\":label}\n","    return ex"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:58:33.053491Z","iopub.status.busy":"2022-06-21T03:58:33.052590Z","iopub.status.idle":"2022-06-21T03:58:33.059127Z","shell.execute_reply":"2022-06-21T03:58:33.058202Z","shell.execute_reply.started":"2022-06-21T03:58:33.053454Z"},"trusted":true},"outputs":[],"source":["def APPLY_AUG(example):\n","    image,label=example['image'],example['label']\n","    #image,label=SHIFT_ROTATE_ZOOM(image,label)\n","    image=tf.image.random_flip_left_right(image,)\n","    image=tf.image.random_brightness(image,0.2)\n","    image=tf.image.random_contrast(image,0.02,1)\n","    return image,label"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:58:34.041257Z","iopub.status.busy":"2022-06-21T03:58:34.040484Z","iopub.status.idle":"2022-06-21T03:58:34.046247Z","shell.execute_reply":"2022-06-21T03:58:34.045245Z","shell.execute_reply.started":"2022-06-21T03:58:34.041219Z"},"trusted":true},"outputs":[],"source":["def Train_input(image,label):\n","    return (image,label),label\n","def Valid_input(example):\n","    image,label=example['image'],example['label']\n","    return (image,label),label"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:58:34.706653Z","iopub.status.busy":"2022-06-21T03:58:34.705844Z","iopub.status.idle":"2022-06-21T03:58:34.719179Z","shell.execute_reply":"2022-06-21T03:58:34.718256Z","shell.execute_reply.started":"2022-06-21T03:58:34.706597Z"},"trusted":true},"outputs":[],"source":["def Valid_data_pipe(files):\n","    AUTO=tf.data.experimental.AUTOTUNE\n","    dataset = tf.data.TFRecordDataset(files, num_parallel_reads = AUTO)\n","    dataset=dataset.map(Desearlize,num_parallel_calls=AUTO)\n","    dataset=dataset.map(Valid_input,num_parallel_calls=AUTO)\n","    dataset=dataset.batch(BATCH_SIZE,drop_remainder=True)\n","    dataset=dataset.prefetch(AUTO)\n","    return dataset\n","\n","def Train_data_pipe(files):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False\n","    AUTO=tf.data.experimental.AUTOTUNE\n","    dataset = tf.data.TFRecordDataset(files, num_parallel_reads = AUTO )\n","    dataset=dataset.with_options(ignore_order)\n","    dataset=dataset.map(Desearlize,num_parallel_calls=AUTO)\n","    dataset=dataset.map(APPLY_AUG,num_parallel_calls=AUTO)\n","    dataset=dataset.map(Train_input,num_parallel_calls=AUTO)\n","    dataset = dataset.repeat()\n","    dataset=dataset.shuffle(1024)\n","    dataset=dataset.batch(BATCH_SIZE)\n","    dataset=dataset.prefetch(AUTO)\n","    return dataset"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:58:35.301556Z","iopub.status.busy":"2022-06-21T03:58:35.300754Z","iopub.status.idle":"2022-06-21T03:58:35.401960Z","shell.execute_reply":"2022-06-21T03:58:35.401274Z","shell.execute_reply.started":"2022-06-21T03:58:35.301503Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-21 03:58:35.310697: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"]}],"source":["files=tf.io.gfile.glob(f\"{GCS_PATH}/tfrecords/fold_*.tfrec\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:58:35.893522Z","iopub.status.busy":"2022-06-21T03:58:35.892770Z","iopub.status.idle":"2022-06-21T03:58:35.896974Z","shell.execute_reply":"2022-06-21T03:58:35.896297Z","shell.execute_reply.started":"2022-06-21T03:58:35.893481Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.applications import EfficientNetB5"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:58:36.766591Z","iopub.status.busy":"2022-06-21T03:58:36.766145Z","iopub.status.idle":"2022-06-21T03:58:36.779118Z","shell.execute_reply":"2022-06-21T03:58:36.778267Z","shell.execute_reply.started":"2022-06-21T03:58:36.766560Z"},"trusted":true},"outputs":[],"source":["class ARCFACE_LAYER(tf.keras.layers.Layer):\n","    def __init__(self,m=0.5,s=30,n_classes=11014):\n","        super(ARCFACE_LAYER,self).__init__()\n","        self.m=m\n","        self.s=s\n","        self.sin_m=tf.sin(m)\n","        self.cos_m=tf.cos(m)\n","        self.n_classes=n_classes\n","        self.threshold = tf.cos(math.pi - m)\n","        self.mm = tf.math.sin(math.pi - m) * m\n","\n","    def build(self,input_shape):\n","        prev_layer_units=input_shape[0][1]\n","        self.w=self.add_weight(shape=(prev_layer_units,self.n_classes),trainable=True,\n","                              initializer='glorot_uniform')\n","\n","    def get_config(self):\n","        config=super().get_config()\n","        config.update({\"m\":0.5,\n","                       \"s\":30,\n","                       \"n_classes\":11014})\n","        return config\n","\n","\n","    def call(self,inputs):\n","        prev_layer,y=inputs\n","        y=tf.cast(y,dtype=tf.int32)\n","        y_hot=tf.one_hot(y,self.n_classes)\n","        y_hot=tf.cast(y_hot,dtype=tf.float32)\n","        w_norm=tf.linalg.l2_normalize(self.w,axis=0)\n","        x_norm=tf.linalg.l2_normalize(prev_layer,axis=1)\n","        cos_theta=tf.linalg.matmul(x_norm,w_norm)\n","        sin_theta=tf.sqrt(1-tf.pow(cos_theta,tf.cast(2,dtype=tf.float32)))\n","        cos_theta_m=(cos_theta*self.cos_m)-(sin_theta*self.sin_m)\n","        cos_theta_m=tf.where(cos_theta>self.threshold,cos_theta_m,cos_theta-self.mm)\n","        final=self.s*((y_hot*cos_theta_m)+((1-y_hot)*cos_theta))\n","        return final"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:58:40.853921Z","iopub.status.busy":"2022-06-21T03:58:40.853650Z","iopub.status.idle":"2022-06-21T03:58:40.859859Z","shell.execute_reply":"2022-06-21T03:58:40.858976Z","shell.execute_reply.started":"2022-06-21T03:58:40.853895Z"},"trusted":true},"outputs":[],"source":["LR_START = 0.000005\n","LR_MAX   = 0.001#0.00005 * strategy.num_replicas_in_sync\n","LR_MIN   = 0.000005\n","LR_RAMPUP_EPOCHS = 5\n","LR_EXP_DECAY = .8\n","\n","def lrfn(epoch):\n","    if epoch < LR_RAMPUP_EPOCHS:\n","        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n","    elif epoch < LR_RAMPUP_EPOCHS:\n","        lr = LR_MAX\n","    else:\n","        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS) + LR_MIN\n","    return lr"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-06-21T03:58:44.957834Z","iopub.status.busy":"2022-06-21T03:58:44.957065Z","iopub.status.idle":"2022-06-21T11:43:07.185852Z","shell.execute_reply":"2022-06-21T11:43:07.183849Z","shell.execute_reply.started":"2022-06-21T03:58:44.957795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n","115269632/115263384 [==============================] - 1s 0us/step\n","training for fold 0\n","Epoch 1/40\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 5e-06.\n","107/107 [==============================] - 277s 1s/step - loss: 23.8726 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.8225 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00001: val_loss improved from inf to 23.82248, saving model to effb50.h5\n","Epoch 2/40\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.00020400000000000003.\n","107/107 [==============================] - 131s 1s/step - loss: 23.7551 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.4719 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00002: val_loss improved from 23.82248 to 23.47189, saving model to effb50.h5\n","Epoch 3/40\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.00040300000000000004.\n","107/107 [==============================] - 132s 1s/step - loss: 23.0785 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.2147 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00003: val_loss improved from 23.47189 to 23.21472, saving model to effb50.h5\n","Epoch 4/40\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0006020000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 21.2599 - sparse_categorical_accuracy: 6.2645e-04 - val_loss: 20.9529 - val_sparse_categorical_accuracy: 0.0036\n","\n","Epoch 00004: val_loss improved from 23.21472 to 20.95288, saving model to effb50.h5\n","Epoch 5/40\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 18.7016 - sparse_categorical_accuracy: 0.0092 - val_loss: 21.5986 - val_sparse_categorical_accuracy: 0.0017\n","\n","Epoch 00005: val_loss did not improve from 20.95288\n","Epoch 6/40\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","107/107 [==============================] - 131s 1s/step - loss: 15.9263 - sparse_categorical_accuracy: 0.0287 - val_loss: 24.4149 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00006: val_loss did not improve from 20.95288\n","Epoch 7/40\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 13.2237 - sparse_categorical_accuracy: 0.0664 - val_loss: 17.8544 - val_sparse_categorical_accuracy: 0.0150\n","\n","Epoch 00007: val_loss improved from 20.95288 to 17.85441, saving model to effb50.h5\n","Epoch 8/40\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0006418000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 11.2118 - sparse_categorical_accuracy: 0.1230 - val_loss: 13.0279 - val_sparse_categorical_accuracy: 0.1354\n","\n","Epoch 00008: val_loss improved from 17.85441 to 13.02791, saving model to effb50.h5\n","Epoch 9/40\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0005144400000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 9.7759 - sparse_categorical_accuracy: 0.1887 - val_loss: 11.9624 - val_sparse_categorical_accuracy: 0.1919\n","\n","Epoch 00009: val_loss improved from 13.02791 to 11.96239, saving model to effb50.h5\n","Epoch 10/40\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0004125520000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 8.8180 - sparse_categorical_accuracy: 0.2467 - val_loss: 12.4165 - val_sparse_categorical_accuracy: 0.1663\n","\n","Epoch 00010: val_loss did not improve from 11.96239\n","Epoch 11/40\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.0003310416000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 8.0756 - sparse_categorical_accuracy: 0.2997 - val_loss: 11.9528 - val_sparse_categorical_accuracy: 0.1852\n","\n","Epoch 00011: val_loss improved from 11.96239 to 11.95282, saving model to effb50.h5\n","Epoch 12/40\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.0002658332800000001.\n","107/107 [==============================] - 132s 1s/step - loss: 7.6121 - sparse_categorical_accuracy: 0.3356 - val_loss: 13.0349 - val_sparse_categorical_accuracy: 0.1103\n","\n","Epoch 00012: val_loss did not improve from 11.95282\n","Epoch 13/40\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.00021366662400000008.\n","107/107 [==============================] - 131s 1s/step - loss: 7.2540 - sparse_categorical_accuracy: 0.3631 - val_loss: 13.4161 - val_sparse_categorical_accuracy: 0.1074\n","\n","Epoch 00013: val_loss did not improve from 11.95282\n","Epoch 14/40\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.0001719332992000001.\n","107/107 [==============================] - 131s 1s/step - loss: 6.9243 - sparse_categorical_accuracy: 0.3957 - val_loss: 11.0080 - val_sparse_categorical_accuracy: 0.2569\n","\n","Epoch 00014: val_loss improved from 11.95282 to 11.00798, saving model to effb50.h5\n","Epoch 15/40\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.00013854663936000008.\n","107/107 [==============================] - 131s 1s/step - loss: 6.7350 - sparse_categorical_accuracy: 0.4125 - val_loss: 9.9828 - val_sparse_categorical_accuracy: 0.3377\n","\n","Epoch 00015: val_loss improved from 11.00798 to 9.98277, saving model to effb50.h5\n","Epoch 16/40\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.00011183731148800006.\n","107/107 [==============================] - 131s 1s/step - loss: 6.6530 - sparse_categorical_accuracy: 0.4307 - val_loss: 9.7921 - val_sparse_categorical_accuracy: 0.3585\n","\n","Epoch 00016: val_loss improved from 9.98277 to 9.79213, saving model to effb50.h5\n","Epoch 17/40\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 9.046984919040005e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.3600 - sparse_categorical_accuracy: 0.4484 - val_loss: 9.8810 - val_sparse_categorical_accuracy: 0.3498\n","\n","Epoch 00017: val_loss did not improve from 9.79213\n","Epoch 18/40\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 7.337587935232004e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.3963 - sparse_categorical_accuracy: 0.4527 - val_loss: 9.6481 - val_sparse_categorical_accuracy: 0.3699\n","\n","Epoch 00018: val_loss improved from 9.79213 to 9.64806, saving model to effb50.h5\n","Epoch 19/40\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 5.9700703481856035e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.1841 - sparse_categorical_accuracy: 0.4672 - val_loss: 9.6796 - val_sparse_categorical_accuracy: 0.3717\n","\n","Epoch 00019: val_loss did not improve from 9.64806\n","Epoch 20/40\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 4.8760562785484834e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.0628 - sparse_categorical_accuracy: 0.4704 - val_loss: 9.6253 - val_sparse_categorical_accuracy: 0.3756\n","\n","Epoch 00020: val_loss improved from 9.64806 to 9.62534, saving model to effb50.h5\n","Epoch 21/40\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 4.000845022838787e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.1467 - sparse_categorical_accuracy: 0.4815 - val_loss: 9.6074 - val_sparse_categorical_accuracy: 0.3764\n","\n","Epoch 00021: val_loss improved from 9.62534 to 9.60738, saving model to effb50.h5\n","Epoch 22/40\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 3.30067601827103e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9910 - sparse_categorical_accuracy: 0.4876 - val_loss: 9.5974 - val_sparse_categorical_accuracy: 0.3777\n","\n","Epoch 00022: val_loss improved from 9.60738 to 9.59740, saving model to effb50.h5\n","Epoch 23/40\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 2.740540814616824e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.9409 - sparse_categorical_accuracy: 0.4894 - val_loss: 9.4702 - val_sparse_categorical_accuracy: 0.3894\n","\n","Epoch 00023: val_loss improved from 9.59740 to 9.47016, saving model to effb50.h5\n","Epoch 24/40\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 2.2924326516934593e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9722 - sparse_categorical_accuracy: 0.4936 - val_loss: 9.4462 - val_sparse_categorical_accuracy: 0.3915\n","\n","Epoch 00024: val_loss improved from 9.47016 to 9.44623, saving model to effb50.h5\n","Epoch 25/40\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 1.9339461213547675e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9002 - sparse_categorical_accuracy: 0.4940 - val_loss: 9.4366 - val_sparse_categorical_accuracy: 0.3948\n","\n","Epoch 00025: val_loss improved from 9.44623 to 9.43656, saving model to effb50.h5\n","Epoch 26/40\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 1.647156897083814e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7926 - sparse_categorical_accuracy: 0.4990 - val_loss: 9.3957 - val_sparse_categorical_accuracy: 0.3977\n","\n","Epoch 00026: val_loss improved from 9.43656 to 9.39574, saving model to effb50.h5\n","Epoch 27/40\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 1.4177255176670514e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.8515 - sparse_categorical_accuracy: 0.5060 - val_loss: 9.3894 - val_sparse_categorical_accuracy: 0.3986\n","\n","Epoch 00027: val_loss improved from 9.39574 to 9.38937, saving model to effb50.h5\n","Epoch 28/40\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 1.234180414133641e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.8518 - sparse_categorical_accuracy: 0.5011 - val_loss: 9.3786 - val_sparse_categorical_accuracy: 0.3986\n","\n","Epoch 00028: val_loss improved from 9.38937 to 9.37856, saving model to effb50.h5\n","Epoch 29/40\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 1.087344331306913e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.8315 - sparse_categorical_accuracy: 0.5073 - val_loss: 9.3701 - val_sparse_categorical_accuracy: 0.4001\n","\n","Epoch 00029: val_loss improved from 9.37856 to 9.37011, saving model to effb50.h5\n","Epoch 30/40\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 9.698754650455303e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7940 - sparse_categorical_accuracy: 0.5013 - val_loss: 9.3692 - val_sparse_categorical_accuracy: 0.4013\n","\n","Epoch 00030: val_loss improved from 9.37011 to 9.36917, saving model to effb50.h5\n","Epoch 31/40\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 8.759003720364244e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7966 - sparse_categorical_accuracy: 0.5092 - val_loss: 9.3637 - val_sparse_categorical_accuracy: 0.4011\n","\n","Epoch 00031: val_loss improved from 9.36917 to 9.36375, saving model to effb50.h5\n","Epoch 32/40\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 8.007202976291395e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7338 - sparse_categorical_accuracy: 0.5115 - val_loss: 9.3532 - val_sparse_categorical_accuracy: 0.4023\n","\n","Epoch 00032: val_loss improved from 9.36375 to 9.35322, saving model to effb50.h5\n","Epoch 33/40\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 7.4057623810331166e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8540 - sparse_categorical_accuracy: 0.5051 - val_loss: 9.3544 - val_sparse_categorical_accuracy: 0.4031\n","\n","Epoch 00033: val_loss did not improve from 9.35322\n","Epoch 34/40\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 6.9246099048264925e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7432 - sparse_categorical_accuracy: 0.5142 - val_loss: 9.3464 - val_sparse_categorical_accuracy: 0.4034\n","\n","Epoch 00034: val_loss improved from 9.35322 to 9.34640, saving model to effb50.h5\n","Epoch 35/40\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 6.539687923861194e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7542 - sparse_categorical_accuracy: 0.5113 - val_loss: 9.3419 - val_sparse_categorical_accuracy: 0.4043\n","\n","Epoch 00035: val_loss improved from 9.34640 to 9.34188, saving model to effb50.h5\n","Epoch 36/40\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 6.231750339088956e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7877 - sparse_categorical_accuracy: 0.5088 - val_loss: 9.3348 - val_sparse_categorical_accuracy: 0.4049\n","\n","Epoch 00036: val_loss improved from 9.34188 to 9.33480, saving model to effb50.h5\n","Epoch 37/40\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 5.985400271271165e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.6859 - sparse_categorical_accuracy: 0.5188 - val_loss: 9.3302 - val_sparse_categorical_accuracy: 0.4049\n","\n","Epoch 00037: val_loss improved from 9.33480 to 9.33019, saving model to effb50.h5\n","Epoch 38/40\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 5.788320217016932e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.6445 - sparse_categorical_accuracy: 0.5186 - val_loss: 9.3309 - val_sparse_categorical_accuracy: 0.4064\n","\n","Epoch 00038: val_loss did not improve from 9.33019\n","Epoch 39/40\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 5.630656173613546e-06.\n","107/107 [==============================] - 134s 1s/step - loss: 5.8343 - sparse_categorical_accuracy: 0.5115 - val_loss: 9.3277 - val_sparse_categorical_accuracy: 0.4056\n","\n","Epoch 00039: val_loss improved from 9.33019 to 9.32774, saving model to effb50.h5\n","Epoch 40/40\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 5.5045249388908364e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.6900 - sparse_categorical_accuracy: 0.5178 - val_loss: 9.3241 - val_sparse_categorical_accuracy: 0.4059\n","\n","Epoch 00040: val_loss improved from 9.32774 to 9.32411, saving model to effb50.h5\n","model training for 0 is done\n","training for fold 1\n","Epoch 1/40\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 5e-06.\n","107/107 [==============================] - 278s 1s/step - loss: 23.8825 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.8337 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00001: val_loss improved from inf to 23.83374, saving model to effb51.h5\n","Epoch 2/40\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.00020400000000000003.\n","107/107 [==============================] - 131s 1s/step - loss: 23.7353 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.4020 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00002: val_loss improved from 23.83374 to 23.40196, saving model to effb51.h5\n","Epoch 3/40\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.00040300000000000004.\n","107/107 [==============================] - 131s 1s/step - loss: 23.0370 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.0761 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00003: val_loss improved from 23.40196 to 22.07607, saving model to effb51.h5\n","Epoch 4/40\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0006020000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 21.2776 - sparse_categorical_accuracy: 0.0013 - val_loss: 22.0253 - val_sparse_categorical_accuracy: 0.0021\n","\n","Epoch 00004: val_loss improved from 22.07607 to 22.02534, saving model to effb51.h5\n","Epoch 5/40\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 18.7497 - sparse_categorical_accuracy: 0.0111 - val_loss: 20.4077 - val_sparse_categorical_accuracy: 0.0077\n","\n","Epoch 00005: val_loss improved from 22.02534 to 20.40765, saving model to effb51.h5\n","Epoch 6/40\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","107/107 [==============================] - 132s 1s/step - loss: 16.0106 - sparse_categorical_accuracy: 0.0298 - val_loss: 20.9479 - val_sparse_categorical_accuracy: 0.0039\n","\n","Epoch 00006: val_loss did not improve from 20.40765\n","Epoch 7/40\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 13.2541 - sparse_categorical_accuracy: 0.0652 - val_loss: 16.3960 - val_sparse_categorical_accuracy: 0.0446\n","\n","Epoch 00007: val_loss improved from 20.40765 to 16.39602, saving model to effb51.h5\n","Epoch 8/40\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0006418000000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 11.1967 - sparse_categorical_accuracy: 0.1214 - val_loss: 14.1848 - val_sparse_categorical_accuracy: 0.0938\n","\n","Epoch 00008: val_loss improved from 16.39602 to 14.18476, saving model to effb51.h5\n","Epoch 9/40\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0005144400000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 9.7934 - sparse_categorical_accuracy: 0.1845 - val_loss: 15.8580 - val_sparse_categorical_accuracy: 0.0352\n","\n","Epoch 00009: val_loss did not improve from 14.18476\n","Epoch 10/40\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0004125520000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 8.9265 - sparse_categorical_accuracy: 0.2392 - val_loss: 14.8642 - val_sparse_categorical_accuracy: 0.0631\n","\n","Epoch 00010: val_loss did not improve from 14.18476\n","Epoch 11/40\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.0003310416000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 8.2016 - sparse_categorical_accuracy: 0.2887 - val_loss: 14.5234 - val_sparse_categorical_accuracy: 0.0712\n","\n","Epoch 00011: val_loss did not improve from 14.18476\n","Epoch 12/40\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.0002658332800000001.\n","107/107 [==============================] - 131s 1s/step - loss: 7.5216 - sparse_categorical_accuracy: 0.3349 - val_loss: 17.1800 - val_sparse_categorical_accuracy: 0.0219\n","\n","Epoch 00012: val_loss did not improve from 14.18476\n","Epoch 13/40\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.00021366662400000008.\n","107/107 [==============================] - 131s 1s/step - loss: 7.2971 - sparse_categorical_accuracy: 0.3615 - val_loss: 10.5335 - val_sparse_categorical_accuracy: 0.2940\n","\n","Epoch 00013: val_loss improved from 14.18476 to 10.53347, saving model to effb51.h5\n","Epoch 14/40\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.0001719332992000001.\n","107/107 [==============================] - 131s 1s/step - loss: 7.0685 - sparse_categorical_accuracy: 0.3921 - val_loss: 13.5681 - val_sparse_categorical_accuracy: 0.1041\n","\n","Epoch 00014: val_loss did not improve from 10.53347\n","Epoch 15/40\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.00013854663936000008.\n","107/107 [==============================] - 131s 1s/step - loss: 6.8848 - sparse_categorical_accuracy: 0.4030 - val_loss: 11.3031 - val_sparse_categorical_accuracy: 0.2324\n","\n","Epoch 00015: val_loss did not improve from 10.53347\n","Epoch 16/40\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.00011183731148800006.\n","107/107 [==============================] - 131s 1s/step - loss: 6.6021 - sparse_categorical_accuracy: 0.4280 - val_loss: 9.7360 - val_sparse_categorical_accuracy: 0.3666\n","\n","Epoch 00016: val_loss improved from 10.53347 to 9.73597, saving model to effb51.h5\n","Epoch 17/40\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 9.046984919040005e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.4309 - sparse_categorical_accuracy: 0.4475 - val_loss: 9.6665 - val_sparse_categorical_accuracy: 0.3726\n","\n","Epoch 00017: val_loss improved from 9.73597 to 9.66649, saving model to effb51.h5\n","Epoch 18/40\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 7.337587935232004e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.2545 - sparse_categorical_accuracy: 0.4601 - val_loss: 9.7627 - val_sparse_categorical_accuracy: 0.3664\n","\n","Epoch 00018: val_loss did not improve from 9.66649\n","Epoch 19/40\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 5.9700703481856035e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.3460 - sparse_categorical_accuracy: 0.4603 - val_loss: 9.5032 - val_sparse_categorical_accuracy: 0.3834\n","\n","Epoch 00019: val_loss improved from 9.66649 to 9.50317, saving model to effb51.h5\n","Epoch 20/40\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 4.8760562785484834e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.1774 - sparse_categorical_accuracy: 0.4694 - val_loss: 9.4656 - val_sparse_categorical_accuracy: 0.3887\n","\n","Epoch 00020: val_loss improved from 9.50317 to 9.46560, saving model to effb51.h5\n","Epoch 21/40\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 4.000845022838787e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.0385 - sparse_categorical_accuracy: 0.4792 - val_loss: 9.4537 - val_sparse_categorical_accuracy: 0.3891\n","\n","Epoch 00021: val_loss improved from 9.46560 to 9.45368, saving model to effb51.h5\n","Epoch 22/40\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 3.30067601827103e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.1206 - sparse_categorical_accuracy: 0.4775 - val_loss: 9.4092 - val_sparse_categorical_accuracy: 0.3918\n","\n","Epoch 00022: val_loss improved from 9.45368 to 9.40924, saving model to effb51.h5\n","Epoch 23/40\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 2.740540814616824e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9794 - sparse_categorical_accuracy: 0.4854 - val_loss: 9.3951 - val_sparse_categorical_accuracy: 0.3924\n","\n","Epoch 00023: val_loss improved from 9.40924 to 9.39514, saving model to effb51.h5\n","Epoch 24/40\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 2.2924326516934593e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.0008 - sparse_categorical_accuracy: 0.4913 - val_loss: 9.4162 - val_sparse_categorical_accuracy: 0.3930\n","\n","Epoch 00024: val_loss did not improve from 9.39514\n","Epoch 25/40\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 1.9339461213547675e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.8829 - sparse_categorical_accuracy: 0.4919 - val_loss: 9.3599 - val_sparse_categorical_accuracy: 0.3989\n","\n","Epoch 00025: val_loss improved from 9.39514 to 9.35987, saving model to effb51.h5\n","Epoch 26/40\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 1.647156897083814e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.9066 - sparse_categorical_accuracy: 0.4927 - val_loss: 9.3477 - val_sparse_categorical_accuracy: 0.3989\n","\n","Epoch 00026: val_loss improved from 9.35987 to 9.34770, saving model to effb51.h5\n","Epoch 27/40\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 1.4177255176670514e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8805 - sparse_categorical_accuracy: 0.4988 - val_loss: 9.3511 - val_sparse_categorical_accuracy: 0.3981\n","\n","Epoch 00027: val_loss did not improve from 9.34770\n","Epoch 28/40\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 1.234180414133641e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.9085 - sparse_categorical_accuracy: 0.4971 - val_loss: 9.3378 - val_sparse_categorical_accuracy: 0.4005\n","\n","Epoch 00028: val_loss improved from 9.34770 to 9.33780, saving model to effb51.h5\n","Epoch 29/40\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 1.087344331306913e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.8348 - sparse_categorical_accuracy: 0.5052 - val_loss: 9.3352 - val_sparse_categorical_accuracy: 0.4010\n","\n","Epoch 00029: val_loss improved from 9.33780 to 9.33521, saving model to effb51.h5\n","Epoch 30/40\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 9.698754650455303e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7373 - sparse_categorical_accuracy: 0.5069 - val_loss: 9.3206 - val_sparse_categorical_accuracy: 0.4040\n","\n","Epoch 00030: val_loss improved from 9.33521 to 9.32059, saving model to effb51.h5\n","Epoch 31/40\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 8.759003720364244e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7986 - sparse_categorical_accuracy: 0.5002 - val_loss: 9.3201 - val_sparse_categorical_accuracy: 0.4025\n","\n","Epoch 00031: val_loss improved from 9.32059 to 9.32011, saving model to effb51.h5\n","Epoch 32/40\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 8.007202976291395e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8987 - sparse_categorical_accuracy: 0.5029 - val_loss: 9.3102 - val_sparse_categorical_accuracy: 0.4035\n","\n","Epoch 00032: val_loss improved from 9.32011 to 9.31023, saving model to effb51.h5\n","Epoch 33/40\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 7.4057623810331166e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7183 - sparse_categorical_accuracy: 0.5081 - val_loss: 9.3115 - val_sparse_categorical_accuracy: 0.4040\n","\n","Epoch 00033: val_loss did not improve from 9.31023\n","Epoch 34/40\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 6.9246099048264925e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7714 - sparse_categorical_accuracy: 0.5104 - val_loss: 9.3112 - val_sparse_categorical_accuracy: 0.4041\n","\n","Epoch 00034: val_loss did not improve from 9.31023\n","Epoch 35/40\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 6.539687923861194e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7585 - sparse_categorical_accuracy: 0.5043 - val_loss: 9.3077 - val_sparse_categorical_accuracy: 0.4041\n","\n","Epoch 00035: val_loss improved from 9.31023 to 9.30774, saving model to effb51.h5\n","Epoch 36/40\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 6.231750339088956e-06.\n","107/107 [==============================] - 133s 1s/step - loss: 5.7915 - sparse_categorical_accuracy: 0.5092 - val_loss: 9.3021 - val_sparse_categorical_accuracy: 0.4052\n","\n","Epoch 00036: val_loss improved from 9.30774 to 9.30214, saving model to effb51.h5\n","Epoch 37/40\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 5.985400271271165e-06.\n","107/107 [==============================] - 133s 1s/step - loss: 5.7893 - sparse_categorical_accuracy: 0.5128 - val_loss: 9.3045 - val_sparse_categorical_accuracy: 0.4059\n","\n","Epoch 00037: val_loss did not improve from 9.30214\n","Epoch 38/40\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 5.788320217016932e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7884 - sparse_categorical_accuracy: 0.5115 - val_loss: 9.3005 - val_sparse_categorical_accuracy: 0.4056\n","\n","Epoch 00038: val_loss improved from 9.30214 to 9.30053, saving model to effb51.h5\n","Epoch 39/40\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 5.630656173613546e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7421 - sparse_categorical_accuracy: 0.5124 - val_loss: 9.2951 - val_sparse_categorical_accuracy: 0.4055\n","\n","Epoch 00039: val_loss improved from 9.30053 to 9.29508, saving model to effb51.h5\n","Epoch 40/40\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 5.5045249388908364e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.6587 - sparse_categorical_accuracy: 0.5162 - val_loss: 9.2932 - val_sparse_categorical_accuracy: 0.4066\n","\n","Epoch 00040: val_loss improved from 9.29508 to 9.29319, saving model to effb51.h5\n","model training for 1 is done\n","training for fold 2\n","Epoch 1/40\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 5e-06.\n","107/107 [==============================] - 285s 1s/step - loss: 23.8939 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.7767 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00001: val_loss improved from inf to 23.77666, saving model to effb52.h5\n","Epoch 2/40\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.00020400000000000003.\n","107/107 [==============================] - 132s 1s/step - loss: 23.7398 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.5273 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00002: val_loss improved from 23.77666 to 23.52729, saving model to effb52.h5\n","Epoch 3/40\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.00040300000000000004.\n","107/107 [==============================] - 132s 1s/step - loss: 23.0276 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.2379 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00003: val_loss improved from 23.52729 to 22.23787, saving model to effb52.h5\n","Epoch 4/40\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0006020000000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 21.2191 - sparse_categorical_accuracy: 5.7899e-04 - val_loss: 21.5734 - val_sparse_categorical_accuracy: 0.0029\n","\n","Epoch 00004: val_loss improved from 22.23787 to 21.57337, saving model to effb52.h5\n","Epoch 5/40\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 18.6118 - sparse_categorical_accuracy: 0.0115 - val_loss: 22.7055 - val_sparse_categorical_accuracy: 9.0144e-04\n","\n","Epoch 00005: val_loss did not improve from 21.57337\n","Epoch 6/40\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","107/107 [==============================] - 131s 1s/step - loss: 15.8160 - sparse_categorical_accuracy: 0.0338 - val_loss: 23.8606 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00006: val_loss did not improve from 21.57337\n","Epoch 7/40\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 13.0936 - sparse_categorical_accuracy: 0.0722 - val_loss: 25.3541 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00007: val_loss did not improve from 21.57337\n","Epoch 8/40\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0006418000000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 11.2442 - sparse_categorical_accuracy: 0.1268 - val_loss: 16.8608 - val_sparse_categorical_accuracy: 0.0206\n","\n","Epoch 00008: val_loss improved from 21.57337 to 16.86075, saving model to effb52.h5\n","Epoch 9/40\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0005144400000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 9.7046 - sparse_categorical_accuracy: 0.1941 - val_loss: 13.8906 - val_sparse_categorical_accuracy: 0.0996\n","\n","Epoch 00009: val_loss improved from 16.86075 to 13.89057, saving model to effb52.h5\n","Epoch 10/40\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0004125520000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 8.7572 - sparse_categorical_accuracy: 0.2526 - val_loss: 12.2494 - val_sparse_categorical_accuracy: 0.1767\n","\n","Epoch 00010: val_loss improved from 13.89057 to 12.24943, saving model to effb52.h5\n","Epoch 11/40\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.0003310416000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 7.9997 - sparse_categorical_accuracy: 0.3036 - val_loss: 10.9566 - val_sparse_categorical_accuracy: 0.2712\n","\n","Epoch 00011: val_loss improved from 12.24943 to 10.95663, saving model to effb52.h5\n","Epoch 12/40\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.0002658332800000001.\n","107/107 [==============================] - 131s 1s/step - loss: 7.5924 - sparse_categorical_accuracy: 0.3415 - val_loss: 10.5776 - val_sparse_categorical_accuracy: 0.2981\n","\n","Epoch 00012: val_loss improved from 10.95663 to 10.57763, saving model to effb52.h5\n","Epoch 13/40\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.00021366662400000008.\n","107/107 [==============================] - 131s 1s/step - loss: 7.1699 - sparse_categorical_accuracy: 0.3751 - val_loss: 11.6237 - val_sparse_categorical_accuracy: 0.2117\n","\n","Epoch 00013: val_loss did not improve from 10.57763\n","Epoch 14/40\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.0001719332992000001.\n","107/107 [==============================] - 132s 1s/step - loss: 6.8666 - sparse_categorical_accuracy: 0.3984 - val_loss: 10.4908 - val_sparse_categorical_accuracy: 0.3047\n","\n","Epoch 00014: val_loss improved from 10.57763 to 10.49080, saving model to effb52.h5\n","Epoch 15/40\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.00013854663936000008.\n","107/107 [==============================] - 132s 1s/step - loss: 6.6850 - sparse_categorical_accuracy: 0.4165 - val_loss: 9.8015 - val_sparse_categorical_accuracy: 0.3667\n","\n","Epoch 00015: val_loss improved from 10.49080 to 9.80149, saving model to effb52.h5\n","Epoch 16/40\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.00011183731148800006.\n","107/107 [==============================] - 132s 1s/step - loss: 6.4837 - sparse_categorical_accuracy: 0.4364 - val_loss: 9.7151 - val_sparse_categorical_accuracy: 0.3709\n","\n","Epoch 00016: val_loss improved from 9.80149 to 9.71510, saving model to effb52.h5\n","Epoch 17/40\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 9.046984919040005e-05.\n","107/107 [==============================] - 133s 1s/step - loss: 6.4102 - sparse_categorical_accuracy: 0.4492 - val_loss: 9.7873 - val_sparse_categorical_accuracy: 0.3657\n","\n","Epoch 00017: val_loss did not improve from 9.71510\n","Epoch 18/40\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 7.337587935232004e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.2932 - sparse_categorical_accuracy: 0.4553 - val_loss: 9.6717 - val_sparse_categorical_accuracy: 0.3794\n","\n","Epoch 00018: val_loss improved from 9.71510 to 9.67166, saving model to effb52.h5\n","Epoch 19/40\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 5.9700703481856035e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.0503 - sparse_categorical_accuracy: 0.4729 - val_loss: 9.5396 - val_sparse_categorical_accuracy: 0.3885\n","\n","Epoch 00019: val_loss improved from 9.67166 to 9.53963, saving model to effb52.h5\n","Epoch 20/40\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 4.8760562785484834e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.0671 - sparse_categorical_accuracy: 0.4836 - val_loss: 9.4982 - val_sparse_categorical_accuracy: 0.3909\n","\n","Epoch 00020: val_loss improved from 9.53963 to 9.49823, saving model to effb52.h5\n","Epoch 21/40\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 4.000845022838787e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.0588 - sparse_categorical_accuracy: 0.4874 - val_loss: 9.4667 - val_sparse_categorical_accuracy: 0.3935\n","\n","Epoch 00021: val_loss improved from 9.49823 to 9.46674, saving model to effb52.h5\n","Epoch 22/40\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 3.30067601827103e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9449 - sparse_categorical_accuracy: 0.4957 - val_loss: 9.4783 - val_sparse_categorical_accuracy: 0.3947\n","\n","Epoch 00022: val_loss did not improve from 9.46674\n","Epoch 23/40\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 2.740540814616824e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9397 - sparse_categorical_accuracy: 0.4957 - val_loss: 9.6082 - val_sparse_categorical_accuracy: 0.3812\n","\n","Epoch 00023: val_loss did not improve from 9.46674\n","Epoch 24/40\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 2.2924326516934593e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.9992 - sparse_categorical_accuracy: 0.4984 - val_loss: 9.3875 - val_sparse_categorical_accuracy: 0.4029\n","\n","Epoch 00024: val_loss improved from 9.46674 to 9.38753, saving model to effb52.h5\n","Epoch 25/40\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 1.9339461213547675e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8755 - sparse_categorical_accuracy: 0.5013 - val_loss: 9.3677 - val_sparse_categorical_accuracy: 0.4043\n","\n","Epoch 00025: val_loss improved from 9.38753 to 9.36769, saving model to effb52.h5\n","Epoch 26/40\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 1.647156897083814e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.8849 - sparse_categorical_accuracy: 0.5002 - val_loss: 9.3531 - val_sparse_categorical_accuracy: 0.4067\n","\n","Epoch 00026: val_loss improved from 9.36769 to 9.35314, saving model to effb52.h5\n","Epoch 27/40\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 1.4177255176670514e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9340 - sparse_categorical_accuracy: 0.5010 - val_loss: 9.3460 - val_sparse_categorical_accuracy: 0.4069\n","\n","Epoch 00027: val_loss improved from 9.35314 to 9.34604, saving model to effb52.h5\n","Epoch 28/40\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 1.234180414133641e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7927 - sparse_categorical_accuracy: 0.5078 - val_loss: 9.3627 - val_sparse_categorical_accuracy: 0.4072\n","\n","Epoch 00028: val_loss did not improve from 9.34604\n","Epoch 29/40\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 1.087344331306913e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8437 - sparse_categorical_accuracy: 0.5114 - val_loss: 9.3489 - val_sparse_categorical_accuracy: 0.4076\n","\n","Epoch 00029: val_loss did not improve from 9.34604\n","Epoch 30/40\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 9.698754650455303e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7396 - sparse_categorical_accuracy: 0.5175 - val_loss: 9.3230 - val_sparse_categorical_accuracy: 0.4096\n","\n","Epoch 00030: val_loss improved from 9.34604 to 9.32300, saving model to effb52.h5\n","Epoch 31/40\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 8.759003720364244e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7326 - sparse_categorical_accuracy: 0.5129 - val_loss: 9.3184 - val_sparse_categorical_accuracy: 0.4105\n","\n","Epoch 00031: val_loss improved from 9.32300 to 9.31843, saving model to effb52.h5\n","Epoch 32/40\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 8.007202976291395e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8201 - sparse_categorical_accuracy: 0.5139 - val_loss: 9.3135 - val_sparse_categorical_accuracy: 0.4106\n","\n","Epoch 00032: val_loss improved from 9.31843 to 9.31350, saving model to effb52.h5\n","Epoch 33/40\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 7.4057623810331166e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8046 - sparse_categorical_accuracy: 0.5115 - val_loss: 9.3130 - val_sparse_categorical_accuracy: 0.4099\n","\n","Epoch 00033: val_loss improved from 9.31350 to 9.31305, saving model to effb52.h5\n","Epoch 34/40\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 6.9246099048264925e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.6952 - sparse_categorical_accuracy: 0.5138 - val_loss: 9.3087 - val_sparse_categorical_accuracy: 0.4114\n","\n","Epoch 00034: val_loss improved from 9.31305 to 9.30867, saving model to effb52.h5\n","Epoch 35/40\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 6.539687923861194e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.6977 - sparse_categorical_accuracy: 0.5213 - val_loss: 9.3006 - val_sparse_categorical_accuracy: 0.4114\n","\n","Epoch 00035: val_loss improved from 9.30867 to 9.30061, saving model to effb52.h5\n","Epoch 36/40\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 6.231750339088956e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.6110 - sparse_categorical_accuracy: 0.5226 - val_loss: 9.2901 - val_sparse_categorical_accuracy: 0.4117\n","\n","Epoch 00036: val_loss improved from 9.30061 to 9.29009, saving model to effb52.h5\n","Epoch 37/40\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 5.985400271271165e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.5918 - sparse_categorical_accuracy: 0.5261 - val_loss: 9.2837 - val_sparse_categorical_accuracy: 0.4120\n","\n","Epoch 00037: val_loss improved from 9.29009 to 9.28366, saving model to effb52.h5\n","Epoch 38/40\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 5.788320217016932e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7170 - sparse_categorical_accuracy: 0.5202 - val_loss: 9.2897 - val_sparse_categorical_accuracy: 0.4117\n","\n","Epoch 00038: val_loss did not improve from 9.28366\n","Epoch 39/40\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 5.630656173613546e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.6032 - sparse_categorical_accuracy: 0.5197 - val_loss: 9.2828 - val_sparse_categorical_accuracy: 0.4130\n","\n","Epoch 00039: val_loss improved from 9.28366 to 9.28280, saving model to effb52.h5\n","Epoch 40/40\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 5.5045249388908364e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.5867 - sparse_categorical_accuracy: 0.5233 - val_loss: 9.2763 - val_sparse_categorical_accuracy: 0.4139\n","\n","Epoch 00040: val_loss improved from 9.28280 to 9.27635, saving model to effb52.h5\n","model training for 2 is done\n","training for fold 3\n","Epoch 1/40\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 5e-06.\n","107/107 [==============================] - 285s 1s/step - loss: 23.8790 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.7249 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00001: val_loss improved from inf to 23.72488, saving model to effb53.h5\n","Epoch 2/40\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.00020400000000000003.\n","107/107 [==============================] - 131s 1s/step - loss: 23.7417 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.5453 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00002: val_loss improved from 23.72488 to 23.54526, saving model to effb53.h5\n","Epoch 3/40\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.00040300000000000004.\n","107/107 [==============================] - 132s 1s/step - loss: 23.0184 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.3540 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00003: val_loss improved from 23.54526 to 22.35404, saving model to effb53.h5\n","Epoch 4/40\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0006020000000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 21.2412 - sparse_categorical_accuracy: 9.1811e-04 - val_loss: 21.3333 - val_sparse_categorical_accuracy: 0.0017\n","\n","Epoch 00004: val_loss improved from 22.35404 to 21.33333, saving model to effb53.h5\n","Epoch 5/40\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 18.6336 - sparse_categorical_accuracy: 0.0115 - val_loss: 19.8780 - val_sparse_categorical_accuracy: 0.0090\n","\n","Epoch 00005: val_loss improved from 21.33333 to 19.87804, saving model to effb53.h5\n","Epoch 6/40\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","107/107 [==============================] - 131s 1s/step - loss: 15.8387 - sparse_categorical_accuracy: 0.0344 - val_loss: 19.2697 - val_sparse_categorical_accuracy: 0.0105\n","\n","Epoch 00006: val_loss improved from 19.87804 to 19.26970, saving model to effb53.h5\n","Epoch 7/40\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 13.2318 - sparse_categorical_accuracy: 0.0713 - val_loss: 23.4634 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00007: val_loss did not improve from 19.26970\n","Epoch 8/40\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0006418000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 11.2449 - sparse_categorical_accuracy: 0.1295 - val_loss: 18.3453 - val_sparse_categorical_accuracy: 0.0122\n","\n","Epoch 00008: val_loss improved from 19.26970 to 18.34527, saving model to effb53.h5\n","Epoch 9/40\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0005144400000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 9.8288 - sparse_categorical_accuracy: 0.1908 - val_loss: 17.9443 - val_sparse_categorical_accuracy: 0.0153\n","\n","Epoch 00009: val_loss improved from 18.34527 to 17.94427, saving model to effb53.h5\n","Epoch 10/40\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0004125520000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 8.7663 - sparse_categorical_accuracy: 0.2442 - val_loss: 12.4785 - val_sparse_categorical_accuracy: 0.1698\n","\n","Epoch 00010: val_loss improved from 17.94427 to 12.47845, saving model to effb53.h5\n","Epoch 11/40\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.0003310416000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 8.0443 - sparse_categorical_accuracy: 0.3018 - val_loss: 13.8407 - val_sparse_categorical_accuracy: 0.1011\n","\n","Epoch 00011: val_loss did not improve from 12.47845\n","Epoch 12/40\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.0002658332800000001.\n","107/107 [==============================] - 131s 1s/step - loss: 7.6212 - sparse_categorical_accuracy: 0.3378 - val_loss: 16.8001 - val_sparse_categorical_accuracy: 0.0222\n","\n","Epoch 00012: val_loss did not improve from 12.47845\n","Epoch 13/40\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.00021366662400000008.\n","107/107 [==============================] - 132s 1s/step - loss: 7.1793 - sparse_categorical_accuracy: 0.3701 - val_loss: 16.7238 - val_sparse_categorical_accuracy: 0.0294\n","\n","Epoch 00013: val_loss did not improve from 12.47845\n","Epoch 14/40\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.0001719332992000001.\n","107/107 [==============================] - 132s 1s/step - loss: 6.8019 - sparse_categorical_accuracy: 0.4044 - val_loss: 13.0913 - val_sparse_categorical_accuracy: 0.1264\n","\n","Epoch 00014: val_loss did not improve from 12.47845\n","Epoch 15/40\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.00013854663936000008.\n","107/107 [==============================] - 132s 1s/step - loss: 6.6684 - sparse_categorical_accuracy: 0.4212 - val_loss: 14.3102 - val_sparse_categorical_accuracy: 0.0751\n","\n","Epoch 00015: val_loss did not improve from 12.47845\n","Epoch 16/40\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.00011183731148800006.\n","107/107 [==============================] - 132s 1s/step - loss: 6.4810 - sparse_categorical_accuracy: 0.4409 - val_loss: 10.2573 - val_sparse_categorical_accuracy: 0.3176\n","\n","Epoch 00016: val_loss improved from 12.47845 to 10.25732, saving model to effb53.h5\n","Epoch 17/40\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 9.046984919040005e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.3102 - sparse_categorical_accuracy: 0.4556 - val_loss: 10.7451 - val_sparse_categorical_accuracy: 0.2799\n","\n","Epoch 00017: val_loss did not improve from 10.25732\n","Epoch 18/40\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 7.337587935232004e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.2374 - sparse_categorical_accuracy: 0.4642 - val_loss: 9.5792 - val_sparse_categorical_accuracy: 0.3773\n","\n","Epoch 00018: val_loss improved from 10.25732 to 9.57917, saving model to effb53.h5\n","Epoch 19/40\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 5.9700703481856035e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.1403 - sparse_categorical_accuracy: 0.4751 - val_loss: 9.5513 - val_sparse_categorical_accuracy: 0.3803\n","\n","Epoch 00019: val_loss improved from 9.57917 to 9.55128, saving model to effb53.h5\n","Epoch 20/40\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 4.8760562785484834e-05.\n","107/107 [==============================] - 133s 1s/step - loss: 6.1100 - sparse_categorical_accuracy: 0.4801 - val_loss: 9.5157 - val_sparse_categorical_accuracy: 0.3867\n","\n","Epoch 00020: val_loss improved from 9.55128 to 9.51565, saving model to effb53.h5\n","Epoch 21/40\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 4.000845022838787e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9825 - sparse_categorical_accuracy: 0.4904 - val_loss: 9.4748 - val_sparse_categorical_accuracy: 0.3897\n","\n","Epoch 00021: val_loss improved from 9.51565 to 9.47476, saving model to effb53.h5\n","Epoch 22/40\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 3.30067601827103e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9642 - sparse_categorical_accuracy: 0.4920 - val_loss: 9.4394 - val_sparse_categorical_accuracy: 0.3906\n","\n","Epoch 00022: val_loss improved from 9.47476 to 9.43942, saving model to effb53.h5\n","Epoch 23/40\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 2.740540814616824e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9064 - sparse_categorical_accuracy: 0.4949 - val_loss: 9.3714 - val_sparse_categorical_accuracy: 0.3974\n","\n","Epoch 00023: val_loss improved from 9.43942 to 9.37141, saving model to effb53.h5\n","Epoch 24/40\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 2.2924326516934593e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8321 - sparse_categorical_accuracy: 0.5034 - val_loss: 9.3369 - val_sparse_categorical_accuracy: 0.4022\n","\n","Epoch 00024: val_loss improved from 9.37141 to 9.33692, saving model to effb53.h5\n","Epoch 25/40\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 1.9339461213547675e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.8646 - sparse_categorical_accuracy: 0.5049 - val_loss: 9.3248 - val_sparse_categorical_accuracy: 0.4022\n","\n","Epoch 00025: val_loss improved from 9.33692 to 9.32477, saving model to effb53.h5\n","Epoch 26/40\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 1.647156897083814e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.8637 - sparse_categorical_accuracy: 0.5029 - val_loss: 9.2927 - val_sparse_categorical_accuracy: 0.4052\n","\n","Epoch 00026: val_loss improved from 9.32477 to 9.29270, saving model to effb53.h5\n","Epoch 27/40\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 1.4177255176670514e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8068 - sparse_categorical_accuracy: 0.5102 - val_loss: 9.2785 - val_sparse_categorical_accuracy: 0.4069\n","\n","Epoch 00027: val_loss improved from 9.29270 to 9.27852, saving model to effb53.h5\n","Epoch 28/40\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 1.234180414133641e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8790 - sparse_categorical_accuracy: 0.5043 - val_loss: 9.2751 - val_sparse_categorical_accuracy: 0.4069\n","\n","Epoch 00028: val_loss improved from 9.27852 to 9.27507, saving model to effb53.h5\n","Epoch 29/40\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 1.087344331306913e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8697 - sparse_categorical_accuracy: 0.5111 - val_loss: 9.2558 - val_sparse_categorical_accuracy: 0.4096\n","\n","Epoch 00029: val_loss improved from 9.27507 to 9.25575, saving model to effb53.h5\n","Epoch 30/40\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 9.698754650455303e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7998 - sparse_categorical_accuracy: 0.5088 - val_loss: 9.2477 - val_sparse_categorical_accuracy: 0.4090\n","\n","Epoch 00030: val_loss improved from 9.25575 to 9.24766, saving model to effb53.h5\n","Epoch 31/40\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 8.759003720364244e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.6924 - sparse_categorical_accuracy: 0.5166 - val_loss: 9.2398 - val_sparse_categorical_accuracy: 0.4099\n","\n","Epoch 00031: val_loss improved from 9.24766 to 9.23985, saving model to effb53.h5\n","Epoch 32/40\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 8.007202976291395e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.6524 - sparse_categorical_accuracy: 0.5197 - val_loss: 9.2369 - val_sparse_categorical_accuracy: 0.4096\n","\n","Epoch 00032: val_loss improved from 9.23985 to 9.23690, saving model to effb53.h5\n","Epoch 33/40\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 7.4057623810331166e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7587 - sparse_categorical_accuracy: 0.5137 - val_loss: 9.2235 - val_sparse_categorical_accuracy: 0.4109\n","\n","Epoch 00033: val_loss improved from 9.23690 to 9.22349, saving model to effb53.h5\n","Epoch 34/40\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 6.9246099048264925e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.8563 - sparse_categorical_accuracy: 0.5098 - val_loss: 9.2160 - val_sparse_categorical_accuracy: 0.4120\n","\n","Epoch 00034: val_loss improved from 9.22349 to 9.21605, saving model to effb53.h5\n","Epoch 35/40\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 6.539687923861194e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7737 - sparse_categorical_accuracy: 0.5160 - val_loss: 9.2091 - val_sparse_categorical_accuracy: 0.4129\n","\n","Epoch 00035: val_loss improved from 9.21605 to 9.20908, saving model to effb53.h5\n","Epoch 36/40\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 6.231750339088956e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.6228 - sparse_categorical_accuracy: 0.5239 - val_loss: 9.2055 - val_sparse_categorical_accuracy: 0.4126\n","\n","Epoch 00036: val_loss improved from 9.20908 to 9.20545, saving model to effb53.h5\n","Epoch 37/40\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 5.985400271271165e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7561 - sparse_categorical_accuracy: 0.5169 - val_loss: 9.1983 - val_sparse_categorical_accuracy: 0.4138\n","\n","Epoch 00037: val_loss improved from 9.20545 to 9.19833, saving model to effb53.h5\n","Epoch 38/40\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 5.788320217016932e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7212 - sparse_categorical_accuracy: 0.5226 - val_loss: 9.1945 - val_sparse_categorical_accuracy: 0.4147\n","\n","Epoch 00038: val_loss improved from 9.19833 to 9.19454, saving model to effb53.h5\n","Epoch 39/40\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 5.630656173613546e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.6823 - sparse_categorical_accuracy: 0.5215 - val_loss: 9.1897 - val_sparse_categorical_accuracy: 0.4144\n","\n","Epoch 00039: val_loss improved from 9.19454 to 9.18965, saving model to effb53.h5\n","Epoch 40/40\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 5.5045249388908364e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.7000 - sparse_categorical_accuracy: 0.5196 - val_loss: 9.1874 - val_sparse_categorical_accuracy: 0.4144\n","\n","Epoch 00040: val_loss improved from 9.18965 to 9.18738, saving model to effb53.h5\n","model training for 3 is done\n","training for fold 4\n","Epoch 1/40\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 5e-06.\n","107/107 [==============================] - 285s 1s/step - loss: 23.8870 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.7719 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00001: val_loss improved from inf to 23.77194, saving model to effb54.h5\n","Epoch 2/40\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.00020400000000000003.\n","107/107 [==============================] - 132s 1s/step - loss: 23.7317 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.5602 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00002: val_loss improved from 23.77194 to 23.56015, saving model to effb54.h5\n","Epoch 3/40\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.00040300000000000004.\n","107/107 [==============================] - 132s 1s/step - loss: 23.0168 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.6660 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00003: val_loss improved from 23.56015 to 22.66603, saving model to effb54.h5\n","Epoch 4/40\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0006020000000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 21.3180 - sparse_categorical_accuracy: 7.2508e-04 - val_loss: 21.9221 - val_sparse_categorical_accuracy: 7.5120e-04\n","\n","Epoch 00004: val_loss improved from 22.66603 to 21.92213, saving model to effb54.h5\n","Epoch 5/40\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 18.9462 - sparse_categorical_accuracy: 0.0105 - val_loss: 19.4279 - val_sparse_categorical_accuracy: 0.0102\n","\n","Epoch 00005: val_loss improved from 21.92213 to 19.42792, saving model to effb54.h5\n","Epoch 6/40\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","107/107 [==============================] - 132s 1s/step - loss: 16.2530 - sparse_categorical_accuracy: 0.0302 - val_loss: 23.8954 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00006: val_loss did not improve from 19.42792\n","Epoch 7/40\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0008010000000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 13.4890 - sparse_categorical_accuracy: 0.0663 - val_loss: 18.3778 - val_sparse_categorical_accuracy: 0.0146\n","\n","Epoch 00007: val_loss improved from 19.42792 to 18.37779, saving model to effb54.h5\n","Epoch 8/40\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0006418000000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 11.3910 - sparse_categorical_accuracy: 0.1213 - val_loss: 25.9972 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00008: val_loss did not improve from 18.37779\n","Epoch 9/40\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0005144400000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 10.0021 - sparse_categorical_accuracy: 0.1813 - val_loss: 16.3143 - val_sparse_categorical_accuracy: 0.0341\n","\n","Epoch 00009: val_loss improved from 18.37779 to 16.31429, saving model to effb54.h5\n","Epoch 10/40\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0004125520000000001.\n","107/107 [==============================] - 131s 1s/step - loss: 8.8102 - sparse_categorical_accuracy: 0.2412 - val_loss: 12.7391 - val_sparse_categorical_accuracy: 0.1439\n","\n","Epoch 00010: val_loss improved from 16.31429 to 12.73913, saving model to effb54.h5\n","Epoch 11/40\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.0003310416000000001.\n","107/107 [==============================] - 132s 1s/step - loss: 8.1871 - sparse_categorical_accuracy: 0.2863 - val_loss: 12.1229 - val_sparse_categorical_accuracy: 0.1743\n","\n","Epoch 00011: val_loss improved from 12.73913 to 12.12288, saving model to effb54.h5\n","Epoch 12/40\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.0002658332800000001.\n","107/107 [==============================] - 131s 1s/step - loss: 7.6240 - sparse_categorical_accuracy: 0.3300 - val_loss: 18.0694 - val_sparse_categorical_accuracy: 0.0120\n","\n","Epoch 00012: val_loss did not improve from 12.12288\n","Epoch 13/40\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.00021366662400000008.\n","107/107 [==============================] - 132s 1s/step - loss: 7.2109 - sparse_categorical_accuracy: 0.3622 - val_loss: 11.1256 - val_sparse_categorical_accuracy: 0.2467\n","\n","Epoch 00013: val_loss improved from 12.12288 to 11.12563, saving model to effb54.h5\n","Epoch 14/40\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.0001719332992000001.\n","107/107 [==============================] - 132s 1s/step - loss: 6.9879 - sparse_categorical_accuracy: 0.3871 - val_loss: 11.1374 - val_sparse_categorical_accuracy: 0.2446\n","\n","Epoch 00014: val_loss did not improve from 11.12563\n","Epoch 15/40\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.00013854663936000008.\n","107/107 [==============================] - 132s 1s/step - loss: 6.8318 - sparse_categorical_accuracy: 0.4129 - val_loss: 10.3502 - val_sparse_categorical_accuracy: 0.3120\n","\n","Epoch 00015: val_loss improved from 11.12563 to 10.35019, saving model to effb54.h5\n","Epoch 16/40\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.00011183731148800006.\n","107/107 [==============================] - 131s 1s/step - loss: 6.6696 - sparse_categorical_accuracy: 0.4260 - val_loss: 10.0539 - val_sparse_categorical_accuracy: 0.3383\n","\n","Epoch 00016: val_loss improved from 10.35019 to 10.05395, saving model to effb54.h5\n","Epoch 17/40\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 9.046984919040005e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.4621 - sparse_categorical_accuracy: 0.4431 - val_loss: 10.0356 - val_sparse_categorical_accuracy: 0.3403\n","\n","Epoch 00017: val_loss improved from 10.05395 to 10.03562, saving model to effb54.h5\n","Epoch 18/40\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 7.337587935232004e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.3797 - sparse_categorical_accuracy: 0.4539 - val_loss: 9.8718 - val_sparse_categorical_accuracy: 0.3586\n","\n","Epoch 00018: val_loss improved from 10.03562 to 9.87183, saving model to effb54.h5\n","Epoch 19/40\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 5.9700703481856035e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.1986 - sparse_categorical_accuracy: 0.4600 - val_loss: 9.8378 - val_sparse_categorical_accuracy: 0.3615\n","\n","Epoch 00019: val_loss improved from 9.87183 to 9.83781, saving model to effb54.h5\n","Epoch 20/40\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 4.8760562785484834e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.0753 - sparse_categorical_accuracy: 0.4759 - val_loss: 9.7392 - val_sparse_categorical_accuracy: 0.3699\n","\n","Epoch 00020: val_loss improved from 9.83781 to 9.73919, saving model to effb54.h5\n","Epoch 21/40\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 4.000845022838787e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.1978 - sparse_categorical_accuracy: 0.4702 - val_loss: 9.7338 - val_sparse_categorical_accuracy: 0.3697\n","\n","Epoch 00021: val_loss improved from 9.73919 to 9.73382, saving model to effb54.h5\n","Epoch 22/40\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 3.30067601827103e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.1199 - sparse_categorical_accuracy: 0.4760 - val_loss: 9.7577 - val_sparse_categorical_accuracy: 0.3691\n","\n","Epoch 00022: val_loss did not improve from 9.73382\n","Epoch 23/40\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 2.740540814616824e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.0465 - sparse_categorical_accuracy: 0.4788 - val_loss: 9.6810 - val_sparse_categorical_accuracy: 0.3759\n","\n","Epoch 00023: val_loss improved from 9.73382 to 9.68104, saving model to effb54.h5\n","Epoch 24/40\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 2.2924326516934593e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 6.0301 - sparse_categorical_accuracy: 0.4849 - val_loss: 9.6204 - val_sparse_categorical_accuracy: 0.3818\n","\n","Epoch 00024: val_loss improved from 9.68104 to 9.62045, saving model to effb54.h5\n","Epoch 25/40\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 1.9339461213547675e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 6.0361 - sparse_categorical_accuracy: 0.4826 - val_loss: 9.6705 - val_sparse_categorical_accuracy: 0.3818\n","\n","Epoch 00025: val_loss did not improve from 9.62045\n","Epoch 26/40\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 1.647156897083814e-05.\n","107/107 [==============================] - 131s 1s/step - loss: 5.9687 - sparse_categorical_accuracy: 0.4927 - val_loss: 9.5748 - val_sparse_categorical_accuracy: 0.3885\n","\n","Epoch 00026: val_loss improved from 9.62045 to 9.57479, saving model to effb54.h5\n","Epoch 27/40\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 1.4177255176670514e-05.\n","107/107 [==============================] - 133s 1s/step - loss: 5.8921 - sparse_categorical_accuracy: 0.4955 - val_loss: 9.5760 - val_sparse_categorical_accuracy: 0.3881\n","\n","Epoch 00027: val_loss did not improve from 9.57479\n","Epoch 28/40\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 1.234180414133641e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8871 - sparse_categorical_accuracy: 0.4948 - val_loss: 9.5613 - val_sparse_categorical_accuracy: 0.3884\n","\n","Epoch 00028: val_loss improved from 9.57479 to 9.56133, saving model to effb54.h5\n","Epoch 29/40\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 1.087344331306913e-05.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9197 - sparse_categorical_accuracy: 0.4989 - val_loss: 9.5468 - val_sparse_categorical_accuracy: 0.3905\n","\n","Epoch 00029: val_loss improved from 9.56133 to 9.54685, saving model to effb54.h5\n","Epoch 30/40\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 9.698754650455303e-06.\n","107/107 [==============================] - 131s 1s/step - loss: 5.9342 - sparse_categorical_accuracy: 0.5009 - val_loss: 9.5382 - val_sparse_categorical_accuracy: 0.3918\n","\n","Epoch 00030: val_loss improved from 9.54685 to 9.53816, saving model to effb54.h5\n","Epoch 31/40\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 8.759003720364244e-06.\n","107/107 [==============================] - 133s 1s/step - loss: 5.8813 - sparse_categorical_accuracy: 0.5033 - val_loss: 9.5313 - val_sparse_categorical_accuracy: 0.3929\n","\n","Epoch 00031: val_loss improved from 9.53816 to 9.53126, saving model to effb54.h5\n","Epoch 32/40\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 8.007202976291395e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9705 - sparse_categorical_accuracy: 0.4959 - val_loss: 9.5285 - val_sparse_categorical_accuracy: 0.3923\n","\n","Epoch 00032: val_loss improved from 9.53126 to 9.52850, saving model to effb54.h5\n","Epoch 33/40\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 7.4057623810331166e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.9514 - sparse_categorical_accuracy: 0.4977 - val_loss: 9.5223 - val_sparse_categorical_accuracy: 0.3942\n","\n","Epoch 00033: val_loss improved from 9.52850 to 9.52232, saving model to effb54.h5\n","Epoch 34/40\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 6.9246099048264925e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8115 - sparse_categorical_accuracy: 0.5033 - val_loss: 9.5110 - val_sparse_categorical_accuracy: 0.3947\n","\n","Epoch 00034: val_loss improved from 9.52232 to 9.51103, saving model to effb54.h5\n","Epoch 35/40\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 6.539687923861194e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8002 - sparse_categorical_accuracy: 0.5078 - val_loss: 9.5039 - val_sparse_categorical_accuracy: 0.3951\n","\n","Epoch 00035: val_loss improved from 9.51103 to 9.50388, saving model to effb54.h5\n","Epoch 36/40\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 6.231750339088956e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8804 - sparse_categorical_accuracy: 0.5069 - val_loss: 9.4980 - val_sparse_categorical_accuracy: 0.3956\n","\n","Epoch 00036: val_loss improved from 9.50388 to 9.49804, saving model to effb54.h5\n","Epoch 37/40\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 5.985400271271165e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8246 - sparse_categorical_accuracy: 0.5104 - val_loss: 9.4954 - val_sparse_categorical_accuracy: 0.3959\n","\n","Epoch 00037: val_loss improved from 9.49804 to 9.49542, saving model to effb54.h5\n","Epoch 38/40\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 5.788320217016932e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.7145 - sparse_categorical_accuracy: 0.5104 - val_loss: 9.4848 - val_sparse_categorical_accuracy: 0.3956\n","\n","Epoch 00038: val_loss improved from 9.49542 to 9.48483, saving model to effb54.h5\n","Epoch 39/40\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 5.630656173613546e-06.\n","107/107 [==============================] - 132s 1s/step - loss: 5.8001 - sparse_categorical_accuracy: 0.5067 - val_loss: 9.4755 - val_sparse_categorical_accuracy: 0.3972\n","\n","Epoch 00039: val_loss improved from 9.48483 to 9.47552, saving model to effb54.h5\n","Epoch 40/40\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 5.5045249388908364e-06.\n","107/107 [==============================] - 133s 1s/step - loss: 5.7890 - sparse_categorical_accuracy: 0.5125 - val_loss: 9.4785 - val_sparse_categorical_accuracy: 0.3969\n","\n","Epoch 00040: val_loss did not improve from 9.47552\n","model training for 4 is done\n"]}],"source":["for fold in range(5):\n","    train_records=files[:fold]+files[fold+1:]\n","    test_records=files[fold]\n","    NUM_TRAIN_STEPS=train_steps[fold]//BATCH_SIZE\n","    NUM_VALID_STEPS=valid_steps[fold]//BATCH_SIZE\n","    tf.keras.backend.clear_session()\n","    with strategy.scope():\n","        pre_trained=EfficientNetB5(include_top=False,weights=\"imagenet\",input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n","        ins=tf.keras.layers.Input(())\n","        x=pre_trained.layers[-1].output\n","        x=tf.keras.layers.GlobalMaxPooling2D()(x)\n","        #x=tf.keras.layers.Dense(720)(x)\n","        arc_layer=ARCFACE_LAYER()\n","        x=arc_layer([x,ins])\n","        outs=tf.keras.layers.Softmax()(x)\n","        model=tf.keras.models.Model(inputs=(pre_trained.input,ins),outputs=outs)\n","        print(f\"training for fold {fold}\")\n","        #print(model.summary())\n","        model.compile(optimizer=tf.keras.optimizers.Adam(),\n","                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n","    lr_callback=tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch),verbose=1)\n","    early=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",mode=\"min\",verbose=1,patience=10)\n","    saver=tf.keras.callbacks.ModelCheckpoint(filepath=\"effb5\"+f\"{fold}.h5\",\n","                                     monitor=\"val_loss\",mode=\"min\",save_best_only=True,\n","                                     save_weights_only=True,verbose=1)\n","    train_dataloader=Train_data_pipe(train_records)\n","    valid_dataloader=Valid_data_pipe(test_records)\n","    model.fit(train_dataloader,\n","              validation_data=valid_dataloader,epochs=40,\n","              callbacks=[early,saver,lr_callback],steps_per_epoch=NUM_TRAIN_STEPS,\n","             validation_steps=NUM_VALID_STEPS)\n","    print(f\"model training for {fold} is done\")\n","    del model\n","    import gc\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Experiments 5 fold error\n","with dense\n","1) B0->1e-5 to 4e-4 -> 12.648266\n","   B0->1e-6 to 4e-5 -> \"very high error\"\n","   B0 ->1e-6 to 4e-4 -> 12.823738\n","without dense\n","1) B0->1e-5 to 4e-4 -> 13.708846\n","##################################################\n","(only 1 fold)\n","no dense\n","1) B0->1e-5 to 4e-4->13.8519\n","2) B0-> 1e-5 to 1e-3->11.1301\n","   B0-> 1e-6 to 1e-3->11.08619\n","With dense\n","1) B0->1e-5 to 4e-4-> 12.53761\n","2) B0-> 1e-5 to 1e-3->10.94927\n","   B0-> 1e-6 to 1e-3->10.72708(30 epochs)\n","###############################################\n","B3(dense)\n","1) B3 -> 1e-6 to 1e-3 -> 10.26380(50 epochs)\n","2) B3 -> 5e-6 to 1e-3 -> 10.11745(44 epochs)\n","B3(no dense)\n","5e-6 to 1e-3->10.06651(40 epochs)\n","1e-6 to 1e-3 -> 10.17261\n","1e-5 to 4e-4 -> 11.89102\n","#may be during training I observed that in b3 case dense layer is causing overfiitting at first.\n","##########################################\n","B5(no dense)\n","5e-6 to 1e-3 -> 9.59691\n","B5(no dense removed shift scale rotate)\n","5 fold error\n","5e-6 to 1e-3 ->9.31131"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
