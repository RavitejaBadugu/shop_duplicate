{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:12.010598Z","iopub.status.busy":"2022-06-29T13:52:12.010037Z","iopub.status.idle":"2022-06-29T13:52:18.637145Z","shell.execute_reply":"2022-06-29T13:52:18.636217Z","shell.execute_reply.started":"2022-06-29T13:52:12.010484Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-29 13:52:12.824955: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n","2022-06-29 13:52:12.825080: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from kaggle_datasets import KaggleDatasets\n","import tensorflow as tf\n","import math\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:18.639169Z","iopub.status.busy":"2022-06-29T13:52:18.638873Z","iopub.status.idle":"2022-06-29T13:52:24.688280Z","shell.execute_reply":"2022-06-29T13:52:24.687488Z","shell.execute_reply.started":"2022-06-29T13:52:18.639137Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on TPU  grpc://10.0.0.2:8470\n"]},{"name":"stderr","output_type":"stream","text":["2022-06-29 13:52:18.647531: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-06-29 13:52:18.650640: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n","2022-06-29 13:52:18.650679: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n","2022-06-29 13:52:18.650706: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d49ecccbca92): /proc/driver/nvidia/version does not exist\n","2022-06-29 13:52:18.655319: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-06-29 13:52:18.657154: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-06-29 13:52:18.695241: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2022-06-29 13:52:18.695329: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30043}\n","2022-06-29 13:52:18.715554: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2022-06-29 13:52:18.715610: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30043}\n","2022-06-29 13:52:18.717127: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30043\n"]},{"name":"stdout","output_type":"stream","text":["REPLICAS:  8\n"]}],"source":["try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:24.689877Z","iopub.status.busy":"2022-06-29T13:52:24.689623Z","iopub.status.idle":"2022-06-29T13:52:25.052941Z","shell.execute_reply":"2022-06-29T13:52:25.052173Z","shell.execute_reply.started":"2022-06-29T13:52:24.689840Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE=32 * strategy.num_replicas_in_sync\n","GCS_PATH=KaggleDatasets().get_gcs_path('shop-tpu-folds')\n","MAX_LENGTH=180\n","PRE_TRAINED_NAME=\"bert-base-uncased\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:31.463014Z","iopub.status.busy":"2022-06-29T13:52:31.462696Z","iopub.status.idle":"2022-06-29T13:52:41.385598Z","shell.execute_reply":"2022-06-29T13:52:41.384655Z","shell.execute_reply.started":"2022-06-29T13:52:31.462980Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>posting_id</th>\n","      <th>image</th>\n","      <th>image_phash</th>\n","      <th>title</th>\n","      <th>label_group</th>\n","      <th>image_path</th>\n","      <th>gfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_129225211</td>\n","      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n","      <td>94974f937d4c2433</td>\n","      <td>Paper Bag Victoria Secret</td>\n","      <td>666</td>\n","      <td>train_images\\0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_3386243561</td>\n","      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n","      <td>af3f9460c2838f0f</td>\n","      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n","      <td>7572</td>\n","      <td>train_images\\00039780dfc94d01db8676fe789ecd05.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_2288590299</td>\n","      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n","      <td>b94cb00ed3e50f78</td>\n","      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n","      <td>6172</td>\n","      <td>train_images\\000a190fdd715a2a36faed16e2c65df7.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_2406599165</td>\n","      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n","      <td>8514fc58eafea283</td>\n","      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n","      <td>10509</td>\n","      <td>train_images\\00117e4fc239b1b641ff08340b429633.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_3369186413</td>\n","      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n","      <td>a6f319f924ad708c</td>\n","      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n","      <td>9425</td>\n","      <td>train_images\\00136d1cf4edede0203f32f05f660588.jpg</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         posting_id                                 image       image_phash  \\\n","0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n","1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n","2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n","3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n","4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n","\n","                                               title  label_group  \\\n","0                          Paper Bag Victoria Secret          666   \n","1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...         7572   \n","2        Maling TTS Canned Pork Luncheon Meat 397 gr         6172   \n","3  Daster Batik Lengan pendek - Motif Acak / Camp...        10509   \n","4                  Nescafe \\xc3\\x89clair Latte 220ml         9425   \n","\n","                                          image_path  gfold  \n","0  train_images\\0000a68812bc7e98c42888dfb1c07da0.jpg      0  \n","1  train_images\\00039780dfc94d01db8676fe789ecd05.jpg      2  \n","2  train_images\\000a190fdd715a2a36faed16e2c65df7.jpg      0  \n","3  train_images\\00117e4fc239b1b641ff08340b429633.jpg      1  \n","4  train_images\\00136d1cf4edede0203f32f05f660588.jpg      3  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df=pd.read_csv(f\"{GCS_PATH}/fold_data.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:41.387337Z","iopub.status.busy":"2022-06-29T13:52:41.387106Z","iopub.status.idle":"2022-06-29T13:52:41.452213Z","shell.execute_reply":"2022-06-29T13:52:41.451145Z","shell.execute_reply.started":"2022-06-29T13:52:41.387312Z"},"trusted":true},"outputs":[{"data":{"text/plain":["({0: 107, 1: 107, 2: 107, 3: 107, 4: 107}, {0: 26, 1: 26, 2: 26, 3: 26, 4: 26})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_steps={}\n","valid_steps={}\n","for fold in range(5):\n","    train_steps[fold]=df.loc[df['gfold']!=fold].reset_index(drop=True).shape[0]//BATCH_SIZE\n","    valid_steps[fold]=df.loc[df['gfold']==fold].reset_index(drop=True).shape[0]//BATCH_SIZE\n","train_steps,valid_steps"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:41.453596Z","iopub.status.busy":"2022-06-29T13:52:41.453303Z","iopub.status.idle":"2022-06-29T13:52:41.924998Z","shell.execute_reply":"2022-06-29T13:52:41.924190Z","shell.execute_reply.started":"2022-06-29T13:52:41.453569Z"},"trusted":true},"outputs":[],"source":["from transformers import TFBertModel,TFRobertaModel\n","from transformers import BertTokenizer,RobertaTokenizer"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:41.927032Z","iopub.status.busy":"2022-06-29T13:52:41.926710Z","iopub.status.idle":"2022-06-29T13:52:43.683190Z","shell.execute_reply":"2022-06-29T13:52:43.682198Z","shell.execute_reply.started":"2022-06-29T13:52:41.927000Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de8637b4ac094dd1a09369ff33e922cf","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e7e7ac826d949e5af06fe39232c89b9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fdc2f17094fb4fe88a09d3b3399831f3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if PRE_TRAINED_NAME.startswith(\"bert\"):\n","    TOKENIZER= BertTokenizer.from_pretrained(PRE_TRAINED_NAME,do_lower_case=True)\n","else:\n","    TOKENIZER= RobertaTokenizer.from_pretrained(PRE_TRAINED_NAME,do_lower_case=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:43.684640Z","iopub.status.busy":"2022-06-29T13:52:43.684392Z","iopub.status.idle":"2022-06-29T13:52:43.689001Z","shell.execute_reply":"2022-06-29T13:52:43.688017Z","shell.execute_reply.started":"2022-06-29T13:52:43.684613Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Input,Dense\n","from tensorflow.keras.models import Model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:43.691079Z","iopub.status.busy":"2022-06-29T13:52:43.690633Z","iopub.status.idle":"2022-06-29T13:52:43.709569Z","shell.execute_reply":"2022-06-29T13:52:43.708642Z","shell.execute_reply.started":"2022-06-29T13:52:43.691036Z"},"trusted":true},"outputs":[],"source":["class ARCFACE_LAYER(tf.keras.layers.Layer):\n","    def __init__(self,m=0.5,s=30,n_classes=11014):\n","        super(ARCFACE_LAYER,self).__init__()\n","        self.m=m\n","        self.s=s\n","        self.sin_m=tf.sin(m)\n","        self.cos_m=tf.cos(m)\n","        self.n_classes=n_classes\n","        self.threshold = tf.cos(math.pi - m)\n","        self.mm = tf.math.sin(math.pi - m) * m\n","\n","    def build(self,input_shape):\n","        prev_layer_units=input_shape[0][1]\n","        self.w=self.add_weight(shape=(prev_layer_units,self.n_classes),trainable=True,\n","                              initializer='glorot_uniform')\n","\n","    def get_config(self):\n","        config=super().get_config()\n","        config.update({\"m\":0.5,\n","                       \"s\":30,\n","                       \"n_classes\":11014})\n","        return config\n","\n","\n","    def call(self,inputs):\n","        prev_layer,y=inputs\n","        y=tf.cast(y,dtype=tf.int32)\n","        y_hot=tf.one_hot(y,self.n_classes)\n","        y_hot=tf.cast(y_hot,dtype=tf.float32)\n","        w_norm=tf.linalg.l2_normalize(self.w,axis=0)\n","        x_norm=tf.linalg.l2_normalize(prev_layer,axis=1)\n","        cos_theta=tf.linalg.matmul(x_norm,w_norm)\n","        sin_theta=tf.sqrt(1-tf.pow(cos_theta,tf.cast(2,dtype=tf.float32)))\n","        cos_theta_m=(cos_theta*self.cos_m)-(sin_theta*self.sin_m)\n","        cos_theta_m=tf.where(cos_theta>self.threshold,cos_theta_m,cos_theta-self.mm)\n","        final=self.s*((y_hot*cos_theta_m)+((1-y_hot)*cos_theta))\n","        return final"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:43.711460Z","iopub.status.busy":"2022-06-29T13:52:43.710909Z","iopub.status.idle":"2022-06-29T13:52:43.729403Z","shell.execute_reply":"2022-06-29T13:52:43.728468Z","shell.execute_reply.started":"2022-06-29T13:52:43.711424Z"},"trusted":true},"outputs":[],"source":["def MAKE_MODEL_INPUTS(dataframe):\n","    INPUT_IDS=np.zeros((dataframe.shape[0],MAX_LENGTH),dtype=np.int32)\n","    ATTENTION_MASK=np.zeros((dataframe.shape[0],MAX_LENGTH),dtype=np.int32)\n","    if PRE_TRAINED_NAME.startswith(\"bert\"):\n","        TOKEN_TYPE_IDS=np.zeros((dataframe.shape[0],MAX_LENGTH),dtype=np.int32)\n","    Y=np.zeros((dataframe.shape[0],),dtype=np.int32)\n","    n_iter=int(np.ceil(dataframe.shape[0])/BATCH_SIZE)\n","    max_size=dataframe.shape[0]\n","    for batch in range(n_iter):\n","        start=batch*BATCH_SIZE\n","        end=(batch+1)*BATCH_SIZE\n","        if end>max_size:\n","            end=max_size\n","        if PRE_TRAINED_NAME.startswith(\"bert\"):\n","            curr=dataframe.iloc[start:end]['title'].values.tolist()\n","        else:\n","            curr=list(\" \"+x for x in dataframe.iloc[start:end]['title'].values.tolist())\n","        tokenized_data=TOKENIZER.batch_encode_plus(curr,max_length=MAX_LENGTH,truncation=\"longest_first\",padding='max_length')\n","        INPUT_IDS[start:end,]=tokenized_data['input_ids']\n","        ATTENTION_MASK[start:end,]=tokenized_data['attention_mask']\n","        if PRE_TRAINED_NAME.startswith(\"bert\"):\n","            TOKEN_TYPE_IDS[start:end,]=tokenized_data['token_type_ids']\n","        Y[start:end,]=dataframe.iloc[start:end]['label_group'].values.tolist()\n","    MODEL_INPUTS=({\"input_ids\":INPUT_IDS,\"attention_mask\":ATTENTION_MASK},Y)\n","    if PRE_TRAINED_NAME.startswith(\"bert\"):\n","        MODEL_INPUTS[0]['token_type_ids']=TOKEN_TYPE_IDS\n","    MODEL_OUTPUTS=Y\n","    return MODEL_INPUTS,MODEL_OUTPUTS"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T13:52:44.315134Z","iopub.status.busy":"2022-06-29T13:52:44.314823Z","iopub.status.idle":"2022-06-29T16:34:58.617350Z","shell.execute_reply":"2022-06-29T16:34:58.616344Z","shell.execute_reply.started":"2022-06-29T13:52:44.315081Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf5e1a39524d4f5798f9d3f861c7eb2d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bafe39c478764fc7b3ad598780dbefcb","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/536M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["training for fold 0\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 180)]        0                                            \n","__________________________________________________________________________________________________\n","input_1 (InputLayer)            [(None, 180)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 180)]        0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_2[0][0]                    \n","                                                                 input_1[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 180, 3072)    0           tf_bert_model[0][12]             \n","                                                                 tf_bert_model[0][11]             \n","                                                                 tf_bert_model[0][10]             \n","                                                                 tf_bert_model[0][9]              \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem (Slici (None, 3072)         0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 720)          2212560     tf.__operators__.getitem[0][0]   \n","__________________________________________________________________________________________________\n","label_input (InputLayer)        [(None,)]            0                                            \n","__________________________________________________________________________________________________\n","arcface_layer (ARCFACE_LAYER)   (None, 11014)        7930080     dense[0][0]                      \n","                                                                 label_input[0][0]                \n","__________________________________________________________________________________________________\n","softmax (Softmax)               (None, 11014)        0           arcface_layer[0][0]              \n","==================================================================================================\n","Total params: 119,624,880\n","Trainable params: 119,624,880\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/80\n","107/107 [==============================] - 157s 767ms/step - loss: 24.0969 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.7127 - val_sparse_categorical_accuracy: 0.0283\n","\n","Epoch 00001: val_loss improved from inf to 22.71271, saving model to bert-base-uncased0_180.h5\n","Epoch 2/80\n","107/107 [==============================] - 22s 202ms/step - loss: 22.6406 - sparse_categorical_accuracy: 9.5304e-04 - val_loss: 20.9230 - val_sparse_categorical_accuracy: 0.0362\n","\n","Epoch 00002: val_loss improved from 22.71271 to 20.92295, saving model to bert-base-uncased0_180.h5\n","Epoch 3/80\n","107/107 [==============================] - 22s 202ms/step - loss: 20.6510 - sparse_categorical_accuracy: 0.0091 - val_loss: 19.3235 - val_sparse_categorical_accuracy: 0.0543\n","\n","Epoch 00003: val_loss improved from 20.92295 to 19.32349, saving model to bert-base-uncased0_180.h5\n","Epoch 4/80\n","107/107 [==============================] - 22s 202ms/step - loss: 18.7467 - sparse_categorical_accuracy: 0.0231 - val_loss: 18.0984 - val_sparse_categorical_accuracy: 0.0683\n","\n","Epoch 00004: val_loss improved from 19.32349 to 18.09840, saving model to bert-base-uncased0_180.h5\n","Epoch 5/80\n","107/107 [==============================] - 22s 202ms/step - loss: 17.0567 - sparse_categorical_accuracy: 0.0366 - val_loss: 17.0652 - val_sparse_categorical_accuracy: 0.0848\n","\n","Epoch 00005: val_loss improved from 18.09840 to 17.06518, saving model to bert-base-uncased0_180.h5\n","Epoch 6/80\n","107/107 [==============================] - 22s 203ms/step - loss: 15.5636 - sparse_categorical_accuracy: 0.0575 - val_loss: 16.1966 - val_sparse_categorical_accuracy: 0.1028\n","\n","Epoch 00006: val_loss improved from 17.06518 to 16.19663, saving model to bert-base-uncased0_180.h5\n","Epoch 7/80\n","107/107 [==============================] - 22s 203ms/step - loss: 14.2779 - sparse_categorical_accuracy: 0.0733 - val_loss: 15.4554 - val_sparse_categorical_accuracy: 0.1203\n","\n","Epoch 00007: val_loss improved from 16.19663 to 15.45537, saving model to bert-base-uncased0_180.h5\n","Epoch 8/80\n","107/107 [==============================] - 22s 202ms/step - loss: 13.0874 - sparse_categorical_accuracy: 0.0918 - val_loss: 14.8262 - val_sparse_categorical_accuracy: 0.1377\n","\n","Epoch 00008: val_loss improved from 15.45537 to 14.82625, saving model to bert-base-uncased0_180.h5\n","Epoch 9/80\n","107/107 [==============================] - 22s 204ms/step - loss: 11.9177 - sparse_categorical_accuracy: 0.1159 - val_loss: 14.2517 - val_sparse_categorical_accuracy: 0.1555\n","\n","Epoch 00009: val_loss improved from 14.82625 to 14.25169, saving model to bert-base-uncased0_180.h5\n","Epoch 10/80\n","107/107 [==============================] - 22s 202ms/step - loss: 10.9844 - sparse_categorical_accuracy: 0.1330 - val_loss: 13.7140 - val_sparse_categorical_accuracy: 0.1714\n","\n","Epoch 00010: val_loss improved from 14.25169 to 13.71399, saving model to bert-base-uncased0_180.h5\n","Epoch 11/80\n","107/107 [==============================] - 22s 203ms/step - loss: 9.9323 - sparse_categorical_accuracy: 0.1660 - val_loss: 13.2707 - val_sparse_categorical_accuracy: 0.1850\n","\n","Epoch 00011: val_loss improved from 13.71399 to 13.27073, saving model to bert-base-uncased0_180.h5\n","Epoch 12/80\n","107/107 [==============================] - 22s 202ms/step - loss: 9.0549 - sparse_categorical_accuracy: 0.1910 - val_loss: 12.8558 - val_sparse_categorical_accuracy: 0.2013\n","\n","Epoch 00012: val_loss improved from 13.27073 to 12.85581, saving model to bert-base-uncased0_180.h5\n","Epoch 13/80\n","107/107 [==============================] - 22s 202ms/step - loss: 8.2325 - sparse_categorical_accuracy: 0.2203 - val_loss: 12.5134 - val_sparse_categorical_accuracy: 0.2166\n","\n","Epoch 00013: val_loss improved from 12.85581 to 12.51340, saving model to bert-base-uncased0_180.h5\n","Epoch 14/80\n","107/107 [==============================] - 22s 203ms/step - loss: 7.5038 - sparse_categorical_accuracy: 0.2490 - val_loss: 12.1747 - val_sparse_categorical_accuracy: 0.2321\n","\n","Epoch 00014: val_loss improved from 12.51340 to 12.17474, saving model to bert-base-uncased0_180.h5\n","Epoch 15/80\n","107/107 [==============================] - 22s 203ms/step - loss: 6.7521 - sparse_categorical_accuracy: 0.2905 - val_loss: 11.9105 - val_sparse_categorical_accuracy: 0.2442\n","\n","Epoch 00015: val_loss improved from 12.17474 to 11.91052, saving model to bert-base-uncased0_180.h5\n","Epoch 16/80\n","107/107 [==============================] - 22s 202ms/step - loss: 6.0872 - sparse_categorical_accuracy: 0.3290 - val_loss: 11.6569 - val_sparse_categorical_accuracy: 0.2569\n","\n","Epoch 00016: val_loss improved from 11.91052 to 11.65690, saving model to bert-base-uncased0_180.h5\n","Epoch 17/80\n","107/107 [==============================] - 22s 202ms/step - loss: 5.4325 - sparse_categorical_accuracy: 0.3770 - val_loss: 11.4148 - val_sparse_categorical_accuracy: 0.2669\n","\n","Epoch 00017: val_loss improved from 11.65690 to 11.41482, saving model to bert-base-uncased0_180.h5\n","Epoch 18/80\n","107/107 [==============================] - 22s 202ms/step - loss: 4.8847 - sparse_categorical_accuracy: 0.4224 - val_loss: 11.2038 - val_sparse_categorical_accuracy: 0.2762\n","\n","Epoch 00018: val_loss improved from 11.41482 to 11.20380, saving model to bert-base-uncased0_180.h5\n","Epoch 19/80\n","107/107 [==============================] - 22s 203ms/step - loss: 4.3327 - sparse_categorical_accuracy: 0.4707 - val_loss: 10.9869 - val_sparse_categorical_accuracy: 0.2882\n","\n","Epoch 00019: val_loss improved from 11.20380 to 10.98686, saving model to bert-base-uncased0_180.h5\n","Epoch 20/80\n","107/107 [==============================] - 22s 202ms/step - loss: 3.7925 - sparse_categorical_accuracy: 0.5248 - val_loss: 10.8118 - val_sparse_categorical_accuracy: 0.2981\n","\n","Epoch 00020: val_loss improved from 10.98686 to 10.81181, saving model to bert-base-uncased0_180.h5\n","Epoch 21/80\n","107/107 [==============================] - 22s 203ms/step - loss: 3.3776 - sparse_categorical_accuracy: 0.5620 - val_loss: 10.6291 - val_sparse_categorical_accuracy: 0.3077\n","\n","Epoch 00021: val_loss improved from 10.81181 to 10.62911, saving model to bert-base-uncased0_180.h5\n","Epoch 22/80\n","107/107 [==============================] - 22s 203ms/step - loss: 2.9931 - sparse_categorical_accuracy: 0.6007 - val_loss: 10.4782 - val_sparse_categorical_accuracy: 0.3149\n","\n","Epoch 00022: val_loss improved from 10.62911 to 10.47823, saving model to bert-base-uncased0_180.h5\n","Epoch 23/80\n","107/107 [==============================] - 22s 203ms/step - loss: 2.6116 - sparse_categorical_accuracy: 0.6408 - val_loss: 10.3365 - val_sparse_categorical_accuracy: 0.3253\n","\n","Epoch 00023: val_loss improved from 10.47823 to 10.33653, saving model to bert-base-uncased0_180.h5\n","Epoch 24/80\n","107/107 [==============================] - 22s 203ms/step - loss: 2.2771 - sparse_categorical_accuracy: 0.6817 - val_loss: 10.2146 - val_sparse_categorical_accuracy: 0.3286\n","\n","Epoch 00024: val_loss improved from 10.33653 to 10.21463, saving model to bert-base-uncased0_180.h5\n","Epoch 25/80\n","107/107 [==============================] - 22s 203ms/step - loss: 2.0061 - sparse_categorical_accuracy: 0.7161 - val_loss: 10.0532 - val_sparse_categorical_accuracy: 0.3420\n","\n","Epoch 00025: val_loss improved from 10.21463 to 10.05319, saving model to bert-base-uncased0_180.h5\n","Epoch 26/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.7284 - sparse_categorical_accuracy: 0.7590 - val_loss: 9.9783 - val_sparse_categorical_accuracy: 0.3505\n","\n","Epoch 00026: val_loss improved from 10.05319 to 9.97830, saving model to bert-base-uncased0_180.h5\n","Epoch 27/80\n","107/107 [==============================] - 22s 203ms/step - loss: 1.4803 - sparse_categorical_accuracy: 0.7929 - val_loss: 9.8467 - val_sparse_categorical_accuracy: 0.3587\n","\n","Epoch 00027: val_loss improved from 9.97830 to 9.84669, saving model to bert-base-uncased0_180.h5\n","Epoch 28/80\n","107/107 [==============================] - 22s 203ms/step - loss: 1.2704 - sparse_categorical_accuracy: 0.8292 - val_loss: 9.7536 - val_sparse_categorical_accuracy: 0.3672\n","\n","Epoch 00028: val_loss improved from 9.84669 to 9.75360, saving model to bert-base-uncased0_180.h5\n","Epoch 29/80\n","107/107 [==============================] - 22s 203ms/step - loss: 1.0844 - sparse_categorical_accuracy: 0.8599 - val_loss: 9.6779 - val_sparse_categorical_accuracy: 0.3724\n","\n","Epoch 00029: val_loss improved from 9.75360 to 9.67787, saving model to bert-base-uncased0_180.h5\n","Epoch 30/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.9287 - sparse_categorical_accuracy: 0.8931 - val_loss: 9.6024 - val_sparse_categorical_accuracy: 0.3815\n","\n","Epoch 00030: val_loss improved from 9.67787 to 9.60240, saving model to bert-base-uncased0_180.h5\n","Epoch 31/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.8003 - sparse_categorical_accuracy: 0.9137 - val_loss: 9.5349 - val_sparse_categorical_accuracy: 0.3866\n","\n","Epoch 00031: val_loss improved from 9.60240 to 9.53490, saving model to bert-base-uncased0_180.h5\n","Epoch 32/80\n","107/107 [==============================] - 22s 209ms/step - loss: 0.6820 - sparse_categorical_accuracy: 0.9333 - val_loss: 9.4582 - val_sparse_categorical_accuracy: 0.3928\n","\n","Epoch 00032: val_loss improved from 9.53490 to 9.45825, saving model to bert-base-uncased0_180.h5\n","Epoch 33/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.5877 - sparse_categorical_accuracy: 0.9508 - val_loss: 9.4363 - val_sparse_categorical_accuracy: 0.3936\n","\n","Epoch 00033: val_loss improved from 9.45825 to 9.43632, saving model to bert-base-uncased0_180.h5\n","Epoch 34/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.5074 - sparse_categorical_accuracy: 0.9620 - val_loss: 9.3700 - val_sparse_categorical_accuracy: 0.4003\n","\n","Epoch 00034: val_loss improved from 9.43632 to 9.37005, saving model to bert-base-uncased0_180.h5\n","Epoch 35/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.4497 - sparse_categorical_accuracy: 0.9683 - val_loss: 9.3599 - val_sparse_categorical_accuracy: 0.4042\n","\n","Epoch 00035: val_loss improved from 9.37005 to 9.35987, saving model to bert-base-uncased0_180.h5\n","Epoch 36/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.3792 - sparse_categorical_accuracy: 0.9778 - val_loss: 9.2940 - val_sparse_categorical_accuracy: 0.4073\n","\n","Epoch 00036: val_loss improved from 9.35987 to 9.29403, saving model to bert-base-uncased0_180.h5\n","Epoch 37/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.3417 - sparse_categorical_accuracy: 0.9811 - val_loss: 9.2747 - val_sparse_categorical_accuracy: 0.4091\n","\n","Epoch 00037: val_loss improved from 9.29403 to 9.27472, saving model to bert-base-uncased0_180.h5\n","Epoch 38/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.3233 - sparse_categorical_accuracy: 0.9835 - val_loss: 9.2626 - val_sparse_categorical_accuracy: 0.4126\n","\n","Epoch 00038: val_loss improved from 9.27472 to 9.26263, saving model to bert-base-uncased0_180.h5\n","Epoch 39/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.2808 - sparse_categorical_accuracy: 0.9857 - val_loss: 9.2246 - val_sparse_categorical_accuracy: 0.4164\n","\n","Epoch 00039: val_loss improved from 9.26263 to 9.22461, saving model to bert-base-uncased0_180.h5\n","Epoch 40/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.2608 - sparse_categorical_accuracy: 0.9863 - val_loss: 9.2141 - val_sparse_categorical_accuracy: 0.4175\n","\n","Epoch 00040: val_loss improved from 9.22461 to 9.21407, saving model to bert-base-uncased0_180.h5\n","Epoch 41/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.2340 - sparse_categorical_accuracy: 0.9890 - val_loss: 9.1948 - val_sparse_categorical_accuracy: 0.4216\n","\n","Epoch 00041: val_loss improved from 9.21407 to 9.19483, saving model to bert-base-uncased0_180.h5\n","Epoch 42/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.2240 - sparse_categorical_accuracy: 0.9894 - val_loss: 9.1977 - val_sparse_categorical_accuracy: 0.4210\n","\n","Epoch 00042: val_loss did not improve from 9.19483\n","Epoch 43/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.2213 - sparse_categorical_accuracy: 0.9884 - val_loss: 9.1766 - val_sparse_categorical_accuracy: 0.4242\n","\n","Epoch 00043: val_loss improved from 9.19483 to 9.17656, saving model to bert-base-uncased0_180.h5\n","Epoch 44/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2061 - sparse_categorical_accuracy: 0.9905 - val_loss: 9.1951 - val_sparse_categorical_accuracy: 0.4226\n","\n","Epoch 00044: val_loss did not improve from 9.17656\n","Epoch 45/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1876 - sparse_categorical_accuracy: 0.9922 - val_loss: 9.1522 - val_sparse_categorical_accuracy: 0.4250\n","\n","Epoch 00045: val_loss improved from 9.17656 to 9.15220, saving model to bert-base-uncased0_180.h5\n","Epoch 46/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1776 - sparse_categorical_accuracy: 0.9917 - val_loss: 9.1252 - val_sparse_categorical_accuracy: 0.4279\n","\n","Epoch 00046: val_loss improved from 9.15220 to 9.12518, saving model to bert-base-uncased0_180.h5\n","Epoch 47/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1767 - sparse_categorical_accuracy: 0.9920 - val_loss: 9.1502 - val_sparse_categorical_accuracy: 0.4291\n","\n","Epoch 00047: val_loss did not improve from 9.12518\n","Epoch 48/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9920 - val_loss: 9.1351 - val_sparse_categorical_accuracy: 0.4295\n","\n","Epoch 00048: val_loss did not improve from 9.12518\n","Epoch 49/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9928 - val_loss: 9.1263 - val_sparse_categorical_accuracy: 0.4299\n","\n","Epoch 00049: val_loss did not improve from 9.12518\n","Epoch 50/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1729 - sparse_categorical_accuracy: 0.9920 - val_loss: 9.1095 - val_sparse_categorical_accuracy: 0.4307\n","\n","Epoch 00050: val_loss improved from 9.12518 to 9.10949, saving model to bert-base-uncased0_180.h5\n","Epoch 51/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1667 - sparse_categorical_accuracy: 0.9913 - val_loss: 9.0873 - val_sparse_categorical_accuracy: 0.4315\n","\n","Epoch 00051: val_loss improved from 9.10949 to 9.08728, saving model to bert-base-uncased0_180.h5\n","Epoch 52/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1475 - sparse_categorical_accuracy: 0.9926 - val_loss: 9.1138 - val_sparse_categorical_accuracy: 0.4312\n","\n","Epoch 00052: val_loss did not improve from 9.08728\n","Epoch 53/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1509 - sparse_categorical_accuracy: 0.9929 - val_loss: 9.1008 - val_sparse_categorical_accuracy: 0.4340\n","\n","Epoch 00053: val_loss did not improve from 9.08728\n","Epoch 54/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1461 - sparse_categorical_accuracy: 0.9928 - val_loss: 9.0763 - val_sparse_categorical_accuracy: 0.4347\n","\n","Epoch 00054: val_loss improved from 9.08728 to 9.07633, saving model to bert-base-uncased0_180.h5\n","Epoch 55/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1413 - sparse_categorical_accuracy: 0.9930 - val_loss: 9.0811 - val_sparse_categorical_accuracy: 0.4353\n","\n","Epoch 00055: val_loss did not improve from 9.07633\n","Epoch 56/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1396 - sparse_categorical_accuracy: 0.9925 - val_loss: 9.1030 - val_sparse_categorical_accuracy: 0.4328\n","\n","Epoch 00056: val_loss did not improve from 9.07633\n","Epoch 57/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1404 - sparse_categorical_accuracy: 0.9922 - val_loss: 9.0871 - val_sparse_categorical_accuracy: 0.4339\n","\n","Epoch 00057: val_loss did not improve from 9.07633\n","Epoch 58/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1386 - sparse_categorical_accuracy: 0.9917 - val_loss: 9.1239 - val_sparse_categorical_accuracy: 0.4343\n","\n","Epoch 00058: val_loss did not improve from 9.07633\n","Epoch 59/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1404 - sparse_categorical_accuracy: 0.9924 - val_loss: 9.1018 - val_sparse_categorical_accuracy: 0.4334\n","\n","Epoch 00059: val_loss did not improve from 9.07633\n","Epoch 60/80\n","107/107 [==============================] - 22s 202ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9924 - val_loss: 9.1141 - val_sparse_categorical_accuracy: 0.4349\n","\n","Epoch 00060: val_loss did not improve from 9.07633\n","Epoch 61/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1293 - sparse_categorical_accuracy: 0.9930 - val_loss: 9.1168 - val_sparse_categorical_accuracy: 0.4323\n","\n","Epoch 00061: val_loss did not improve from 9.07633\n","Epoch 62/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1403 - sparse_categorical_accuracy: 0.9921 - val_loss: 9.0871 - val_sparse_categorical_accuracy: 0.4339\n","\n","Epoch 00062: val_loss did not improve from 9.07633\n","Epoch 63/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1460 - sparse_categorical_accuracy: 0.9915 - val_loss: 9.0843 - val_sparse_categorical_accuracy: 0.4358\n","\n","Epoch 00063: val_loss did not improve from 9.07633\n","Epoch 64/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1551 - sparse_categorical_accuracy: 0.9916 - val_loss: 9.1310 - val_sparse_categorical_accuracy: 0.4342\n","\n","Epoch 00064: val_loss did not improve from 9.07633\n","Epoch 00064: early stopping\n","model training for 0 is done\n"]},{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["training for fold 1\n","Epoch 1/80\n","107/107 [==============================] - 161s 776ms/step - loss: 24.1160 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.0494 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00001: val_loss improved from inf to 23.04940, saving model to bert-base-uncased1_180.h5\n","Epoch 2/80\n","107/107 [==============================] - 22s 203ms/step - loss: 22.8419 - sparse_categorical_accuracy: 4.9748e-04 - val_loss: 21.1221 - val_sparse_categorical_accuracy: 0.0369\n","\n","Epoch 00002: val_loss improved from 23.04940 to 21.12208, saving model to bert-base-uncased1_180.h5\n","Epoch 3/80\n","107/107 [==============================] - 22s 203ms/step - loss: 20.8618 - sparse_categorical_accuracy: 0.0100 - val_loss: 19.4032 - val_sparse_categorical_accuracy: 0.0517\n","\n","Epoch 00003: val_loss improved from 21.12208 to 19.40323, saving model to bert-base-uncased1_180.h5\n","Epoch 4/80\n","107/107 [==============================] - 22s 204ms/step - loss: 18.8431 - sparse_categorical_accuracy: 0.0235 - val_loss: 18.1294 - val_sparse_categorical_accuracy: 0.0692\n","\n","Epoch 00004: val_loss improved from 19.40323 to 18.12937, saving model to bert-base-uncased1_180.h5\n","Epoch 5/80\n","107/107 [==============================] - 22s 204ms/step - loss: 17.2393 - sparse_categorical_accuracy: 0.0351 - val_loss: 17.0511 - val_sparse_categorical_accuracy: 0.0857\n","\n","Epoch 00005: val_loss improved from 18.12937 to 17.05112, saving model to bert-base-uncased1_180.h5\n","Epoch 6/80\n","107/107 [==============================] - 22s 204ms/step - loss: 15.7457 - sparse_categorical_accuracy: 0.0534 - val_loss: 16.1585 - val_sparse_categorical_accuracy: 0.1051\n","\n","Epoch 00006: val_loss improved from 17.05112 to 16.15853, saving model to bert-base-uncased1_180.h5\n","Epoch 7/80\n","107/107 [==============================] - 22s 204ms/step - loss: 14.3572 - sparse_categorical_accuracy: 0.0715 - val_loss: 15.3798 - val_sparse_categorical_accuracy: 0.1201\n","\n","Epoch 00007: val_loss improved from 16.15853 to 15.37982, saving model to bert-base-uncased1_180.h5\n","Epoch 8/80\n","107/107 [==============================] - 22s 203ms/step - loss: 13.1598 - sparse_categorical_accuracy: 0.0878 - val_loss: 14.7252 - val_sparse_categorical_accuracy: 0.1396\n","\n","Epoch 00008: val_loss improved from 15.37982 to 14.72520, saving model to bert-base-uncased1_180.h5\n","Epoch 9/80\n","107/107 [==============================] - 22s 204ms/step - loss: 12.1047 - sparse_categorical_accuracy: 0.1081 - val_loss: 14.1324 - val_sparse_categorical_accuracy: 0.1569\n","\n","Epoch 00009: val_loss improved from 14.72520 to 14.13242, saving model to bert-base-uncased1_180.h5\n","Epoch 10/80\n","107/107 [==============================] - 22s 204ms/step - loss: 11.0993 - sparse_categorical_accuracy: 0.1311 - val_loss: 13.6170 - val_sparse_categorical_accuracy: 0.1734\n","\n","Epoch 00010: val_loss improved from 14.13242 to 13.61703, saving model to bert-base-uncased1_180.h5\n","Epoch 11/80\n","107/107 [==============================] - 22s 204ms/step - loss: 10.1527 - sparse_categorical_accuracy: 0.1518 - val_loss: 13.1644 - val_sparse_categorical_accuracy: 0.1864\n","\n","Epoch 00011: val_loss improved from 13.61703 to 13.16435, saving model to bert-base-uncased1_180.h5\n","Epoch 12/80\n","107/107 [==============================] - 22s 204ms/step - loss: 9.2169 - sparse_categorical_accuracy: 0.1815 - val_loss: 12.7758 - val_sparse_categorical_accuracy: 0.2015\n","\n","Epoch 00012: val_loss improved from 13.16435 to 12.77578, saving model to bert-base-uncased1_180.h5\n","Epoch 13/80\n","107/107 [==============================] - 22s 204ms/step - loss: 8.4139 - sparse_categorical_accuracy: 0.2062 - val_loss: 12.3735 - val_sparse_categorical_accuracy: 0.2197\n","\n","Epoch 00013: val_loss improved from 12.77578 to 12.37345, saving model to bert-base-uncased1_180.h5\n","Epoch 14/80\n","107/107 [==============================] - 22s 204ms/step - loss: 7.6069 - sparse_categorical_accuracy: 0.2411 - val_loss: 12.0602 - val_sparse_categorical_accuracy: 0.2334\n","\n","Epoch 00014: val_loss improved from 12.37345 to 12.06022, saving model to bert-base-uncased1_180.h5\n","Epoch 15/80\n","107/107 [==============================] - 22s 205ms/step - loss: 6.8640 - sparse_categorical_accuracy: 0.2800 - val_loss: 11.7306 - val_sparse_categorical_accuracy: 0.2439\n","\n","Epoch 00015: val_loss improved from 12.06022 to 11.73062, saving model to bert-base-uncased1_180.h5\n","Epoch 16/80\n","107/107 [==============================] - 22s 204ms/step - loss: 6.1988 - sparse_categorical_accuracy: 0.3206 - val_loss: 11.4879 - val_sparse_categorical_accuracy: 0.2543\n","\n","Epoch 00016: val_loss improved from 11.73062 to 11.48789, saving model to bert-base-uncased1_180.h5\n","Epoch 17/80\n","107/107 [==============================] - 22s 204ms/step - loss: 5.5536 - sparse_categorical_accuracy: 0.3655 - val_loss: 11.2234 - val_sparse_categorical_accuracy: 0.2686\n","\n","Epoch 00017: val_loss improved from 11.48789 to 11.22341, saving model to bert-base-uncased1_180.h5\n","Epoch 18/80\n","107/107 [==============================] - 22s 204ms/step - loss: 4.9721 - sparse_categorical_accuracy: 0.4114 - val_loss: 11.0098 - val_sparse_categorical_accuracy: 0.2782\n","\n","Epoch 00018: val_loss improved from 11.22341 to 11.00984, saving model to bert-base-uncased1_180.h5\n","Epoch 19/80\n","107/107 [==============================] - 22s 204ms/step - loss: 4.4374 - sparse_categorical_accuracy: 0.4568 - val_loss: 10.8040 - val_sparse_categorical_accuracy: 0.2863\n","\n","Epoch 00019: val_loss improved from 11.00984 to 10.80399, saving model to bert-base-uncased1_180.h5\n","Epoch 20/80\n","107/107 [==============================] - 22s 204ms/step - loss: 3.9099 - sparse_categorical_accuracy: 0.5076 - val_loss: 10.5945 - val_sparse_categorical_accuracy: 0.3004\n","\n","Epoch 00020: val_loss improved from 10.80399 to 10.59447, saving model to bert-base-uncased1_180.h5\n","Epoch 21/80\n","107/107 [==============================] - 22s 204ms/step - loss: 3.4840 - sparse_categorical_accuracy: 0.5457 - val_loss: 10.4384 - val_sparse_categorical_accuracy: 0.3082\n","\n","Epoch 00021: val_loss improved from 10.59447 to 10.43843, saving model to bert-base-uncased1_180.h5\n","Epoch 22/80\n","107/107 [==============================] - 22s 204ms/step - loss: 3.0723 - sparse_categorical_accuracy: 0.5891 - val_loss: 10.2672 - val_sparse_categorical_accuracy: 0.3182\n","\n","Epoch 00022: val_loss improved from 10.43843 to 10.26715, saving model to bert-base-uncased1_180.h5\n","Epoch 23/80\n","107/107 [==============================] - 22s 203ms/step - loss: 2.7281 - sparse_categorical_accuracy: 0.6273 - val_loss: 10.1141 - val_sparse_categorical_accuracy: 0.3298\n","\n","Epoch 00023: val_loss improved from 10.26715 to 10.11406, saving model to bert-base-uncased1_180.h5\n","Epoch 24/80\n","107/107 [==============================] - 22s 203ms/step - loss: 2.3503 - sparse_categorical_accuracy: 0.6708 - val_loss: 9.9843 - val_sparse_categorical_accuracy: 0.3375\n","\n","Epoch 00024: val_loss improved from 10.11406 to 9.98431, saving model to bert-base-uncased1_180.h5\n","Epoch 25/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.9978 - sparse_categorical_accuracy: 0.7181 - val_loss: 9.8588 - val_sparse_categorical_accuracy: 0.3453\n","\n","Epoch 00025: val_loss improved from 9.98431 to 9.85882, saving model to bert-base-uncased1_180.h5\n","Epoch 26/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.7581 - sparse_categorical_accuracy: 0.7499 - val_loss: 9.7361 - val_sparse_categorical_accuracy: 0.3534\n","\n","Epoch 00026: val_loss improved from 9.85882 to 9.73609, saving model to bert-base-uncased1_180.h5\n","Epoch 27/80\n","107/107 [==============================] - 22s 209ms/step - loss: 1.5348 - sparse_categorical_accuracy: 0.7897 - val_loss: 9.6383 - val_sparse_categorical_accuracy: 0.3644\n","\n","Epoch 00027: val_loss improved from 9.73609 to 9.63834, saving model to bert-base-uncased1_180.h5\n","Epoch 28/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.3219 - sparse_categorical_accuracy: 0.8249 - val_loss: 9.5213 - val_sparse_categorical_accuracy: 0.3707\n","\n","Epoch 00028: val_loss improved from 9.63834 to 9.52125, saving model to bert-base-uncased1_180.h5\n","Epoch 29/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.1288 - sparse_categorical_accuracy: 0.8558 - val_loss: 9.4278 - val_sparse_categorical_accuracy: 0.3800\n","\n","Epoch 00029: val_loss improved from 9.52125 to 9.42778, saving model to bert-base-uncased1_180.h5\n","Epoch 30/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.9682 - sparse_categorical_accuracy: 0.8855 - val_loss: 9.3620 - val_sparse_categorical_accuracy: 0.3857\n","\n","Epoch 00030: val_loss improved from 9.42778 to 9.36202, saving model to bert-base-uncased1_180.h5\n","Epoch 31/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.8228 - sparse_categorical_accuracy: 0.9148 - val_loss: 9.2616 - val_sparse_categorical_accuracy: 0.3918\n","\n","Epoch 00031: val_loss improved from 9.36202 to 9.26163, saving model to bert-base-uncased1_180.h5\n","Epoch 32/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.7004 - sparse_categorical_accuracy: 0.9329 - val_loss: 9.2185 - val_sparse_categorical_accuracy: 0.3945\n","\n","Epoch 00032: val_loss improved from 9.26163 to 9.21846, saving model to bert-base-uncased1_180.h5\n","Epoch 33/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.6039 - sparse_categorical_accuracy: 0.9474 - val_loss: 9.1682 - val_sparse_categorical_accuracy: 0.4022\n","\n","Epoch 00033: val_loss improved from 9.21846 to 9.16820, saving model to bert-base-uncased1_180.h5\n","Epoch 34/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.5145 - sparse_categorical_accuracy: 0.9628 - val_loss: 9.1289 - val_sparse_categorical_accuracy: 0.4023\n","\n","Epoch 00034: val_loss improved from 9.16820 to 9.12886, saving model to bert-base-uncased1_180.h5\n","Epoch 35/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.4394 - sparse_categorical_accuracy: 0.9706 - val_loss: 9.1022 - val_sparse_categorical_accuracy: 0.4093\n","\n","Epoch 00035: val_loss improved from 9.12886 to 9.10222, saving model to bert-base-uncased1_180.h5\n","Epoch 36/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.4044 - sparse_categorical_accuracy: 0.9760 - val_loss: 9.0562 - val_sparse_categorical_accuracy: 0.4112\n","\n","Epoch 00036: val_loss improved from 9.10222 to 9.05624, saving model to bert-base-uncased1_180.h5\n","Epoch 37/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.3657 - sparse_categorical_accuracy: 0.9804 - val_loss: 9.0350 - val_sparse_categorical_accuracy: 0.4137\n","\n","Epoch 00037: val_loss improved from 9.05624 to 9.03503, saving model to bert-base-uncased1_180.h5\n","Epoch 38/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.3225 - sparse_categorical_accuracy: 0.9832 - val_loss: 8.9916 - val_sparse_categorical_accuracy: 0.4182\n","\n","Epoch 00038: val_loss improved from 9.03503 to 8.99163, saving model to bert-base-uncased1_180.h5\n","Epoch 39/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.2744 - sparse_categorical_accuracy: 0.9860 - val_loss: 8.9954 - val_sparse_categorical_accuracy: 0.4199\n","\n","Epoch 00039: val_loss did not improve from 8.99163\n","Epoch 40/80\n","107/107 [==============================] - 22s 208ms/step - loss: 0.2588 - sparse_categorical_accuracy: 0.9877 - val_loss: 8.9711 - val_sparse_categorical_accuracy: 0.4232\n","\n","Epoch 00040: val_loss improved from 8.99163 to 8.97110, saving model to bert-base-uncased1_180.h5\n","Epoch 41/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.2474 - sparse_categorical_accuracy: 0.9882 - val_loss: 8.9500 - val_sparse_categorical_accuracy: 0.4228\n","\n","Epoch 00041: val_loss improved from 8.97110 to 8.95000, saving model to bert-base-uncased1_180.h5\n","Epoch 42/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2240 - sparse_categorical_accuracy: 0.9894 - val_loss: 8.9442 - val_sparse_categorical_accuracy: 0.4244\n","\n","Epoch 00042: val_loss improved from 8.95000 to 8.94419, saving model to bert-base-uncased1_180.h5\n","Epoch 43/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1981 - sparse_categorical_accuracy: 0.9910 - val_loss: 8.9235 - val_sparse_categorical_accuracy: 0.4270\n","\n","Epoch 00043: val_loss improved from 8.94419 to 8.92353, saving model to bert-base-uncased1_180.h5\n","Epoch 44/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1965 - sparse_categorical_accuracy: 0.9913 - val_loss: 8.9180 - val_sparse_categorical_accuracy: 0.4269\n","\n","Epoch 00044: val_loss improved from 8.92353 to 8.91802, saving model to bert-base-uncased1_180.h5\n","Epoch 45/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1847 - sparse_categorical_accuracy: 0.9917 - val_loss: 8.8940 - val_sparse_categorical_accuracy: 0.4276\n","\n","Epoch 00045: val_loss improved from 8.91802 to 8.89401, saving model to bert-base-uncased1_180.h5\n","Epoch 46/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1831 - sparse_categorical_accuracy: 0.9915 - val_loss: 8.8930 - val_sparse_categorical_accuracy: 0.4324\n","\n","Epoch 00046: val_loss improved from 8.89401 to 8.89299, saving model to bert-base-uncased1_180.h5\n","Epoch 47/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1683 - sparse_categorical_accuracy: 0.9924 - val_loss: 8.8684 - val_sparse_categorical_accuracy: 0.4324\n","\n","Epoch 00047: val_loss improved from 8.89299 to 8.86841, saving model to bert-base-uncased1_180.h5\n","Epoch 48/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9933 - val_loss: 8.8875 - val_sparse_categorical_accuracy: 0.4340\n","\n","Epoch 00048: val_loss did not improve from 8.86841\n","Epoch 49/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1535 - sparse_categorical_accuracy: 0.9928 - val_loss: 8.8742 - val_sparse_categorical_accuracy: 0.4342\n","\n","Epoch 00049: val_loss did not improve from 8.86841\n","Epoch 50/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9941 - val_loss: 8.8995 - val_sparse_categorical_accuracy: 0.4331\n","\n","Epoch 00050: val_loss did not improve from 8.86841\n","Epoch 51/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1346 - sparse_categorical_accuracy: 0.9937 - val_loss: 8.8691 - val_sparse_categorical_accuracy: 0.4355\n","\n","Epoch 00051: val_loss did not improve from 8.86841\n","Epoch 52/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1384 - sparse_categorical_accuracy: 0.9929 - val_loss: 8.8761 - val_sparse_categorical_accuracy: 0.4368\n","\n","Epoch 00052: val_loss did not improve from 8.86841\n","Epoch 53/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1391 - sparse_categorical_accuracy: 0.9936 - val_loss: 8.8834 - val_sparse_categorical_accuracy: 0.4372\n","\n","Epoch 00053: val_loss did not improve from 8.86841\n","Epoch 54/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1525 - sparse_categorical_accuracy: 0.9924 - val_loss: 8.8923 - val_sparse_categorical_accuracy: 0.4377\n","\n","Epoch 00054: val_loss did not improve from 8.86841\n","Epoch 55/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9926 - val_loss: 8.8614 - val_sparse_categorical_accuracy: 0.4378\n","\n","Epoch 00055: val_loss improved from 8.86841 to 8.86139, saving model to bert-base-uncased1_180.h5\n","Epoch 56/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1279 - sparse_categorical_accuracy: 0.9934 - val_loss: 8.8734 - val_sparse_categorical_accuracy: 0.4388\n","\n","Epoch 00056: val_loss did not improve from 8.86139\n","Epoch 57/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1558 - sparse_categorical_accuracy: 0.9913 - val_loss: 8.8547 - val_sparse_categorical_accuracy: 0.4412\n","\n","Epoch 00057: val_loss improved from 8.86139 to 8.85470, saving model to bert-base-uncased1_180.h5\n","Epoch 58/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1553 - sparse_categorical_accuracy: 0.9918 - val_loss: 8.8488 - val_sparse_categorical_accuracy: 0.4390\n","\n","Epoch 00058: val_loss improved from 8.85470 to 8.84879, saving model to bert-base-uncased1_180.h5\n","Epoch 59/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9918 - val_loss: 8.8417 - val_sparse_categorical_accuracy: 0.4404\n","\n","Epoch 00059: val_loss improved from 8.84879 to 8.84171, saving model to bert-base-uncased1_180.h5\n","Epoch 60/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9932 - val_loss: 8.8371 - val_sparse_categorical_accuracy: 0.4423\n","\n","Epoch 00060: val_loss improved from 8.84171 to 8.83707, saving model to bert-base-uncased1_180.h5\n","Epoch 61/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1256 - sparse_categorical_accuracy: 0.9934 - val_loss: 8.8125 - val_sparse_categorical_accuracy: 0.4466\n","\n","Epoch 00061: val_loss improved from 8.83707 to 8.81251, saving model to bert-base-uncased1_180.h5\n","Epoch 62/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1451 - sparse_categorical_accuracy: 0.9919 - val_loss: 8.8025 - val_sparse_categorical_accuracy: 0.4451\n","\n","Epoch 00062: val_loss improved from 8.81251 to 8.80252, saving model to bert-base-uncased1_180.h5\n","Epoch 63/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9932 - val_loss: 8.7927 - val_sparse_categorical_accuracy: 0.4477\n","\n","Epoch 00063: val_loss improved from 8.80252 to 8.79273, saving model to bert-base-uncased1_180.h5\n","Epoch 64/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1215 - sparse_categorical_accuracy: 0.9930 - val_loss: 8.7852 - val_sparse_categorical_accuracy: 0.4511\n","\n","Epoch 00064: val_loss improved from 8.79273 to 8.78520, saving model to bert-base-uncased1_180.h5\n","Epoch 65/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9920 - val_loss: 8.8441 - val_sparse_categorical_accuracy: 0.4435\n","\n","Epoch 00065: val_loss did not improve from 8.78520\n","Epoch 66/80\n","107/107 [==============================] - 22s 207ms/step - loss: 0.1599 - sparse_categorical_accuracy: 0.9911 - val_loss: 8.8196 - val_sparse_categorical_accuracy: 0.4501\n","\n","Epoch 00066: val_loss did not improve from 8.78520\n","Epoch 67/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9936 - val_loss: 8.8057 - val_sparse_categorical_accuracy: 0.4485\n","\n","Epoch 00067: val_loss did not improve from 8.78520\n","Epoch 68/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9935 - val_loss: 8.7947 - val_sparse_categorical_accuracy: 0.4508\n","\n","Epoch 00068: val_loss did not improve from 8.78520\n","Epoch 69/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1119 - sparse_categorical_accuracy: 0.9937 - val_loss: 8.8012 - val_sparse_categorical_accuracy: 0.4507\n","\n","Epoch 00069: val_loss did not improve from 8.78520\n","Epoch 70/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1072 - sparse_categorical_accuracy: 0.9934 - val_loss: 8.7903 - val_sparse_categorical_accuracy: 0.4517\n","\n","Epoch 00070: val_loss did not improve from 8.78520\n","Epoch 71/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1150 - sparse_categorical_accuracy: 0.9924 - val_loss: 8.7703 - val_sparse_categorical_accuracy: 0.4543\n","\n","Epoch 00071: val_loss improved from 8.78520 to 8.77030, saving model to bert-base-uncased1_180.h5\n","Epoch 72/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.0979 - sparse_categorical_accuracy: 0.9936 - val_loss: 8.7864 - val_sparse_categorical_accuracy: 0.4485\n","\n","Epoch 00072: val_loss did not improve from 8.77030\n","Epoch 73/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9926 - val_loss: 8.7847 - val_sparse_categorical_accuracy: 0.4511\n","\n","Epoch 00073: val_loss did not improve from 8.77030\n","Epoch 74/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1083 - sparse_categorical_accuracy: 0.9935 - val_loss: 8.7623 - val_sparse_categorical_accuracy: 0.4526\n","\n","Epoch 00074: val_loss improved from 8.77030 to 8.76228, saving model to bert-base-uncased1_180.h5\n","Epoch 75/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9930 - val_loss: 8.8059 - val_sparse_categorical_accuracy: 0.4473\n","\n","Epoch 00075: val_loss did not improve from 8.76228\n","Epoch 76/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1165 - sparse_categorical_accuracy: 0.9933 - val_loss: 8.7693 - val_sparse_categorical_accuracy: 0.4521\n","\n","Epoch 00076: val_loss did not improve from 8.76228\n","Epoch 77/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9931 - val_loss: 8.8172 - val_sparse_categorical_accuracy: 0.4463\n","\n","Epoch 00077: val_loss did not improve from 8.76228\n","Epoch 78/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.1380 - sparse_categorical_accuracy: 0.9905 - val_loss: 8.8565 - val_sparse_categorical_accuracy: 0.4442\n","\n","Epoch 00078: val_loss did not improve from 8.76228\n","Epoch 79/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1331 - sparse_categorical_accuracy: 0.9905 - val_loss: 8.8044 - val_sparse_categorical_accuracy: 0.4536\n","\n","Epoch 00079: val_loss did not improve from 8.76228\n","Epoch 80/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1377 - sparse_categorical_accuracy: 0.9910 - val_loss: 8.8113 - val_sparse_categorical_accuracy: 0.4453\n","\n","Epoch 00080: val_loss did not improve from 8.76228\n","model training for 1 is done\n"]},{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["training for fold 2\n","Epoch 1/80\n","107/107 [==============================] - 163s 775ms/step - loss: 24.0862 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.6724 - val_sparse_categorical_accuracy: 0.0283\n","\n","Epoch 00001: val_loss improved from inf to 22.67242, saving model to bert-base-uncased2_180.h5\n","Epoch 2/80\n","107/107 [==============================] - 22s 203ms/step - loss: 22.5482 - sparse_categorical_accuracy: 0.0010 - val_loss: 20.6891 - val_sparse_categorical_accuracy: 0.0375\n","\n","Epoch 00002: val_loss improved from 22.67242 to 20.68905, saving model to bert-base-uncased2_180.h5\n","Epoch 3/80\n","107/107 [==============================] - 22s 204ms/step - loss: 20.4262 - sparse_categorical_accuracy: 0.0099 - val_loss: 19.1139 - val_sparse_categorical_accuracy: 0.0561\n","\n","Epoch 00003: val_loss improved from 20.68905 to 19.11388, saving model to bert-base-uncased2_180.h5\n","Epoch 4/80\n","107/107 [==============================] - 22s 203ms/step - loss: 18.5911 - sparse_categorical_accuracy: 0.0238 - val_loss: 17.8464 - val_sparse_categorical_accuracy: 0.0746\n","\n","Epoch 00004: val_loss improved from 19.11388 to 17.84635, saving model to bert-base-uncased2_180.h5\n","Epoch 5/80\n","107/107 [==============================] - 23s 218ms/step - loss: 16.9547 - sparse_categorical_accuracy: 0.0393 - val_loss: 16.7933 - val_sparse_categorical_accuracy: 0.0923\n","\n","Epoch 00005: val_loss improved from 17.84635 to 16.79326, saving model to bert-base-uncased2_180.h5\n","Epoch 6/80\n","107/107 [==============================] - 22s 203ms/step - loss: 15.4984 - sparse_categorical_accuracy: 0.0579 - val_loss: 15.9341 - val_sparse_categorical_accuracy: 0.1069\n","\n","Epoch 00006: val_loss improved from 16.79326 to 15.93408, saving model to bert-base-uncased2_180.h5\n","Epoch 7/80\n","107/107 [==============================] - 22s 204ms/step - loss: 14.1157 - sparse_categorical_accuracy: 0.0794 - val_loss: 15.1932 - val_sparse_categorical_accuracy: 0.1215\n","\n","Epoch 00007: val_loss improved from 15.93408 to 15.19316, saving model to bert-base-uncased2_180.h5\n","Epoch 8/80\n","107/107 [==============================] - 22s 204ms/step - loss: 12.9703 - sparse_categorical_accuracy: 0.0939 - val_loss: 14.5514 - val_sparse_categorical_accuracy: 0.1393\n","\n","Epoch 00008: val_loss improved from 15.19316 to 14.55137, saving model to bert-base-uncased2_180.h5\n","Epoch 9/80\n","107/107 [==============================] - 22s 204ms/step - loss: 11.9160 - sparse_categorical_accuracy: 0.1141 - val_loss: 13.9493 - val_sparse_categorical_accuracy: 0.1587\n","\n","Epoch 00009: val_loss improved from 14.55137 to 13.94928, saving model to bert-base-uncased2_180.h5\n","Epoch 10/80\n","107/107 [==============================] - 22s 204ms/step - loss: 10.8906 - sparse_categorical_accuracy: 0.1352 - val_loss: 13.4501 - val_sparse_categorical_accuracy: 0.1758\n","\n","Epoch 00010: val_loss improved from 13.94928 to 13.45012, saving model to bert-base-uncased2_180.h5\n","Epoch 11/80\n","107/107 [==============================] - 22s 204ms/step - loss: 9.9874 - sparse_categorical_accuracy: 0.1611 - val_loss: 12.9684 - val_sparse_categorical_accuracy: 0.1945\n","\n","Epoch 00011: val_loss improved from 13.45012 to 12.96840, saving model to bert-base-uncased2_180.h5\n","Epoch 12/80\n","107/107 [==============================] - 22s 204ms/step - loss: 9.0414 - sparse_categorical_accuracy: 0.1906 - val_loss: 12.5830 - val_sparse_categorical_accuracy: 0.2093\n","\n","Epoch 00012: val_loss improved from 12.96840 to 12.58301, saving model to bert-base-uncased2_180.h5\n","Epoch 13/80\n","107/107 [==============================] - 22s 204ms/step - loss: 8.2881 - sparse_categorical_accuracy: 0.2154 - val_loss: 12.2155 - val_sparse_categorical_accuracy: 0.2245\n","\n","Epoch 00013: val_loss improved from 12.58301 to 12.21549, saving model to bert-base-uncased2_180.h5\n","Epoch 14/80\n","107/107 [==============================] - 22s 204ms/step - loss: 7.4833 - sparse_categorical_accuracy: 0.2520 - val_loss: 11.8846 - val_sparse_categorical_accuracy: 0.2384\n","\n","Epoch 00014: val_loss improved from 12.21549 to 11.88456, saving model to bert-base-uncased2_180.h5\n","Epoch 15/80\n","107/107 [==============================] - 22s 204ms/step - loss: 6.7774 - sparse_categorical_accuracy: 0.2833 - val_loss: 11.5664 - val_sparse_categorical_accuracy: 0.2505\n","\n","Epoch 00015: val_loss improved from 11.88456 to 11.56645, saving model to bert-base-uncased2_180.h5\n","Epoch 16/80\n","107/107 [==============================] - 22s 204ms/step - loss: 6.0443 - sparse_categorical_accuracy: 0.3302 - val_loss: 11.3094 - val_sparse_categorical_accuracy: 0.2636\n","\n","Epoch 00016: val_loss improved from 11.56645 to 11.30941, saving model to bert-base-uncased2_180.h5\n","Epoch 17/80\n","107/107 [==============================] - 22s 204ms/step - loss: 5.4401 - sparse_categorical_accuracy: 0.3718 - val_loss: 11.0491 - val_sparse_categorical_accuracy: 0.2761\n","\n","Epoch 00017: val_loss improved from 11.30941 to 11.04911, saving model to bert-base-uncased2_180.h5\n","Epoch 18/80\n","107/107 [==============================] - 22s 205ms/step - loss: 4.8358 - sparse_categorical_accuracy: 0.4215 - val_loss: 10.8194 - val_sparse_categorical_accuracy: 0.2870\n","\n","Epoch 00018: val_loss improved from 11.04911 to 10.81939, saving model to bert-base-uncased2_180.h5\n","Epoch 19/80\n","107/107 [==============================] - 22s 205ms/step - loss: 4.3463 - sparse_categorical_accuracy: 0.4676 - val_loss: 10.6087 - val_sparse_categorical_accuracy: 0.2965\n","\n","Epoch 00019: val_loss improved from 10.81939 to 10.60871, saving model to bert-base-uncased2_180.h5\n","Epoch 20/80\n","107/107 [==============================] - 22s 204ms/step - loss: 3.8746 - sparse_categorical_accuracy: 0.5084 - val_loss: 10.4400 - val_sparse_categorical_accuracy: 0.3050\n","\n","Epoch 00020: val_loss improved from 10.60871 to 10.44001, saving model to bert-base-uncased2_180.h5\n","Epoch 21/80\n","107/107 [==============================] - 22s 205ms/step - loss: 3.3992 - sparse_categorical_accuracy: 0.5525 - val_loss: 10.2517 - val_sparse_categorical_accuracy: 0.3168\n","\n","Epoch 00021: val_loss improved from 10.44001 to 10.25173, saving model to bert-base-uncased2_180.h5\n","Epoch 22/80\n","107/107 [==============================] - 22s 204ms/step - loss: 2.9750 - sparse_categorical_accuracy: 0.6015 - val_loss: 10.1075 - val_sparse_categorical_accuracy: 0.3286\n","\n","Epoch 00022: val_loss improved from 10.25173 to 10.10746, saving model to bert-base-uncased2_180.h5\n","Epoch 23/80\n","107/107 [==============================] - 22s 204ms/step - loss: 2.5903 - sparse_categorical_accuracy: 0.6443 - val_loss: 9.9577 - val_sparse_categorical_accuracy: 0.3378\n","\n","Epoch 00023: val_loss improved from 10.10746 to 9.95772, saving model to bert-base-uncased2_180.h5\n","Epoch 24/80\n","107/107 [==============================] - 22s 204ms/step - loss: 2.2472 - sparse_categorical_accuracy: 0.6868 - val_loss: 9.8118 - val_sparse_categorical_accuracy: 0.3499\n","\n","Epoch 00024: val_loss improved from 9.95772 to 9.81177, saving model to bert-base-uncased2_180.h5\n","Epoch 25/80\n","107/107 [==============================] - 22s 203ms/step - loss: 1.9849 - sparse_categorical_accuracy: 0.7245 - val_loss: 9.6667 - val_sparse_categorical_accuracy: 0.3620\n","\n","Epoch 00025: val_loss improved from 9.81177 to 9.66675, saving model to bert-base-uncased2_180.h5\n","Epoch 26/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.7144 - sparse_categorical_accuracy: 0.7577 - val_loss: 9.5513 - val_sparse_categorical_accuracy: 0.3708\n","\n","Epoch 00026: val_loss improved from 9.66675 to 9.55129, saving model to bert-base-uncased2_180.h5\n","Epoch 27/80\n","107/107 [==============================] - 22s 210ms/step - loss: 1.4754 - sparse_categorical_accuracy: 0.7974 - val_loss: 9.4317 - val_sparse_categorical_accuracy: 0.3791\n","\n","Epoch 00027: val_loss improved from 9.55129 to 9.43166, saving model to bert-base-uncased2_180.h5\n","Epoch 28/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.2740 - sparse_categorical_accuracy: 0.8353 - val_loss: 9.3525 - val_sparse_categorical_accuracy: 0.3883\n","\n","Epoch 00028: val_loss improved from 9.43166 to 9.35249, saving model to bert-base-uncased2_180.h5\n","Epoch 29/80\n","107/107 [==============================] - 22s 205ms/step - loss: 1.1033 - sparse_categorical_accuracy: 0.8652 - val_loss: 9.2653 - val_sparse_categorical_accuracy: 0.3943\n","\n","Epoch 00029: val_loss improved from 9.35249 to 9.26526, saving model to bert-base-uncased2_180.h5\n","Epoch 30/80\n","107/107 [==============================] - 23s 216ms/step - loss: 0.9192 - sparse_categorical_accuracy: 0.8951 - val_loss: 9.2093 - val_sparse_categorical_accuracy: 0.4003\n","\n","Epoch 00030: val_loss improved from 9.26526 to 9.20930, saving model to bert-base-uncased2_180.h5\n","Epoch 31/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.7909 - sparse_categorical_accuracy: 0.9176 - val_loss: 9.1157 - val_sparse_categorical_accuracy: 0.4082\n","\n","Epoch 00031: val_loss improved from 9.20930 to 9.11568, saving model to bert-base-uncased2_180.h5\n","Epoch 32/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.6694 - sparse_categorical_accuracy: 0.9386 - val_loss: 9.0825 - val_sparse_categorical_accuracy: 0.4134\n","\n","Epoch 00032: val_loss improved from 9.11568 to 9.08247, saving model to bert-base-uncased2_180.h5\n","Epoch 33/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.5814 - sparse_categorical_accuracy: 0.9523 - val_loss: 9.0214 - val_sparse_categorical_accuracy: 0.4187\n","\n","Epoch 00033: val_loss improved from 9.08247 to 9.02138, saving model to bert-base-uncased2_180.h5\n","Epoch 34/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.4931 - sparse_categorical_accuracy: 0.9635 - val_loss: 8.9818 - val_sparse_categorical_accuracy: 0.4203\n","\n","Epoch 00034: val_loss improved from 9.02138 to 8.98175, saving model to bert-base-uncased2_180.h5\n","Epoch 35/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.4314 - sparse_categorical_accuracy: 0.9723 - val_loss: 8.9401 - val_sparse_categorical_accuracy: 0.4251\n","\n","Epoch 00035: val_loss improved from 8.98175 to 8.94008, saving model to bert-base-uncased2_180.h5\n","Epoch 36/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.3909 - sparse_categorical_accuracy: 0.9766 - val_loss: 8.8861 - val_sparse_categorical_accuracy: 0.4266\n","\n","Epoch 00036: val_loss improved from 8.94008 to 8.88609, saving model to bert-base-uncased2_180.h5\n","Epoch 37/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.3344 - sparse_categorical_accuracy: 0.9828 - val_loss: 8.8878 - val_sparse_categorical_accuracy: 0.4292\n","\n","Epoch 00037: val_loss did not improve from 8.88609\n","Epoch 38/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.3201 - sparse_categorical_accuracy: 0.9831 - val_loss: 8.8597 - val_sparse_categorical_accuracy: 0.4305\n","\n","Epoch 00038: val_loss improved from 8.88609 to 8.85974, saving model to bert-base-uncased2_180.h5\n","Epoch 39/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2704 - sparse_categorical_accuracy: 0.9861 - val_loss: 8.8309 - val_sparse_categorical_accuracy: 0.4353\n","\n","Epoch 00039: val_loss improved from 8.85974 to 8.83091, saving model to bert-base-uncased2_180.h5\n","Epoch 40/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.2703 - sparse_categorical_accuracy: 0.9855 - val_loss: 8.8103 - val_sparse_categorical_accuracy: 0.4375\n","\n","Epoch 00040: val_loss improved from 8.83091 to 8.81028, saving model to bert-base-uncased2_180.h5\n","Epoch 41/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2315 - sparse_categorical_accuracy: 0.9893 - val_loss: 8.8255 - val_sparse_categorical_accuracy: 0.4378\n","\n","Epoch 00041: val_loss did not improve from 8.81028\n","Epoch 42/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2374 - sparse_categorical_accuracy: 0.9886 - val_loss: 8.7843 - val_sparse_categorical_accuracy: 0.4407\n","\n","Epoch 00042: val_loss improved from 8.81028 to 8.78430, saving model to bert-base-uncased2_180.h5\n","Epoch 43/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2192 - sparse_categorical_accuracy: 0.9895 - val_loss: 8.7720 - val_sparse_categorical_accuracy: 0.4432\n","\n","Epoch 00043: val_loss improved from 8.78430 to 8.77204, saving model to bert-base-uncased2_180.h5\n","Epoch 44/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9910 - val_loss: 8.7699 - val_sparse_categorical_accuracy: 0.4464\n","\n","Epoch 00044: val_loss improved from 8.77204 to 8.76988, saving model to bert-base-uncased2_180.h5\n","Epoch 45/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1868 - sparse_categorical_accuracy: 0.9908 - val_loss: 8.7797 - val_sparse_categorical_accuracy: 0.4467\n","\n","Epoch 00045: val_loss did not improve from 8.76988\n","Epoch 46/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1857 - sparse_categorical_accuracy: 0.9914 - val_loss: 8.7642 - val_sparse_categorical_accuracy: 0.4486\n","\n","Epoch 00046: val_loss improved from 8.76988 to 8.76421, saving model to bert-base-uncased2_180.h5\n","Epoch 47/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2055 - sparse_categorical_accuracy: 0.9905 - val_loss: 8.7273 - val_sparse_categorical_accuracy: 0.4498\n","\n","Epoch 00047: val_loss improved from 8.76421 to 8.72735, saving model to bert-base-uncased2_180.h5\n","Epoch 48/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1853 - sparse_categorical_accuracy: 0.9914 - val_loss: 8.7539 - val_sparse_categorical_accuracy: 0.4521\n","\n","Epoch 00048: val_loss did not improve from 8.72735\n","Epoch 49/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1810 - sparse_categorical_accuracy: 0.9906 - val_loss: 8.7230 - val_sparse_categorical_accuracy: 0.4531\n","\n","Epoch 00049: val_loss improved from 8.72735 to 8.72298, saving model to bert-base-uncased2_180.h5\n","Epoch 50/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9923 - val_loss: 8.7170 - val_sparse_categorical_accuracy: 0.4549\n","\n","Epoch 00050: val_loss improved from 8.72298 to 8.71702, saving model to bert-base-uncased2_180.h5\n","Epoch 51/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1531 - sparse_categorical_accuracy: 0.9920 - val_loss: 8.7117 - val_sparse_categorical_accuracy: 0.4546\n","\n","Epoch 00051: val_loss improved from 8.71702 to 8.71174, saving model to bert-base-uncased2_180.h5\n","Epoch 52/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1393 - sparse_categorical_accuracy: 0.9930 - val_loss: 8.7079 - val_sparse_categorical_accuracy: 0.4562\n","\n","Epoch 00052: val_loss improved from 8.71174 to 8.70793, saving model to bert-base-uncased2_180.h5\n","Epoch 53/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1557 - sparse_categorical_accuracy: 0.9915 - val_loss: 8.7178 - val_sparse_categorical_accuracy: 0.4562\n","\n","Epoch 00053: val_loss did not improve from 8.70793\n","Epoch 54/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1527 - sparse_categorical_accuracy: 0.9926 - val_loss: 8.7110 - val_sparse_categorical_accuracy: 0.4558\n","\n","Epoch 00054: val_loss did not improve from 8.70793\n","Epoch 55/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9931 - val_loss: 8.6939 - val_sparse_categorical_accuracy: 0.4588\n","\n","Epoch 00055: val_loss improved from 8.70793 to 8.69391, saving model to bert-base-uncased2_180.h5\n","Epoch 56/80\n","107/107 [==============================] - 22s 207ms/step - loss: 0.1290 - sparse_categorical_accuracy: 0.9932 - val_loss: 8.7086 - val_sparse_categorical_accuracy: 0.4585\n","\n","Epoch 00056: val_loss did not improve from 8.69391\n","Epoch 57/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.1318 - sparse_categorical_accuracy: 0.9926 - val_loss: 8.6993 - val_sparse_categorical_accuracy: 0.4599\n","\n","Epoch 00057: val_loss did not improve from 8.69391\n","Epoch 58/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1454 - sparse_categorical_accuracy: 0.9922 - val_loss: 8.6791 - val_sparse_categorical_accuracy: 0.4622\n","\n","Epoch 00058: val_loss improved from 8.69391 to 8.67907, saving model to bert-base-uncased2_180.h5\n","Epoch 59/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1201 - sparse_categorical_accuracy: 0.9940 - val_loss: 8.6847 - val_sparse_categorical_accuracy: 0.4613\n","\n","Epoch 00059: val_loss did not improve from 8.67907\n","Epoch 60/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1320 - sparse_categorical_accuracy: 0.9928 - val_loss: 8.6878 - val_sparse_categorical_accuracy: 0.4601\n","\n","Epoch 00060: val_loss did not improve from 8.67907\n","Epoch 61/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1420 - sparse_categorical_accuracy: 0.9921 - val_loss: 8.6731 - val_sparse_categorical_accuracy: 0.4628\n","\n","Epoch 00061: val_loss improved from 8.67907 to 8.67306, saving model to bert-base-uncased2_180.h5\n","Epoch 62/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1203 - sparse_categorical_accuracy: 0.9934 - val_loss: 8.6720 - val_sparse_categorical_accuracy: 0.4632\n","\n","Epoch 00062: val_loss improved from 8.67306 to 8.67198, saving model to bert-base-uncased2_180.h5\n","Epoch 63/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1323 - sparse_categorical_accuracy: 0.9925 - val_loss: 8.6691 - val_sparse_categorical_accuracy: 0.4641\n","\n","Epoch 00063: val_loss improved from 8.67198 to 8.66913, saving model to bert-base-uncased2_180.h5\n","Epoch 64/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1223 - sparse_categorical_accuracy: 0.9930 - val_loss: 8.6416 - val_sparse_categorical_accuracy: 0.4658\n","\n","Epoch 00064: val_loss improved from 8.66913 to 8.64158, saving model to bert-base-uncased2_180.h5\n","Epoch 65/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1227 - sparse_categorical_accuracy: 0.9936 - val_loss: 8.6351 - val_sparse_categorical_accuracy: 0.4660\n","\n","Epoch 00065: val_loss improved from 8.64158 to 8.63512, saving model to bert-base-uncased2_180.h5\n","Epoch 66/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9934 - val_loss: 8.6548 - val_sparse_categorical_accuracy: 0.4666\n","\n","Epoch 00066: val_loss did not improve from 8.63512\n","Epoch 67/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1141 - sparse_categorical_accuracy: 0.9935 - val_loss: 8.6611 - val_sparse_categorical_accuracy: 0.4670\n","\n","Epoch 00067: val_loss did not improve from 8.63512\n","Epoch 68/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1338 - sparse_categorical_accuracy: 0.9917 - val_loss: 8.6822 - val_sparse_categorical_accuracy: 0.4604\n","\n","Epoch 00068: val_loss did not improve from 8.63512\n","Epoch 69/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1354 - sparse_categorical_accuracy: 0.9917 - val_loss: 8.7285 - val_sparse_categorical_accuracy: 0.4585\n","\n","Epoch 00069: val_loss did not improve from 8.63512\n","Epoch 70/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1309 - sparse_categorical_accuracy: 0.9917 - val_loss: 8.7070 - val_sparse_categorical_accuracy: 0.4626\n","\n","Epoch 00070: val_loss did not improve from 8.63512\n","Epoch 71/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1504 - sparse_categorical_accuracy: 0.9900 - val_loss: 8.7113 - val_sparse_categorical_accuracy: 0.4644\n","\n","Epoch 00071: val_loss did not improve from 8.63512\n","Epoch 72/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1230 - sparse_categorical_accuracy: 0.9931 - val_loss: 8.6985 - val_sparse_categorical_accuracy: 0.4618\n","\n","Epoch 00072: val_loss did not improve from 8.63512\n","Epoch 73/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9912 - val_loss: 8.7376 - val_sparse_categorical_accuracy: 0.4612\n","\n","Epoch 00073: val_loss did not improve from 8.63512\n","Epoch 74/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1385 - sparse_categorical_accuracy: 0.9910 - val_loss: 8.7235 - val_sparse_categorical_accuracy: 0.4638\n","\n","Epoch 00074: val_loss did not improve from 8.63512\n","Epoch 75/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1426 - sparse_categorical_accuracy: 0.9915 - val_loss: 8.6961 - val_sparse_categorical_accuracy: 0.4661\n","\n","Epoch 00075: val_loss did not improve from 8.63512\n","Epoch 00075: early stopping\n","model training for 2 is done\n"]},{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["training for fold 3\n","Epoch 1/80\n","107/107 [==============================] - 165s 777ms/step - loss: 24.0790 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.6930 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00001: val_loss improved from inf to 22.69299, saving model to bert-base-uncased3_180.h5\n","Epoch 2/80\n","107/107 [==============================] - 22s 204ms/step - loss: 22.4808 - sparse_categorical_accuracy: 0.0010 - val_loss: 20.6945 - val_sparse_categorical_accuracy: 0.0393\n","\n","Epoch 00002: val_loss improved from 22.69299 to 20.69453, saving model to bert-base-uncased3_180.h5\n","Epoch 3/80\n","107/107 [==============================] - 22s 204ms/step - loss: 20.4076 - sparse_categorical_accuracy: 0.0103 - val_loss: 19.2076 - val_sparse_categorical_accuracy: 0.0543\n","\n","Epoch 00003: val_loss improved from 20.69453 to 19.20756, saving model to bert-base-uncased3_180.h5\n","Epoch 4/80\n","107/107 [==============================] - 22s 203ms/step - loss: 18.5274 - sparse_categorical_accuracy: 0.0246 - val_loss: 17.9953 - val_sparse_categorical_accuracy: 0.0704\n","\n","Epoch 00004: val_loss improved from 19.20756 to 17.99531, saving model to bert-base-uncased3_180.h5\n","Epoch 5/80\n","107/107 [==============================] - 22s 204ms/step - loss: 16.9281 - sparse_categorical_accuracy: 0.0394 - val_loss: 16.9848 - val_sparse_categorical_accuracy: 0.0864\n","\n","Epoch 00005: val_loss improved from 17.99531 to 16.98479, saving model to bert-base-uncased3_180.h5\n","Epoch 6/80\n","107/107 [==============================] - 22s 204ms/step - loss: 15.5021 - sparse_categorical_accuracy: 0.0541 - val_loss: 16.1186 - val_sparse_categorical_accuracy: 0.1044\n","\n","Epoch 00006: val_loss improved from 16.98479 to 16.11861, saving model to bert-base-uncased3_180.h5\n","Epoch 7/80\n","107/107 [==============================] - 22s 203ms/step - loss: 14.1394 - sparse_categorical_accuracy: 0.0752 - val_loss: 15.4096 - val_sparse_categorical_accuracy: 0.1193\n","\n","Epoch 00007: val_loss improved from 16.11861 to 15.40964, saving model to bert-base-uncased3_180.h5\n","Epoch 8/80\n","107/107 [==============================] - 22s 204ms/step - loss: 12.9879 - sparse_categorical_accuracy: 0.0937 - val_loss: 14.7665 - val_sparse_categorical_accuracy: 0.1366\n","\n","Epoch 00008: val_loss improved from 15.40964 to 14.76645, saving model to bert-base-uncased3_180.h5\n","Epoch 9/80\n","107/107 [==============================] - 22s 204ms/step - loss: 11.8770 - sparse_categorical_accuracy: 0.1146 - val_loss: 14.1887 - val_sparse_categorical_accuracy: 0.1514\n","\n","Epoch 00009: val_loss improved from 14.76645 to 14.18873, saving model to bert-base-uncased3_180.h5\n","Epoch 10/80\n","107/107 [==============================] - 22s 204ms/step - loss: 10.8265 - sparse_categorical_accuracy: 0.1380 - val_loss: 13.6735 - val_sparse_categorical_accuracy: 0.1691\n","\n","Epoch 00010: val_loss improved from 14.18873 to 13.67347, saving model to bert-base-uncased3_180.h5\n","Epoch 11/80\n","107/107 [==============================] - 22s 203ms/step - loss: 9.8954 - sparse_categorical_accuracy: 0.1659 - val_loss: 13.2311 - val_sparse_categorical_accuracy: 0.1842\n","\n","Epoch 00011: val_loss improved from 13.67347 to 13.23110, saving model to bert-base-uncased3_180.h5\n","Epoch 12/80\n","107/107 [==============================] - 22s 205ms/step - loss: 9.0196 - sparse_categorical_accuracy: 0.1942 - val_loss: 12.8408 - val_sparse_categorical_accuracy: 0.1999\n","\n","Epoch 00012: val_loss improved from 13.23110 to 12.84078, saving model to bert-base-uncased3_180.h5\n","Epoch 13/80\n","107/107 [==============================] - 22s 204ms/step - loss: 8.2349 - sparse_categorical_accuracy: 0.2215 - val_loss: 12.4681 - val_sparse_categorical_accuracy: 0.2137\n","\n","Epoch 00013: val_loss improved from 12.84078 to 12.46805, saving model to bert-base-uncased3_180.h5\n","Epoch 14/80\n","107/107 [==============================] - 22s 203ms/step - loss: 7.4567 - sparse_categorical_accuracy: 0.2526 - val_loss: 12.1546 - val_sparse_categorical_accuracy: 0.2274\n","\n","Epoch 00014: val_loss improved from 12.46805 to 12.15464, saving model to bert-base-uncased3_180.h5\n","Epoch 15/80\n","107/107 [==============================] - 22s 204ms/step - loss: 6.7012 - sparse_categorical_accuracy: 0.2934 - val_loss: 11.8395 - val_sparse_categorical_accuracy: 0.2415\n","\n","Epoch 00015: val_loss improved from 12.15464 to 11.83947, saving model to bert-base-uncased3_180.h5\n","Epoch 16/80\n","107/107 [==============================] - 22s 204ms/step - loss: 5.9857 - sparse_categorical_accuracy: 0.3322 - val_loss: 11.5679 - val_sparse_categorical_accuracy: 0.2528\n","\n","Epoch 00016: val_loss improved from 11.83947 to 11.56794, saving model to bert-base-uncased3_180.h5\n","Epoch 17/80\n","107/107 [==============================] - 22s 204ms/step - loss: 5.4145 - sparse_categorical_accuracy: 0.3785 - val_loss: 11.3260 - val_sparse_categorical_accuracy: 0.2644\n","\n","Epoch 00017: val_loss improved from 11.56794 to 11.32602, saving model to bert-base-uncased3_180.h5\n","Epoch 18/80\n","107/107 [==============================] - 22s 204ms/step - loss: 4.8134 - sparse_categorical_accuracy: 0.4258 - val_loss: 11.0956 - val_sparse_categorical_accuracy: 0.2750\n","\n","Epoch 00018: val_loss improved from 11.32602 to 11.09558, saving model to bert-base-uncased3_180.h5\n","Epoch 19/80\n","107/107 [==============================] - 22s 204ms/step - loss: 4.2645 - sparse_categorical_accuracy: 0.4726 - val_loss: 10.8961 - val_sparse_categorical_accuracy: 0.2882\n","\n","Epoch 00019: val_loss improved from 11.09558 to 10.89615, saving model to bert-base-uncased3_180.h5\n","Epoch 20/80\n","107/107 [==============================] - 22s 204ms/step - loss: 3.7880 - sparse_categorical_accuracy: 0.5180 - val_loss: 10.6988 - val_sparse_categorical_accuracy: 0.3000\n","\n","Epoch 00020: val_loss improved from 10.89615 to 10.69879, saving model to bert-base-uncased3_180.h5\n","Epoch 21/80\n","107/107 [==============================] - 22s 204ms/step - loss: 3.3482 - sparse_categorical_accuracy: 0.5661 - val_loss: 10.5449 - val_sparse_categorical_accuracy: 0.3073\n","\n","Epoch 00021: val_loss improved from 10.69879 to 10.54487, saving model to bert-base-uncased3_180.h5\n","Epoch 22/80\n","107/107 [==============================] - 22s 204ms/step - loss: 2.9598 - sparse_categorical_accuracy: 0.6028 - val_loss: 10.3750 - val_sparse_categorical_accuracy: 0.3177\n","\n","Epoch 00022: val_loss improved from 10.54487 to 10.37499, saving model to bert-base-uncased3_180.h5\n","Epoch 23/80\n","107/107 [==============================] - 22s 204ms/step - loss: 2.5810 - sparse_categorical_accuracy: 0.6443 - val_loss: 10.2193 - val_sparse_categorical_accuracy: 0.3282\n","\n","Epoch 00023: val_loss improved from 10.37499 to 10.21928, saving model to bert-base-uncased3_180.h5\n","Epoch 24/80\n","107/107 [==============================] - 23s 218ms/step - loss: 2.2453 - sparse_categorical_accuracy: 0.6897 - val_loss: 10.0837 - val_sparse_categorical_accuracy: 0.3418\n","\n","Epoch 00024: val_loss improved from 10.21928 to 10.08370, saving model to bert-base-uncased3_180.h5\n","Epoch 25/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.9446 - sparse_categorical_accuracy: 0.7245 - val_loss: 9.9570 - val_sparse_categorical_accuracy: 0.3488\n","\n","Epoch 00025: val_loss improved from 10.08370 to 9.95703, saving model to bert-base-uncased3_180.h5\n","Epoch 26/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.6931 - sparse_categorical_accuracy: 0.7634 - val_loss: 9.8161 - val_sparse_categorical_accuracy: 0.3604\n","\n","Epoch 00026: val_loss improved from 9.95703 to 9.81612, saving model to bert-base-uncased3_180.h5\n","Epoch 27/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.4772 - sparse_categorical_accuracy: 0.8006 - val_loss: 9.7129 - val_sparse_categorical_accuracy: 0.3718\n","\n","Epoch 00027: val_loss improved from 9.81612 to 9.71292, saving model to bert-base-uncased3_180.h5\n","Epoch 28/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.2548 - sparse_categorical_accuracy: 0.8400 - val_loss: 9.6092 - val_sparse_categorical_accuracy: 0.3774\n","\n","Epoch 00028: val_loss improved from 9.71292 to 9.60923, saving model to bert-base-uncased3_180.h5\n","Epoch 29/80\n","107/107 [==============================] - 22s 204ms/step - loss: 1.0769 - sparse_categorical_accuracy: 0.8684 - val_loss: 9.5486 - val_sparse_categorical_accuracy: 0.3841\n","\n","Epoch 00029: val_loss improved from 9.60923 to 9.54855, saving model to bert-base-uncased3_180.h5\n","Epoch 30/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.9121 - sparse_categorical_accuracy: 0.8960 - val_loss: 9.4606 - val_sparse_categorical_accuracy: 0.3886\n","\n","Epoch 00030: val_loss improved from 9.54855 to 9.46064, saving model to bert-base-uncased3_180.h5\n","Epoch 31/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.7653 - sparse_categorical_accuracy: 0.9206 - val_loss: 9.3991 - val_sparse_categorical_accuracy: 0.3965\n","\n","Epoch 00031: val_loss improved from 9.46064 to 9.39910, saving model to bert-base-uncased3_180.h5\n","Epoch 32/80\n","107/107 [==============================] - 22s 210ms/step - loss: 0.6718 - sparse_categorical_accuracy: 0.9383 - val_loss: 9.3583 - val_sparse_categorical_accuracy: 0.4018\n","\n","Epoch 00032: val_loss improved from 9.39910 to 9.35828, saving model to bert-base-uncased3_180.h5\n","Epoch 33/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.5695 - sparse_categorical_accuracy: 0.9544 - val_loss: 9.3122 - val_sparse_categorical_accuracy: 0.4039\n","\n","Epoch 00033: val_loss improved from 9.35828 to 9.31223, saving model to bert-base-uncased3_180.h5\n","Epoch 34/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.5189 - sparse_categorical_accuracy: 0.9609 - val_loss: 9.2655 - val_sparse_categorical_accuracy: 0.4091\n","\n","Epoch 00034: val_loss improved from 9.31223 to 9.26546, saving model to bert-base-uncased3_180.h5\n","Epoch 35/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.4361 - sparse_categorical_accuracy: 0.9696 - val_loss: 9.2202 - val_sparse_categorical_accuracy: 0.4131\n","\n","Epoch 00035: val_loss improved from 9.26546 to 9.22018, saving model to bert-base-uncased3_180.h5\n","Epoch 36/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.3736 - sparse_categorical_accuracy: 0.9774 - val_loss: 9.2050 - val_sparse_categorical_accuracy: 0.4153\n","\n","Epoch 00036: val_loss improved from 9.22018 to 9.20496, saving model to bert-base-uncased3_180.h5\n","Epoch 37/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.3271 - sparse_categorical_accuracy: 0.9820 - val_loss: 9.1699 - val_sparse_categorical_accuracy: 0.4194\n","\n","Epoch 00037: val_loss improved from 9.20496 to 9.16987, saving model to bert-base-uncased3_180.h5\n","Epoch 38/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.3062 - sparse_categorical_accuracy: 0.9837 - val_loss: 9.1543 - val_sparse_categorical_accuracy: 0.4226\n","\n","Epoch 00038: val_loss improved from 9.16987 to 9.15428, saving model to bert-base-uncased3_180.h5\n","Epoch 39/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2921 - sparse_categorical_accuracy: 0.9844 - val_loss: 9.1318 - val_sparse_categorical_accuracy: 0.4235\n","\n","Epoch 00039: val_loss improved from 9.15428 to 9.13180, saving model to bert-base-uncased3_180.h5\n","Epoch 40/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2611 - sparse_categorical_accuracy: 0.9858 - val_loss: 9.1331 - val_sparse_categorical_accuracy: 0.4293\n","\n","Epoch 00040: val_loss did not improve from 9.13180\n","Epoch 41/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.2550 - sparse_categorical_accuracy: 0.9862 - val_loss: 9.1167 - val_sparse_categorical_accuracy: 0.4282\n","\n","Epoch 00041: val_loss improved from 9.13180 to 9.11668, saving model to bert-base-uncased3_180.h5\n","Epoch 42/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2238 - sparse_categorical_accuracy: 0.9887 - val_loss: 9.1062 - val_sparse_categorical_accuracy: 0.4318\n","\n","Epoch 00042: val_loss improved from 9.11668 to 9.10624, saving model to bert-base-uncased3_180.h5\n","Epoch 43/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.2060 - sparse_categorical_accuracy: 0.9898 - val_loss: 9.0785 - val_sparse_categorical_accuracy: 0.4330\n","\n","Epoch 00043: val_loss improved from 9.10624 to 9.07847, saving model to bert-base-uncased3_180.h5\n","Epoch 44/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2011 - sparse_categorical_accuracy: 0.9907 - val_loss: 9.0694 - val_sparse_categorical_accuracy: 0.4343\n","\n","Epoch 00044: val_loss improved from 9.07847 to 9.06939, saving model to bert-base-uncased3_180.h5\n","Epoch 45/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.2037 - sparse_categorical_accuracy: 0.9902 - val_loss: 9.0485 - val_sparse_categorical_accuracy: 0.4333\n","\n","Epoch 00045: val_loss improved from 9.06939 to 9.04847, saving model to bert-base-uncased3_180.h5\n","Epoch 46/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1870 - sparse_categorical_accuracy: 0.9913 - val_loss: 9.0379 - val_sparse_categorical_accuracy: 0.4374\n","\n","Epoch 00046: val_loss improved from 9.04847 to 9.03786, saving model to bert-base-uncased3_180.h5\n","Epoch 47/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1707 - sparse_categorical_accuracy: 0.9922 - val_loss: 9.0286 - val_sparse_categorical_accuracy: 0.4388\n","\n","Epoch 00047: val_loss improved from 9.03786 to 9.02863, saving model to bert-base-uncased3_180.h5\n","Epoch 48/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1557 - sparse_categorical_accuracy: 0.9924 - val_loss: 9.0281 - val_sparse_categorical_accuracy: 0.4396\n","\n","Epoch 00048: val_loss improved from 9.02863 to 9.02806, saving model to bert-base-uncased3_180.h5\n","Epoch 49/80\n","107/107 [==============================] - 22s 209ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9920 - val_loss: 9.0154 - val_sparse_categorical_accuracy: 0.4422\n","\n","Epoch 00049: val_loss improved from 9.02806 to 9.01543, saving model to bert-base-uncased3_180.h5\n","Epoch 50/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1516 - sparse_categorical_accuracy: 0.9924 - val_loss: 9.0128 - val_sparse_categorical_accuracy: 0.4418\n","\n","Epoch 00050: val_loss improved from 9.01543 to 9.01284, saving model to bert-base-uncased3_180.h5\n","Epoch 51/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9926 - val_loss: 9.0278 - val_sparse_categorical_accuracy: 0.4419\n","\n","Epoch 00051: val_loss did not improve from 9.01284\n","Epoch 52/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.1357 - sparse_categorical_accuracy: 0.9935 - val_loss: 8.9985 - val_sparse_categorical_accuracy: 0.4432\n","\n","Epoch 00052: val_loss improved from 9.01284 to 8.99854, saving model to bert-base-uncased3_180.h5\n","Epoch 53/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9923 - val_loss: 8.9936 - val_sparse_categorical_accuracy: 0.4445\n","\n","Epoch 00053: val_loss improved from 8.99854 to 8.99363, saving model to bert-base-uncased3_180.h5\n","Epoch 54/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1395 - sparse_categorical_accuracy: 0.9930 - val_loss: 8.9808 - val_sparse_categorical_accuracy: 0.4442\n","\n","Epoch 00054: val_loss improved from 8.99363 to 8.98084, saving model to bert-base-uncased3_180.h5\n","Epoch 55/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1441 - sparse_categorical_accuracy: 0.9926 - val_loss: 8.9903 - val_sparse_categorical_accuracy: 0.4448\n","\n","Epoch 00055: val_loss did not improve from 8.98084\n","Epoch 56/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.1336 - sparse_categorical_accuracy: 0.9935 - val_loss: 9.0151 - val_sparse_categorical_accuracy: 0.4457\n","\n","Epoch 00056: val_loss did not improve from 8.98084\n","Epoch 57/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1425 - sparse_categorical_accuracy: 0.9923 - val_loss: 8.9873 - val_sparse_categorical_accuracy: 0.4463\n","\n","Epoch 00057: val_loss did not improve from 8.98084\n","Epoch 58/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1342 - sparse_categorical_accuracy: 0.9936 - val_loss: 8.9825 - val_sparse_categorical_accuracy: 0.4485\n","\n","Epoch 00058: val_loss did not improve from 8.98084\n","Epoch 59/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1228 - sparse_categorical_accuracy: 0.9934 - val_loss: 9.0163 - val_sparse_categorical_accuracy: 0.4463\n","\n","Epoch 00059: val_loss did not improve from 8.98084\n","Epoch 60/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1313 - sparse_categorical_accuracy: 0.9928 - val_loss: 8.9629 - val_sparse_categorical_accuracy: 0.4458\n","\n","Epoch 00060: val_loss improved from 8.98084 to 8.96293, saving model to bert-base-uncased3_180.h5\n","Epoch 61/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1318 - sparse_categorical_accuracy: 0.9927 - val_loss: 8.9622 - val_sparse_categorical_accuracy: 0.4457\n","\n","Epoch 00061: val_loss improved from 8.96293 to 8.96221, saving model to bert-base-uncased3_180.h5\n","Epoch 62/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1240 - sparse_categorical_accuracy: 0.9933 - val_loss: 8.9759 - val_sparse_categorical_accuracy: 0.4488\n","\n","Epoch 00062: val_loss did not improve from 8.96221\n","Epoch 63/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1145 - sparse_categorical_accuracy: 0.9940 - val_loss: 8.9417 - val_sparse_categorical_accuracy: 0.4504\n","\n","Epoch 00063: val_loss improved from 8.96221 to 8.94175, saving model to bert-base-uncased3_180.h5\n","Epoch 64/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1129 - sparse_categorical_accuracy: 0.9936 - val_loss: 8.9617 - val_sparse_categorical_accuracy: 0.4514\n","\n","Epoch 00064: val_loss did not improve from 8.94175\n","Epoch 65/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.9943 - val_loss: 8.9599 - val_sparse_categorical_accuracy: 0.4528\n","\n","Epoch 00065: val_loss did not improve from 8.94175\n","Epoch 66/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1204 - sparse_categorical_accuracy: 0.9931 - val_loss: 8.9521 - val_sparse_categorical_accuracy: 0.4528\n","\n","Epoch 00066: val_loss did not improve from 8.94175\n","Epoch 67/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9939 - val_loss: 8.9628 - val_sparse_categorical_accuracy: 0.4530\n","\n","Epoch 00067: val_loss did not improve from 8.94175\n","Epoch 68/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.1114 - sparse_categorical_accuracy: 0.9936 - val_loss: 8.9813 - val_sparse_categorical_accuracy: 0.4485\n","\n","Epoch 00068: val_loss did not improve from 8.94175\n","Epoch 69/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1244 - sparse_categorical_accuracy: 0.9924 - val_loss: 8.9876 - val_sparse_categorical_accuracy: 0.4472\n","\n","Epoch 00069: val_loss did not improve from 8.94175\n","Epoch 70/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9917 - val_loss: 9.0500 - val_sparse_categorical_accuracy: 0.4422\n","\n","Epoch 00070: val_loss did not improve from 8.94175\n","Epoch 71/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1525 - sparse_categorical_accuracy: 0.9905 - val_loss: 9.0012 - val_sparse_categorical_accuracy: 0.4496\n","\n","Epoch 00071: val_loss did not improve from 8.94175\n","Epoch 72/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1377 - sparse_categorical_accuracy: 0.9915 - val_loss: 8.9918 - val_sparse_categorical_accuracy: 0.4511\n","\n","Epoch 00072: val_loss did not improve from 8.94175\n","Epoch 73/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1126 - sparse_categorical_accuracy: 0.9930 - val_loss: 8.9830 - val_sparse_categorical_accuracy: 0.4489\n","\n","Epoch 00073: val_loss did not improve from 8.94175\n","Epoch 00073: early stopping\n","model training for 3 is done\n"]},{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["training for fold 4\n","Epoch 1/80\n","107/107 [==============================] - 168s 773ms/step - loss: 24.0845 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 22.8582 - val_sparse_categorical_accuracy: 0.0000e+00\n","\n","Epoch 00001: val_loss improved from inf to 22.85823, saving model to bert-base-uncased4_180.h5\n","Epoch 2/80\n","107/107 [==============================] - 22s 204ms/step - loss: 22.6516 - sparse_categorical_accuracy: 6.5273e-04 - val_loss: 20.9573 - val_sparse_categorical_accuracy: 0.0358\n","\n","Epoch 00002: val_loss improved from 22.85823 to 20.95729, saving model to bert-base-uncased4_180.h5\n","Epoch 3/80\n","107/107 [==============================] - 22s 204ms/step - loss: 20.6112 - sparse_categorical_accuracy: 0.0095 - val_loss: 19.4571 - val_sparse_categorical_accuracy: 0.0492\n","\n","Epoch 00003: val_loss improved from 20.95729 to 19.45710, saving model to bert-base-uncased4_180.h5\n","Epoch 4/80\n","107/107 [==============================] - 22s 203ms/step - loss: 18.7604 - sparse_categorical_accuracy: 0.0223 - val_loss: 18.2149 - val_sparse_categorical_accuracy: 0.0698\n","\n","Epoch 00004: val_loss improved from 19.45710 to 18.21486, saving model to bert-base-uncased4_180.h5\n","Epoch 5/80\n","107/107 [==============================] - 22s 204ms/step - loss: 17.1458 - sparse_categorical_accuracy: 0.0364 - val_loss: 17.2100 - val_sparse_categorical_accuracy: 0.0832\n","\n","Epoch 00005: val_loss improved from 18.21486 to 17.20998, saving model to bert-base-uncased4_180.h5\n","Epoch 6/80\n","107/107 [==============================] - 22s 204ms/step - loss: 15.6220 - sparse_categorical_accuracy: 0.0553 - val_loss: 16.3353 - val_sparse_categorical_accuracy: 0.1000\n","\n","Epoch 00006: val_loss improved from 17.20998 to 16.33529, saving model to bert-base-uncased4_180.h5\n","Epoch 7/80\n","107/107 [==============================] - 22s 203ms/step - loss: 14.2823 - sparse_categorical_accuracy: 0.0768 - val_loss: 15.5967 - val_sparse_categorical_accuracy: 0.1182\n","\n","Epoch 00007: val_loss improved from 16.33529 to 15.59670, saving model to bert-base-uncased4_180.h5\n","Epoch 8/80\n","107/107 [==============================] - 22s 204ms/step - loss: 13.1448 - sparse_categorical_accuracy: 0.0934 - val_loss: 14.9493 - val_sparse_categorical_accuracy: 0.1355\n","\n","Epoch 00008: val_loss improved from 15.59670 to 14.94930, saving model to bert-base-uncased4_180.h5\n","Epoch 9/80\n","107/107 [==============================] - 22s 203ms/step - loss: 12.0604 - sparse_categorical_accuracy: 0.1116 - val_loss: 14.3673 - val_sparse_categorical_accuracy: 0.1521\n","\n","Epoch 00009: val_loss improved from 14.94930 to 14.36728, saving model to bert-base-uncased4_180.h5\n","Epoch 10/80\n","107/107 [==============================] - 22s 205ms/step - loss: 11.0126 - sparse_categorical_accuracy: 0.1318 - val_loss: 13.8668 - val_sparse_categorical_accuracy: 0.1679\n","\n","Epoch 00010: val_loss improved from 14.36728 to 13.86676, saving model to bert-base-uncased4_180.h5\n","Epoch 11/80\n","107/107 [==============================] - 22s 204ms/step - loss: 10.0841 - sparse_categorical_accuracy: 0.1572 - val_loss: 13.4064 - val_sparse_categorical_accuracy: 0.1801\n","\n","Epoch 00011: val_loss improved from 13.86676 to 13.40639, saving model to bert-base-uncased4_180.h5\n","Epoch 12/80\n","107/107 [==============================] - 22s 204ms/step - loss: 9.1911 - sparse_categorical_accuracy: 0.1838 - val_loss: 12.9750 - val_sparse_categorical_accuracy: 0.1958\n","\n","Epoch 00012: val_loss improved from 13.40639 to 12.97498, saving model to bert-base-uncased4_180.h5\n","Epoch 13/80\n","107/107 [==============================] - 22s 204ms/step - loss: 8.3333 - sparse_categorical_accuracy: 0.2146 - val_loss: 12.6109 - val_sparse_categorical_accuracy: 0.2134\n","\n","Epoch 00013: val_loss improved from 12.97498 to 12.61095, saving model to bert-base-uncased4_180.h5\n","Epoch 14/80\n","107/107 [==============================] - 22s 204ms/step - loss: 7.5807 - sparse_categorical_accuracy: 0.2477 - val_loss: 12.2846 - val_sparse_categorical_accuracy: 0.2273\n","\n","Epoch 00014: val_loss improved from 12.61095 to 12.28463, saving model to bert-base-uncased4_180.h5\n","Epoch 15/80\n","107/107 [==============================] - 22s 203ms/step - loss: 6.8786 - sparse_categorical_accuracy: 0.2805 - val_loss: 11.9755 - val_sparse_categorical_accuracy: 0.2407\n","\n","Epoch 00015: val_loss improved from 12.28463 to 11.97553, saving model to bert-base-uncased4_180.h5\n","Epoch 16/80\n","107/107 [==============================] - 22s 204ms/step - loss: 6.1695 - sparse_categorical_accuracy: 0.3249 - val_loss: 11.7269 - val_sparse_categorical_accuracy: 0.2499\n","\n","Epoch 00016: val_loss improved from 11.97553 to 11.72687, saving model to bert-base-uncased4_180.h5\n","Epoch 17/80\n","107/107 [==============================] - 22s 204ms/step - loss: 5.5252 - sparse_categorical_accuracy: 0.3692 - val_loss: 11.4698 - val_sparse_categorical_accuracy: 0.2599\n","\n","Epoch 00017: val_loss improved from 11.72687 to 11.46978, saving model to bert-base-uncased4_180.h5\n","Epoch 18/80\n","107/107 [==============================] - 22s 204ms/step - loss: 4.9449 - sparse_categorical_accuracy: 0.4193 - val_loss: 11.2231 - val_sparse_categorical_accuracy: 0.2695\n","\n","Epoch 00018: val_loss improved from 11.46978 to 11.22311, saving model to bert-base-uncased4_180.h5\n","Epoch 19/80\n","107/107 [==============================] - 22s 203ms/step - loss: 4.3914 - sparse_categorical_accuracy: 0.4646 - val_loss: 11.0369 - val_sparse_categorical_accuracy: 0.2800\n","\n","Epoch 00019: val_loss improved from 11.22311 to 11.03689, saving model to bert-base-uncased4_180.h5\n","Epoch 20/80\n","107/107 [==============================] - 22s 204ms/step - loss: 3.9242 - sparse_categorical_accuracy: 0.5088 - val_loss: 10.8356 - val_sparse_categorical_accuracy: 0.2908\n","\n","Epoch 00020: val_loss improved from 11.03689 to 10.83557, saving model to bert-base-uncased4_180.h5\n","Epoch 21/80\n","107/107 [==============================] - 22s 208ms/step - loss: 3.4341 - sparse_categorical_accuracy: 0.5581 - val_loss: 10.6570 - val_sparse_categorical_accuracy: 0.2980\n","\n","Epoch 00021: val_loss improved from 10.83557 to 10.65696, saving model to bert-base-uncased4_180.h5\n","Epoch 22/80\n","107/107 [==============================] - 22s 203ms/step - loss: 3.0379 - sparse_categorical_accuracy: 0.5979 - val_loss: 10.5053 - val_sparse_categorical_accuracy: 0.3089\n","\n","Epoch 00022: val_loss improved from 10.65696 to 10.50526, saving model to bert-base-uncased4_180.h5\n","Epoch 23/80\n","107/107 [==============================] - 22s 203ms/step - loss: 2.6291 - sparse_categorical_accuracy: 0.6451 - val_loss: 10.3486 - val_sparse_categorical_accuracy: 0.3218\n","\n","Epoch 00023: val_loss improved from 10.50526 to 10.34858, saving model to bert-base-uncased4_180.h5\n","Epoch 24/80\n","107/107 [==============================] - 22s 203ms/step - loss: 2.3490 - sparse_categorical_accuracy: 0.6788 - val_loss: 10.1935 - val_sparse_categorical_accuracy: 0.3293\n","\n","Epoch 00024: val_loss improved from 10.34858 to 10.19349, saving model to bert-base-uncased4_180.h5\n","Epoch 25/80\n","107/107 [==============================] - 22s 203ms/step - loss: 2.0370 - sparse_categorical_accuracy: 0.7183 - val_loss: 10.0715 - val_sparse_categorical_accuracy: 0.3409\n","\n","Epoch 00025: val_loss improved from 10.19349 to 10.07151, saving model to bert-base-uncased4_180.h5\n","Epoch 26/80\n","107/107 [==============================] - 22s 203ms/step - loss: 1.7640 - sparse_categorical_accuracy: 0.7541 - val_loss: 9.9427 - val_sparse_categorical_accuracy: 0.3515\n","\n","Epoch 00026: val_loss improved from 10.07151 to 9.94270, saving model to bert-base-uncased4_180.h5\n","Epoch 27/80\n","107/107 [==============================] - 22s 203ms/step - loss: 1.5185 - sparse_categorical_accuracy: 0.7924 - val_loss: 9.8352 - val_sparse_categorical_accuracy: 0.3606\n","\n","Epoch 00027: val_loss improved from 9.94270 to 9.83520, saving model to bert-base-uncased4_180.h5\n","Epoch 28/80\n","107/107 [==============================] - 22s 209ms/step - loss: 1.3386 - sparse_categorical_accuracy: 0.8216 - val_loss: 9.7161 - val_sparse_categorical_accuracy: 0.3664\n","\n","Epoch 00028: val_loss improved from 9.83520 to 9.71606, saving model to bert-base-uncased4_180.h5\n","Epoch 29/80\n","107/107 [==============================] - 22s 203ms/step - loss: 1.1500 - sparse_categorical_accuracy: 0.8530 - val_loss: 9.6240 - val_sparse_categorical_accuracy: 0.3784\n","\n","Epoch 00029: val_loss improved from 9.71606 to 9.62405, saving model to bert-base-uncased4_180.h5\n","Epoch 30/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.9482 - sparse_categorical_accuracy: 0.8910 - val_loss: 9.5398 - val_sparse_categorical_accuracy: 0.3834\n","\n","Epoch 00030: val_loss improved from 9.62405 to 9.53978, saving model to bert-base-uncased4_180.h5\n","Epoch 31/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.8317 - sparse_categorical_accuracy: 0.9134 - val_loss: 9.4994 - val_sparse_categorical_accuracy: 0.3877\n","\n","Epoch 00031: val_loss improved from 9.53978 to 9.49945, saving model to bert-base-uncased4_180.h5\n","Epoch 32/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.7252 - sparse_categorical_accuracy: 0.9315 - val_loss: 9.4318 - val_sparse_categorical_accuracy: 0.3959\n","\n","Epoch 00032: val_loss improved from 9.49945 to 9.43180, saving model to bert-base-uncased4_180.h5\n","Epoch 33/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.6109 - sparse_categorical_accuracy: 0.9497 - val_loss: 9.3807 - val_sparse_categorical_accuracy: 0.3966\n","\n","Epoch 00033: val_loss improved from 9.43180 to 9.38067, saving model to bert-base-uncased4_180.h5\n","Epoch 34/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.5362 - sparse_categorical_accuracy: 0.9593 - val_loss: 9.3244 - val_sparse_categorical_accuracy: 0.4048\n","\n","Epoch 00034: val_loss improved from 9.38067 to 9.32436, saving model to bert-base-uncased4_180.h5\n","Epoch 35/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.4747 - sparse_categorical_accuracy: 0.9682 - val_loss: 9.3128 - val_sparse_categorical_accuracy: 0.4058\n","\n","Epoch 00035: val_loss improved from 9.32436 to 9.31278, saving model to bert-base-uncased4_180.h5\n","Epoch 36/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.4358 - sparse_categorical_accuracy: 0.9724 - val_loss: 9.2645 - val_sparse_categorical_accuracy: 0.4123\n","\n","Epoch 00036: val_loss improved from 9.31278 to 9.26448, saving model to bert-base-uncased4_180.h5\n","Epoch 37/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.3588 - sparse_categorical_accuracy: 0.9789 - val_loss: 9.2164 - val_sparse_categorical_accuracy: 0.4161\n","\n","Epoch 00037: val_loss improved from 9.26448 to 9.21636, saving model to bert-base-uncased4_180.h5\n","Epoch 38/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.3417 - sparse_categorical_accuracy: 0.9821 - val_loss: 9.2090 - val_sparse_categorical_accuracy: 0.4171\n","\n","Epoch 00038: val_loss improved from 9.21636 to 9.20895, saving model to bert-base-uncased4_180.h5\n","Epoch 39/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.3033 - sparse_categorical_accuracy: 0.9847 - val_loss: 9.1944 - val_sparse_categorical_accuracy: 0.4201\n","\n","Epoch 00039: val_loss improved from 9.20895 to 9.19439, saving model to bert-base-uncased4_180.h5\n","Epoch 40/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.2940 - sparse_categorical_accuracy: 0.9840 - val_loss: 9.1804 - val_sparse_categorical_accuracy: 0.4204\n","\n","Epoch 00040: val_loss improved from 9.19439 to 9.18039, saving model to bert-base-uncased4_180.h5\n","Epoch 41/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2476 - sparse_categorical_accuracy: 0.9878 - val_loss: 9.1649 - val_sparse_categorical_accuracy: 0.4222\n","\n","Epoch 00041: val_loss improved from 9.18039 to 9.16486, saving model to bert-base-uncased4_180.h5\n","Epoch 42/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2521 - sparse_categorical_accuracy: 0.9871 - val_loss: 9.1281 - val_sparse_categorical_accuracy: 0.4234\n","\n","Epoch 00042: val_loss improved from 9.16486 to 9.12814, saving model to bert-base-uncased4_180.h5\n","Epoch 43/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2202 - sparse_categorical_accuracy: 0.9901 - val_loss: 9.1026 - val_sparse_categorical_accuracy: 0.4242\n","\n","Epoch 00043: val_loss improved from 9.12814 to 9.10259, saving model to bert-base-uncased4_180.h5\n","Epoch 44/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2077 - sparse_categorical_accuracy: 0.9894 - val_loss: 9.1214 - val_sparse_categorical_accuracy: 0.4274\n","\n","Epoch 00044: val_loss did not improve from 9.10259\n","Epoch 45/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2111 - sparse_categorical_accuracy: 0.9891 - val_loss: 9.0937 - val_sparse_categorical_accuracy: 0.4289\n","\n","Epoch 00045: val_loss improved from 9.10259 to 9.09373, saving model to bert-base-uncased4_180.h5\n","Epoch 46/80\n","107/107 [==============================] - 22s 209ms/step - loss: 0.1928 - sparse_categorical_accuracy: 0.9903 - val_loss: 9.0861 - val_sparse_categorical_accuracy: 0.4323\n","\n","Epoch 00046: val_loss improved from 9.09373 to 9.08605, saving model to bert-base-uncased4_180.h5\n","Epoch 47/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.2003 - sparse_categorical_accuracy: 0.9900 - val_loss: 9.0710 - val_sparse_categorical_accuracy: 0.4324\n","\n","Epoch 00047: val_loss improved from 9.08605 to 9.07103, saving model to bert-base-uncased4_180.h5\n","Epoch 48/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1940 - sparse_categorical_accuracy: 0.9911 - val_loss: 9.0667 - val_sparse_categorical_accuracy: 0.4328\n","\n","Epoch 00048: val_loss improved from 9.07103 to 9.06673, saving model to bert-base-uncased4_180.h5\n","Epoch 49/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1605 - sparse_categorical_accuracy: 0.9926 - val_loss: 9.0492 - val_sparse_categorical_accuracy: 0.4356\n","\n","Epoch 00049: val_loss improved from 9.06673 to 9.04916, saving model to bert-base-uncased4_180.h5\n","Epoch 50/80\n","107/107 [==============================] - 22s 205ms/step - loss: 0.1502 - sparse_categorical_accuracy: 0.9927 - val_loss: 9.0407 - val_sparse_categorical_accuracy: 0.4361\n","\n","Epoch 00050: val_loss improved from 9.04916 to 9.04068, saving model to bert-base-uncased4_180.h5\n","Epoch 51/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1736 - sparse_categorical_accuracy: 0.9913 - val_loss: 9.0815 - val_sparse_categorical_accuracy: 0.4355\n","\n","Epoch 00051: val_loss did not improve from 9.04068\n","Epoch 52/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1698 - sparse_categorical_accuracy: 0.9920 - val_loss: 9.0514 - val_sparse_categorical_accuracy: 0.4349\n","\n","Epoch 00052: val_loss did not improve from 9.04068\n","Epoch 53/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1626 - sparse_categorical_accuracy: 0.9919 - val_loss: 9.0431 - val_sparse_categorical_accuracy: 0.4350\n","\n","Epoch 00053: val_loss did not improve from 9.04068\n","Epoch 54/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1765 - sparse_categorical_accuracy: 0.9904 - val_loss: 9.0730 - val_sparse_categorical_accuracy: 0.4352\n","\n","Epoch 00054: val_loss did not improve from 9.04068\n","Epoch 55/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9921 - val_loss: 9.0560 - val_sparse_categorical_accuracy: 0.4368\n","\n","Epoch 00055: val_loss did not improve from 9.04068\n","Epoch 56/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1468 - sparse_categorical_accuracy: 0.9919 - val_loss: 9.0514 - val_sparse_categorical_accuracy: 0.4401\n","\n","Epoch 00056: val_loss did not improve from 9.04068\n","Epoch 57/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1452 - sparse_categorical_accuracy: 0.9922 - val_loss: 9.0436 - val_sparse_categorical_accuracy: 0.4409\n","\n","Epoch 00057: val_loss did not improve from 9.04068\n","Epoch 58/80\n","107/107 [==============================] - 22s 210ms/step - loss: 0.1402 - sparse_categorical_accuracy: 0.9924 - val_loss: 9.0244 - val_sparse_categorical_accuracy: 0.4401\n","\n","Epoch 00058: val_loss improved from 9.04068 to 9.02445, saving model to bert-base-uncased4_180.h5\n","Epoch 59/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1390 - sparse_categorical_accuracy: 0.9924 - val_loss: 9.0139 - val_sparse_categorical_accuracy: 0.4426\n","\n","Epoch 00059: val_loss improved from 9.02445 to 9.01391, saving model to bert-base-uncased4_180.h5\n","Epoch 60/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1589 - sparse_categorical_accuracy: 0.9911 - val_loss: 9.0048 - val_sparse_categorical_accuracy: 0.4419\n","\n","Epoch 00060: val_loss improved from 9.01391 to 9.00484, saving model to bert-base-uncased4_180.h5\n","Epoch 61/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1480 - sparse_categorical_accuracy: 0.9917 - val_loss: 9.0020 - val_sparse_categorical_accuracy: 0.4418\n","\n","Epoch 00061: val_loss improved from 9.00484 to 9.00202, saving model to bert-base-uncased4_180.h5\n","Epoch 62/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9926 - val_loss: 9.0043 - val_sparse_categorical_accuracy: 0.4445\n","\n","Epoch 00062: val_loss did not improve from 9.00202\n","Epoch 63/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1380 - sparse_categorical_accuracy: 0.9909 - val_loss: 9.0165 - val_sparse_categorical_accuracy: 0.4434\n","\n","Epoch 00063: val_loss did not improve from 9.00202\n","Epoch 64/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9917 - val_loss: 9.0356 - val_sparse_categorical_accuracy: 0.4418\n","\n","Epoch 00064: val_loss did not improve from 9.00202\n","Epoch 65/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1453 - sparse_categorical_accuracy: 0.9909 - val_loss: 9.0748 - val_sparse_categorical_accuracy: 0.4397\n","\n","Epoch 00065: val_loss did not improve from 9.00202\n","Epoch 66/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1360 - sparse_categorical_accuracy: 0.9916 - val_loss: 9.0602 - val_sparse_categorical_accuracy: 0.4393\n","\n","Epoch 00066: val_loss did not improve from 9.00202\n","Epoch 67/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1596 - sparse_categorical_accuracy: 0.9900 - val_loss: 9.0553 - val_sparse_categorical_accuracy: 0.4422\n","\n","Epoch 00067: val_loss did not improve from 9.00202\n","Epoch 68/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1695 - sparse_categorical_accuracy: 0.9891 - val_loss: 9.0478 - val_sparse_categorical_accuracy: 0.4410\n","\n","Epoch 00068: val_loss did not improve from 9.00202\n","Epoch 69/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1629 - sparse_categorical_accuracy: 0.9894 - val_loss: 9.0601 - val_sparse_categorical_accuracy: 0.4434\n","\n","Epoch 00069: val_loss did not improve from 9.00202\n","Epoch 70/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9927 - val_loss: 9.0032 - val_sparse_categorical_accuracy: 0.4454\n","\n","Epoch 00070: val_loss did not improve from 9.00202\n","Epoch 71/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1256 - sparse_categorical_accuracy: 0.9925 - val_loss: 8.9650 - val_sparse_categorical_accuracy: 0.4469\n","\n","Epoch 00071: val_loss improved from 9.00202 to 8.96500, saving model to bert-base-uncased4_180.h5\n","Epoch 72/80\n","107/107 [==============================] - 22s 208ms/step - loss: 0.1202 - sparse_categorical_accuracy: 0.9920 - val_loss: 8.9944 - val_sparse_categorical_accuracy: 0.4495\n","\n","Epoch 00072: val_loss did not improve from 8.96500\n","Epoch 73/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1346 - sparse_categorical_accuracy: 0.9912 - val_loss: 8.9903 - val_sparse_categorical_accuracy: 0.4489\n","\n","Epoch 00073: val_loss did not improve from 8.96500\n","Epoch 74/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1260 - sparse_categorical_accuracy: 0.9925 - val_loss: 9.0029 - val_sparse_categorical_accuracy: 0.4473\n","\n","Epoch 00074: val_loss did not improve from 8.96500\n","Epoch 75/80\n","107/107 [==============================] - 22s 203ms/step - loss: 0.1257 - sparse_categorical_accuracy: 0.9921 - val_loss: 8.9798 - val_sparse_categorical_accuracy: 0.4470\n","\n","Epoch 00075: val_loss did not improve from 8.96500\n","Epoch 76/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9933 - val_loss: 8.9384 - val_sparse_categorical_accuracy: 0.4539\n","\n","Epoch 00076: val_loss improved from 8.96500 to 8.93844, saving model to bert-base-uncased4_180.h5\n","Epoch 77/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1049 - sparse_categorical_accuracy: 0.9931 - val_loss: 8.9955 - val_sparse_categorical_accuracy: 0.4501\n","\n","Epoch 00077: val_loss did not improve from 8.93844\n","Epoch 78/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1202 - sparse_categorical_accuracy: 0.9922 - val_loss: 8.9974 - val_sparse_categorical_accuracy: 0.4504\n","\n","Epoch 00078: val_loss did not improve from 8.93844\n","Epoch 79/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1175 - sparse_categorical_accuracy: 0.9919 - val_loss: 8.9795 - val_sparse_categorical_accuracy: 0.4515\n","\n","Epoch 00079: val_loss did not improve from 8.93844\n","Epoch 80/80\n","107/107 [==============================] - 22s 204ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.9918 - val_loss: 9.0013 - val_sparse_categorical_accuracy: 0.4496\n","\n","Epoch 00080: val_loss did not improve from 8.93844\n","model training for 4 is done\n"]}],"source":["#for MAX_LENGTH in [120,180,250,270]:\n","    #print(f\"now runnig for max_length : {MAX_LENGTH}\")\n","for fold in range(5):\n","    train_data=df.loc[df['gfold']!=fold].reset_index(drop=True)\n","    test_data=df.loc[df['gfold']==fold].reset_index(drop=True)\n","    MODEL_INPUTS,MODEL_OUTPUTS=MAKE_MODEL_INPUTS(train_data)\n","    VALID_INPUTS,VALID_OUTPUTS=MAKE_MODEL_INPUTS(test_data)\n","    del train_data,test_data\n","    import gc\n","    gc.collect()\n","    tf.keras.backend.clear_session()\n","    with strategy.scope():\n","        input_ids=Input((MAX_LENGTH,),dtype=tf.int32)\n","        attention_mask=Input((MAX_LENGTH,),dtype=tf.int32)\n","        if PRE_TRAINED_NAME.startswith(\"bert\"):\n","            token_type_ids=Input((MAX_LENGTH,),dtype=tf.int32)\n","        ins=Input((),name=\"label_input\")\n","        if PRE_TRAINED_NAME.startswith(\"bert\"):\n","            pre_trained=TFBertModel.from_pretrained(PRE_TRAINED_NAME,output_hidden_states=True)\n","            pre_outputs=pre_trained({\"input_ids\":input_ids\n","                                     ,\"attention_mask\":attention_mask\n","                                    ,\"token_type_ids\":token_type_ids})\n","        else:\n","            pre_trained=TFRobertaModel.from_pretrained(PRE_TRAINED_NAME,output_hidden_states=True)\n","            pre_outputs=pre_trained({\"input_ids\":input_ids\n","                                     ,\"attention_mask\":attention_mask})\n","        hidden_layers=[]\n","        k=0\n","        for i in reversed(range(len(pre_outputs['hidden_states']))):\n","            if k<4:\n","                hidden_layers.append(pre_outputs['hidden_states'][i])\n","                k+=1\n","            else:\n","                break\n","        x=tf.keras.layers.Concatenate()(hidden_layers)[:,0,:]\n","        x=Dense(720)(x)\n","        arc_layer=ARCFACE_LAYER()\n","        x=arc_layer([x,ins])\n","        outs=tf.keras.layers.Softmax()(x)\n","        if PRE_TRAINED_NAME.startswith(\"bert\"):\n","            model=Model(inputs=({\"input_ids\":input_ids,\"attention_mask\":attention_mask,\n","                                \"token_type_ids\":token_type_ids},ins),outputs=outs)\n","        else:\n","            model=Model(inputs=({\"input_ids\":input_ids,\"attention_mask\":attention_mask},ins),outputs=outs)\n","        print(f\"training for fold {fold}\")\n","        if fold==0:\n","            print(model.summary())\n","        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n","            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n","    NUM_TRAIN_STEPS=train_steps[fold]\n","    NUM_VALID_STEPS=valid_steps[fold]\n","    early=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",mode=\"min\",verbose=1,patience=10)\n","    saver=tf.keras.callbacks.ModelCheckpoint(filepath=PRE_TRAINED_NAME+f\"{fold}_{MAX_LENGTH}.h5\",\n","                                     monitor=\"val_loss\",mode=\"min\",save_best_only=True,\n","                                     save_weights_only=True,verbose=1)\n","    model.fit(MODEL_INPUTS,MODEL_OUTPUTS,\n","              validation_data=(VALID_INPUTS,VALID_OUTPUTS),epochs=80,\n","              callbacks=[early,saver],steps_per_epoch=NUM_TRAIN_STEPS,\n","             validation_steps=NUM_VALID_STEPS)\n","    print(f\"model training for {fold} is done\")\n","    del model,MODEL_INPUTS,MODEL_OUTPUTS,VALID_INPUTS,VALID_OUTPUTS\n","    import gc\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["9.07633,8.76228,8.63512,8.94175,8.93844"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-06-28T15:35:59.748174Z","iopub.status.idle":"2022-06-28T15:35:59.748498Z","shell.execute_reply":"2022-06-28T15:35:59.748347Z","shell.execute_reply.started":"2022-06-28T15:35:59.748331Z"},"trusted":true},"outputs":[],"source":["for 40 epochs\n","#Bert\n","base\n","3e-5\n","hidden states\n","512->10.57901\n","720->10.73882\n","pooler->\n","512->11.51173\n","no dense->20.94596\n","##########################\n","5e-5\n","hidden states\n","512->10.01861\n","720->9.84583\n","#########\n","Roberta\n","3e-4 15.29412\n","3e-5\n","512->12.12880\n","720->\n","1e-5\n","512->16.21013\n","720->\n","5e-5\n","512->11.14457\n","720->11.04617\n","########\n","XLnet(hidden states not good)\n","2e-5\n","with token_type->13.98930\n","without token_type->14.00980\n","##############################################################################\n","bert and roberta with 720,5e-5\n","Roberta\n","max_length->120,180,250,270 (error rates) for 80 epochs\n","10.83226,10.72349,10.59485,10.67350\n","Bert\n","max_length->120,180,250,270 (error rates) for 80 epochs\n","8.99459,8.85223,8.92365,9.06225\n","###################\n","\n","\n","Best chosen is Bert,180,720,5e-5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('restaurant')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"2c6862e46755864499758dfbae00ce2d57952673e4a3eab383efcd7ba4035ea3"}}},"nbformat":4,"nbformat_minor":4}
