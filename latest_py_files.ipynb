{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ySSYzn3xfhdt"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MFZ3M50B8Vpp"
      },
      "outputs": [],
      "source": [
        "os.mkdir(\"utils\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta56TM6iNNwr",
        "outputId": "5edde188-42de-4ca3-be3b-969c69ef04b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing utils/randomness.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils/randomness.py\n",
        "import os\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "def set_randomness():\n",
        "  '''\n",
        "  Sets the randomness in the code. But still during training we may have\n",
        "  randomness because we use GPU.\n",
        "\n",
        "  '''\n",
        "  os.environ['PYTHONHASHSEED']=\"0\"\n",
        "  rn.seed(42)\n",
        "  np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC91KUcH6iBe",
        "outputId": "fae3ec2f-2005-4b5f-b73e-565838885e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing EDA.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile EDA.py\n",
        "\"\"\"\n",
        "The EDA and Cleaning the data.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as implt\n",
        "\n",
        "\n",
        "def Visualize(df):\n",
        "  paths=np.random.choice(df['image_path'].values,size=32,replace=False)\n",
        "  plt.subplots(8,4,figsize=(30,30))\n",
        "  for i,path in enumerate(paths):\n",
        "    plt.subplot(8,4,i+1)\n",
        "    img=implt.imread(path)\n",
        "    plt.imshow(img)\n",
        "  plt.savefig\n",
        "  if not os.path.isdir(\"plots\"):\n",
        "    os.mkdir(\"plots\")\n",
        "  plt.savefig(\"plots/random_images.jpg\")\n",
        "  if args.check_sizes:\n",
        "    print(\"checking height distributions\")\n",
        "    df['height']=df['image_path'].apply(lambda x: implt.imread(path).shape[0])\n",
        "    df['width']=df['image_path'].apply(lambda x: implt.imread(path).shape[1])\n",
        "    plt.figure(figsize=(15,10))\n",
        "    plt.hist(df['height'])\n",
        "    plt.title(\"height distributions\")\n",
        "    plt.savefig(\"plots/height_distributions.jpg\")\n",
        "    print(\"checking weigth distributions\")\n",
        "    plt.figure(figsize=(15,10))\n",
        "    plt.hist(df['width'])\n",
        "    plt.title(\"weidth distributions\")\n",
        "    plt.savefig(\"plots/weigth_distributions.jpg\")\n",
        "  \n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  parser=argparse.ArgumentParser(description=\"EDA and cleaning\")\n",
        "  parser.add_argument(\"--data_path\",help=\"path to the data file\", type=pathlib.Path,required = True)\n",
        "  parser.add_argument(\"--check_sizes\",help=\"whether to check the distributions of height and width of images\", \n",
        "                      type=bool)\n",
        "  args=parser.parse_args()\n",
        "  df=pd.read_csv(args.data_path)\n",
        "  df['image_path']=df['image_path']=df['image'].apply(lambda x: \"/content/train_images/\"+x)\n",
        "  if not os.path.isdir(\"processed_data\"):\n",
        "    os.mkdir(\"processed_data\")\n",
        "  df.to_csv(\"processed_data/cleaned_data.csv\",index=False)\n",
        "  Visualize(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xtu741JOB-O",
        "outputId": "829b94ee-1c7a-4660-8998-bcfef85a6165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing create_fold.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile create_fold.py\n",
        "\"\"\"\n",
        "This file creates the group kfold split to the data. \n",
        "And applies label Encoder to the target Feature.\n",
        "\"\"\"\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from utils.randomness import *\n",
        "import argparse\n",
        "import pickle\n",
        "import pathlib\n",
        "\n",
        "def CREATE_FOLD(args):\n",
        "  df=pd.read_csv(args.data_path)\n",
        "  encoder=LabelEncoder()\n",
        "  df['label_group']=encoder.fit_transform(df['label_group'])\n",
        "  print(\"label encoding is done\")\n",
        "  if not os.path.isdir(\"encoders\"):\n",
        "    os.mkdir(\"encoders\")\n",
        "  with open(\"encoders/label_group_encoder.pkl\",\"wb\") as f:\n",
        "    pickle.dump(encoder,f)\n",
        "  df['gfold']=-1\n",
        "  gfold=GroupKFold(n_splits=5)\n",
        "  for i,(train,test) in enumerate(gfold.split(df,groups=df['label_group'])):\n",
        "    df.loc[test,'gfold']=i\n",
        "  print(\"created the group kfold\")\n",
        "  if not os.path.isdir(\"processed_data\"):\n",
        "    os.mkdir(\"processed_data\")\n",
        "    print(\"created processed_data directory\")\n",
        "  df.to_csv(\"processed_data/fold_data.csv\",index=False)\n",
        "  print(\"group kfold data is stored at processed_data/fold_data.csv\")\n",
        "if __name__==\"__main__\":\n",
        "  set_randomness()\n",
        "  parser=argparse.ArgumentParser(description=\"create folds\")\n",
        "  parser.add_argument(\"--data_path\",help=\"path to the data file\", type=pathlib.Path,required = True)\n",
        "  args=parser.parse_args()\n",
        "  CREATE_FOLD(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GxO0rQg93UiF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1\n",
            "1 rescaling\n",
            "2 normalization\n",
            "3 stem_conv_pad\n",
            "4 stem_conv\n",
            "5 stem_bn\n",
            "6 stem_activation\n",
            "7 block1a_dwconv\n",
            "8 block1a_bn\n",
            "9 block1a_activation\n",
            "10 block1a_se_squeeze\n",
            "11 block1a_se_reshape\n",
            "12 block1a_se_reduce\n",
            "13 block1a_se_expand\n",
            "14 block1a_se_excite\n",
            "15 block1a_project_conv\n",
            "16 block1a_project_bn\n",
            "17 block1b_dwconv\n",
            "18 block1b_bn\n",
            "19 block1b_activation\n",
            "20 block1b_se_squeeze\n",
            "21 block1b_se_reshape\n",
            "22 block1b_se_reduce\n",
            "23 block1b_se_expand\n",
            "24 block1b_se_excite\n",
            "25 block1b_project_conv\n",
            "26 block1b_project_bn\n",
            "27 block1b_drop\n",
            "28 block1b_add\n",
            "29 block2a_expand_conv\n",
            "30 block2a_expand_bn\n",
            "31 block2a_expand_activation\n",
            "32 block2a_dwconv_pad\n",
            "33 block2a_dwconv\n",
            "34 block2a_bn\n",
            "35 block2a_activation\n",
            "36 block2a_se_squeeze\n",
            "37 block2a_se_reshape\n",
            "38 block2a_se_reduce\n",
            "39 block2a_se_expand\n",
            "40 block2a_se_excite\n",
            "41 block2a_project_conv\n",
            "42 block2a_project_bn\n",
            "43 block2b_expand_conv\n",
            "44 block2b_expand_bn\n",
            "45 block2b_expand_activation\n",
            "46 block2b_dwconv\n",
            "47 block2b_bn\n",
            "48 block2b_activation\n",
            "49 block2b_se_squeeze\n",
            "50 block2b_se_reshape\n",
            "51 block2b_se_reduce\n",
            "52 block2b_se_expand\n",
            "53 block2b_se_excite\n",
            "54 block2b_project_conv\n",
            "55 block2b_project_bn\n",
            "56 block2b_drop\n",
            "57 block2b_add\n",
            "58 block2c_expand_conv\n",
            "59 block2c_expand_bn\n",
            "60 block2c_expand_activation\n",
            "61 block2c_dwconv\n",
            "62 block2c_bn\n",
            "63 block2c_activation\n",
            "64 block2c_se_squeeze\n",
            "65 block2c_se_reshape\n",
            "66 block2c_se_reduce\n",
            "67 block2c_se_expand\n",
            "68 block2c_se_excite\n",
            "69 block2c_project_conv\n",
            "70 block2c_project_bn\n",
            "71 block2c_drop\n",
            "72 block2c_add\n",
            "73 block3a_expand_conv\n",
            "74 block3a_expand_bn\n",
            "75 block3a_expand_activation\n",
            "76 block3a_dwconv_pad\n",
            "77 block3a_dwconv\n",
            "78 block3a_bn\n",
            "79 block3a_activation\n",
            "80 block3a_se_squeeze\n",
            "81 block3a_se_reshape\n",
            "82 block3a_se_reduce\n",
            "83 block3a_se_expand\n",
            "84 block3a_se_excite\n",
            "85 block3a_project_conv\n",
            "86 block3a_project_bn\n",
            "87 block3b_expand_conv\n",
            "88 block3b_expand_bn\n",
            "89 block3b_expand_activation\n",
            "90 block3b_dwconv\n",
            "91 block3b_bn\n",
            "92 block3b_activation\n",
            "93 block3b_se_squeeze\n",
            "94 block3b_se_reshape\n",
            "95 block3b_se_reduce\n",
            "96 block3b_se_expand\n",
            "97 block3b_se_excite\n",
            "98 block3b_project_conv\n",
            "99 block3b_project_bn\n",
            "100 block3b_drop\n",
            "101 block3b_add\n",
            "102 block3c_expand_conv\n",
            "103 block3c_expand_bn\n",
            "104 block3c_expand_activation\n",
            "105 block3c_dwconv\n",
            "106 block3c_bn\n",
            "107 block3c_activation\n",
            "108 block3c_se_squeeze\n",
            "109 block3c_se_reshape\n",
            "110 block3c_se_reduce\n",
            "111 block3c_se_expand\n",
            "112 block3c_se_excite\n",
            "113 block3c_project_conv\n",
            "114 block3c_project_bn\n",
            "115 block3c_drop\n",
            "116 block3c_add\n",
            "117 block4a_expand_conv\n",
            "118 block4a_expand_bn\n",
            "119 block4a_expand_activation\n",
            "120 block4a_dwconv_pad\n",
            "121 block4a_dwconv\n",
            "122 block4a_bn\n",
            "123 block4a_activation\n",
            "124 block4a_se_squeeze\n",
            "125 block4a_se_reshape\n",
            "126 block4a_se_reduce\n",
            "127 block4a_se_expand\n",
            "128 block4a_se_excite\n",
            "129 block4a_project_conv\n",
            "130 block4a_project_bn\n",
            "131 block4b_expand_conv\n",
            "132 block4b_expand_bn\n",
            "133 block4b_expand_activation\n",
            "134 block4b_dwconv\n",
            "135 block4b_bn\n",
            "136 block4b_activation\n",
            "137 block4b_se_squeeze\n",
            "138 block4b_se_reshape\n",
            "139 block4b_se_reduce\n",
            "140 block4b_se_expand\n",
            "141 block4b_se_excite\n",
            "142 block4b_project_conv\n",
            "143 block4b_project_bn\n",
            "144 block4b_drop\n",
            "145 block4b_add\n",
            "146 block4c_expand_conv\n",
            "147 block4c_expand_bn\n",
            "148 block4c_expand_activation\n",
            "149 block4c_dwconv\n",
            "150 block4c_bn\n",
            "151 block4c_activation\n",
            "152 block4c_se_squeeze\n",
            "153 block4c_se_reshape\n",
            "154 block4c_se_reduce\n",
            "155 block4c_se_expand\n",
            "156 block4c_se_excite\n",
            "157 block4c_project_conv\n",
            "158 block4c_project_bn\n",
            "159 block4c_drop\n",
            "160 block4c_add\n",
            "161 block4d_expand_conv\n",
            "162 block4d_expand_bn\n",
            "163 block4d_expand_activation\n",
            "164 block4d_dwconv\n",
            "165 block4d_bn\n",
            "166 block4d_activation\n",
            "167 block4d_se_squeeze\n",
            "168 block4d_se_reshape\n",
            "169 block4d_se_reduce\n",
            "170 block4d_se_expand\n",
            "171 block4d_se_excite\n",
            "172 block4d_project_conv\n",
            "173 block4d_project_bn\n",
            "174 block4d_drop\n",
            "175 block4d_add\n",
            "176 block5a_expand_conv\n",
            "177 block5a_expand_bn\n",
            "178 block5a_expand_activation\n",
            "179 block5a_dwconv\n",
            "180 block5a_bn\n",
            "181 block5a_activation\n",
            "182 block5a_se_squeeze\n",
            "183 block5a_se_reshape\n",
            "184 block5a_se_reduce\n",
            "185 block5a_se_expand\n",
            "186 block5a_se_excite\n",
            "187 block5a_project_conv\n",
            "188 block5a_project_bn\n",
            "189 block5b_expand_conv\n",
            "190 block5b_expand_bn\n",
            "191 block5b_expand_activation\n",
            "192 block5b_dwconv\n",
            "193 block5b_bn\n",
            "194 block5b_activation\n",
            "195 block5b_se_squeeze\n",
            "196 block5b_se_reshape\n",
            "197 block5b_se_reduce\n",
            "198 block5b_se_expand\n",
            "199 block5b_se_excite\n",
            "200 block5b_project_conv\n",
            "201 block5b_project_bn\n",
            "202 block5b_drop\n",
            "203 block5b_add\n",
            "204 block5c_expand_conv\n",
            "205 block5c_expand_bn\n",
            "206 block5c_expand_activation\n",
            "207 block5c_dwconv\n",
            "208 block5c_bn\n",
            "209 block5c_activation\n",
            "210 block5c_se_squeeze\n",
            "211 block5c_se_reshape\n",
            "212 block5c_se_reduce\n",
            "213 block5c_se_expand\n",
            "214 block5c_se_excite\n",
            "215 block5c_project_conv\n",
            "216 block5c_project_bn\n",
            "217 block5c_drop\n",
            "218 block5c_add\n",
            "219 block5d_expand_conv\n",
            "220 block5d_expand_bn\n",
            "221 block5d_expand_activation\n",
            "222 block5d_dwconv\n",
            "223 block5d_bn\n",
            "224 block5d_activation\n",
            "225 block5d_se_squeeze\n",
            "226 block5d_se_reshape\n",
            "227 block5d_se_reduce\n",
            "228 block5d_se_expand\n",
            "229 block5d_se_excite\n",
            "230 block5d_project_conv\n",
            "231 block5d_project_bn\n",
            "232 block5d_drop\n",
            "233 block5d_add\n",
            "234 block6a_expand_conv\n",
            "235 block6a_expand_bn\n",
            "236 block6a_expand_activation\n",
            "237 block6a_dwconv_pad\n",
            "238 block6a_dwconv\n",
            "239 block6a_bn\n",
            "240 block6a_activation\n",
            "241 block6a_se_squeeze\n",
            "242 block6a_se_reshape\n",
            "243 block6a_se_reduce\n",
            "244 block6a_se_expand\n",
            "245 block6a_se_excite\n",
            "246 block6a_project_conv\n",
            "247 block6a_project_bn\n",
            "248 block6b_expand_conv\n",
            "249 block6b_expand_bn\n",
            "250 block6b_expand_activation\n",
            "251 block6b_dwconv\n",
            "252 block6b_bn\n",
            "253 block6b_activation\n",
            "254 block6b_se_squeeze\n",
            "255 block6b_se_reshape\n",
            "256 block6b_se_reduce\n",
            "257 block6b_se_expand\n",
            "258 block6b_se_excite\n",
            "259 block6b_project_conv\n",
            "260 block6b_project_bn\n",
            "261 block6b_drop\n",
            "262 block6b_add\n",
            "263 block6c_expand_conv\n",
            "264 block6c_expand_bn\n",
            "265 block6c_expand_activation\n",
            "266 block6c_dwconv\n",
            "267 block6c_bn\n",
            "268 block6c_activation\n",
            "269 block6c_se_squeeze\n",
            "270 block6c_se_reshape\n",
            "271 block6c_se_reduce\n",
            "272 block6c_se_expand\n",
            "273 block6c_se_excite\n",
            "274 block6c_project_conv\n",
            "275 block6c_project_bn\n",
            "276 block6c_drop\n",
            "277 block6c_add\n",
            "278 block6d_expand_conv\n",
            "279 block6d_expand_bn\n",
            "280 block6d_expand_activation\n",
            "281 block6d_dwconv\n",
            "282 block6d_bn\n",
            "283 block6d_activation\n",
            "284 block6d_se_squeeze\n",
            "285 block6d_se_reshape\n",
            "286 block6d_se_reduce\n",
            "287 block6d_se_expand\n",
            "288 block6d_se_excite\n",
            "289 block6d_project_conv\n",
            "290 block6d_project_bn\n",
            "291 block6d_drop\n",
            "292 block6d_add\n",
            "293 block6e_expand_conv\n",
            "294 block6e_expand_bn\n",
            "295 block6e_expand_activation\n",
            "296 block6e_dwconv\n",
            "297 block6e_bn\n",
            "298 block6e_activation\n",
            "299 block6e_se_squeeze\n",
            "300 block6e_se_reshape\n",
            "301 block6e_se_reduce\n",
            "302 block6e_se_expand\n",
            "303 block6e_se_excite\n",
            "304 block6e_project_conv\n",
            "305 block6e_project_bn\n",
            "306 block6e_drop\n",
            "307 block6e_add\n",
            "308 block7a_expand_conv\n",
            "309 block7a_expand_bn\n",
            "310 block7a_expand_activation\n",
            "311 block7a_dwconv\n",
            "312 block7a_bn\n",
            "313 block7a_activation\n",
            "314 block7a_se_squeeze\n",
            "315 block7a_se_reshape\n",
            "316 block7a_se_reduce\n",
            "317 block7a_se_expand\n",
            "318 block7a_se_excite\n",
            "319 block7a_project_conv\n",
            "320 block7a_project_bn\n",
            "321 block7b_expand_conv\n",
            "322 block7b_expand_bn\n",
            "323 block7b_expand_activation\n",
            "324 block7b_dwconv\n",
            "325 block7b_bn\n",
            "326 block7b_activation\n",
            "327 block7b_se_squeeze\n",
            "328 block7b_se_reshape\n",
            "329 block7b_se_reduce\n",
            "330 block7b_se_expand\n",
            "331 block7b_se_excite\n",
            "332 block7b_project_conv\n",
            "333 block7b_project_bn\n",
            "334 block7b_drop\n",
            "335 block7b_add\n",
            "336 top_conv\n",
            "337 top_bn\n",
            "338 top_activation\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "pre_trained_model=EfficientNetB1(include_top=False,input_shape=(512,512,3))\n",
        "for i,layer in enumerate(pre_trained_model.layers):\n",
        "  print(i,layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVbxb8Oz0ZkY",
        "outputId": "128ffea2-153c-458e-f46c-240971a46912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing params.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile params.yaml\n",
        "data:\n",
        " initial_file: \"train.csv\"\n",
        "model_type: \"image\"\n",
        "image:\n",
        " image_size: (512,512)\n",
        " unfreeze: 324\n",
        " pre_trained_name: \"EfficientNetB4\"\n",
        "text:\n",
        "  max_length: 512\n",
        "  pre_trained_name: \"bert-base-uncased\"\n",
        "scheduler: \"one_cycle\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4LzLxSFPRg1",
        "outputId": "e40d4f06-da43-4e52-9dda-356ca204b3ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting dvc.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile dvc.yaml\n",
        "vars:\n",
        "- params.yaml\n",
        "stages:\n",
        " eda:\n",
        "  cmd: python EDA.py --data_path ${data.initial_file} --check_sizes True\n",
        "  params:\n",
        "  - ${data.initial_file}\n",
        "  deps:\n",
        "  - EDA.py\n",
        "  outs:\n",
        "  - processed_data/cleaned_data.csv\n",
        "  plots:\n",
        "  - plots/weigth_distributions.jpg:\n",
        "      cache: false\n",
        "  - plots/height_distributions.jpg:\n",
        "      cache: false\n",
        "  - plots/random_images.jpg:\n",
        "      cache: false\n",
        " Folds:\n",
        "  cmd: python create_fold.py --data_path \"processed_data/cleaned_data.csv\"\n",
        "  deps:\n",
        "  - create_fold.py\n",
        "  - processed_data/cleaned_data.csv\n",
        "  outs:\n",
        "  - encoders/label_group_encoder.pkl\n",
        "  - processed_data/fold_data.csv\n",
        " training:\n",
        "  cmd: >\n",
        "  python training.py --data_path processed_data/fold_data.csv --model_type ${model_type} \\\n",
        "  --batch_size 32 --save_model_path \"models_dir/image_test\" --epochs 30 --lr_callback ${scheduler}\n",
        "  deps:\n",
        "  - training.py\n",
        "  - processed_data/fold_data.csv\n",
        "  - utils/models/py\n",
        "  - utils/dataloaders/py\n",
        "  outs:\n",
        "  - \"models_dir/image_test-0.h5\"\n",
        "  - \"models_dir/image_test-1.h5\"\n",
        "  - \"models_dir/image_test-2.h5\"\n",
        "  - \"models_dir/image_test-3.h5\"\n",
        "  - \"models_dir/image_test-4.h5\"\n",
        "  params:\n",
        "  - ${scheduler}\n",
        "  - ${model_type}\n",
        "  - ${image.unfreeze}\n",
        "  - ${image.pretrained_name}\n",
        "  - ${text.pretrained_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65kOUYDM1Hza",
        "outputId": "6dabe5c8-cd53-4e43-b121-bc322b4ded23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing params.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile params.py\n",
        "\n",
        "import yaml\n",
        "with open(\"params.yaml\") as f:\n",
        "  HYPERPARAMETERS=yaml.safe_load(f)\n",
        "\n",
        "HYPERPARAMETERS['image']['image_size']=tuple(int(x) for x in HYPERPARAMETERS['image']['image_size'][1:-1].split(\",\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8a7DNQTgBmu",
        "outputId": "709f3a16-43aa-4fef-8ba5-6ad4a94d6f28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing utils/models.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils/models.py\n",
        "\"\"\"\n",
        "Below we have models for image, text and combined models and arcface layer\n",
        "\n",
        "\"\"\"\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense,Input,Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from transformers import TFBertModel,TFRobertaModel,TFAlbertModel,TFXLNetModel\n",
        "\n",
        "\n",
        "class ARCFACE_LAYER(Layer):\n",
        "  def __init__(self,m=0.5,s=60,n_classes=11014):\n",
        "    super(ARCFACE_LAYER,self).__init__()\n",
        "    self.m=m\n",
        "    self.s=s\n",
        "    self.sin_m=tf.sin(m)\n",
        "    self.cos_m=tf.cos(m)\n",
        "    self.n_classes=n_classes\n",
        "    self.threshold = tf.cos(math.pi - m)\n",
        "    self.mm = tf.math.sin(math.pi - m) * m\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    prev_layer_units=input_shape[0][1]\n",
        "    self.w=self.add_weight(shape=(prev_layer_units,self.n_classes),trainable=True)\n",
        "\n",
        "  def get_config(self):\n",
        "    config=super().get_config()\n",
        "    config.update({\"m\":0.5,\n",
        "                   \"s\":60,\n",
        "                   \"n_classes\":11014})\n",
        "    return config\n",
        "\n",
        "\n",
        "  def call(self,inputs):\n",
        "    prev_layer,y=inputs\n",
        "    y=tf.cast(y,dtype=tf.int32)\n",
        "    y_hot=tf.one_hot(y,self.n_classes)\n",
        "    y_hot=tf.cast(y_hot,dtype=tf.float32)\n",
        "    w_norm=tf.linalg.l2_normalize(self.w,axis=0)\n",
        "    x_norm=tf.linalg.l2_normalize(prev_layer,axis=1)\n",
        "    cos_theta=tf.linalg.matmul(x_norm,w_norm)\n",
        "    cos_theta=tf.keras.backend.clip(cos_theta,-1+1e-5,1-1e-5)\n",
        "    sin_theta=tf.sqrt(1-tf.pow(cos_theta,tf.cast(2,dtype=tf.float32)))\n",
        "    cos_theta_m=(cos_theta*self.cos_m)-(sin_theta*self.sin_m)\n",
        "    cos_theta_m=tf.where(cos_theta_m>self.cos_m,cos_theta_m,cos_theta-self.mm)\n",
        "    final=self.s*((y_hot*cos_theta_m)+((1-y_hot)*cos_theta))\n",
        "    return final\n",
        "  \n",
        "\n",
        "\n",
        "def IMAGE_MODEL(image_size,unfreeze_layers_number):\n",
        "  tf.keras.backend.clear_session()\n",
        "  pre_trained=EfficientNetB4(include_top=False,weights=\"imagenet\",input_shape=(image_size[0],image_size[1],3))\n",
        "  ins=Input((),name=\"label_input\")\n",
        "  for i,layer in enumerate(pre_trained.layers):\n",
        "    if i>=unfreeze_layers_number:\n",
        "      if not layer.name.endswith(\"bn\"):\n",
        "        pre_trained.layers[i].trainable=True\n",
        "      else:\n",
        "        pre_trained.layers[i].trainable=False\n",
        "    else:\n",
        "      pre_trained.layers[i].trainable=False\n",
        "  x=pre_trained.layers[-1].output\n",
        "  x=tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "  x=Dense(512)(x)\n",
        "  arc_layer=ARCFACE_LAYER()\n",
        "  x=arc_layer([x,ins])\n",
        "  outs=tf.keras.layers.Softmax()(x)\n",
        "  model=Model(inputs=(pre_trained.input,ins),outputs=outs)\n",
        "  return model\n",
        "\n",
        "def TEXT_MODEL(pre_trained_name,max_length):\n",
        "  tf.keras.backend.clear_session()\n",
        "  input_ids=Input((max_length,),dtype=tf.int32)\n",
        "  attention_mask=Input((max_length,),dtype=tf.int32)\n",
        "  token_type_ids=Input((max_length,),dtype=tf.int32)\n",
        "  ins=Input((),name=\"label_input\")\n",
        "  pre_trained=TFBertModel.from_pretrained(pre_trained_name,output_hidden_states=True)\n",
        "  pre_outputs=pre_trained({\"input_ids\":input_ids,\"attention_mask\":attention_mask,\n",
        "                  \"token_type_ids\":token_type_ids})\n",
        "  hidden_layers=[]\n",
        "  for i in range(4):\n",
        "    hidden_layers.append(pre_outputs['hidden_states'][-i])\n",
        "  x=tf.keras.layers.Concatenate()(hidden_layers)[:,0,:]\n",
        "  x=Dense(512)(x)\n",
        "  arc_layer=ARCFACE_LAYER()\n",
        "  x=arc_layer([x,ins])\n",
        "  outs=tf.keras.layers.Softmax()(x)\n",
        "  model=Model(inputs=({\"input_ids\":input_ids,\"attention_mask\":attention_mask,\n",
        "                 \"token_type_ids\":token_type_ids},ins),outputs=outs)\n",
        "  return model\n",
        "\n",
        "def COMBINE_MODEL(max_length,image_size,unfreeze_layers_number):\n",
        "  tf.keras.backend.clear_session()\n",
        "  input_ids=Input((max_length,),dtype=tf.int32)\n",
        "  attention_mask=Input((max_length,),dtype=tf.int32)\n",
        "  token_type_ids=Input((max_length,),dtype=tf.int32)\n",
        "  ins=Input((),name=\"label_input\")\n",
        "  text_trained=TFBertModel.from_pretrained(\"bert-base-uncased\",output_hidden_states=True)\n",
        "  text_outputs=text_trained({\"input_ids\":input_ids,\"attention_mask\":attention_mask,\n",
        "                  \"token_type_ids\":token_type_ids})\n",
        "  hidden_layers=[]\n",
        "  for i in range(4):\n",
        "    hidden_layers.append(text_outputs['hidden_states'][-i])\n",
        "  x1=tf.keras.layers.Concatenate()(hidden_layers)[:,0,:]\n",
        "  ################\n",
        "  img_trained=DenseNet201(include_top=False,weights=\"imagenet\",input_shape=(image_size[0],image_size[1],3))\n",
        "  for i,layer in enumerate(img_trained.layers):\n",
        "    if i>=unfreeze_layers_number:\n",
        "      if not layer.name.endswith(\"bn\"):\n",
        "        img_trained.layers[i].trainable=True\n",
        "      else:\n",
        "        img_trained.layers[i].trainable=False\n",
        "    else:\n",
        "      img_trained.layers[i].trainable=False\n",
        "  x2=img_trained.layers[-1].output\n",
        "  x2=tf.keras.layers.GlobalMaxPooling2D()(x2)\n",
        "  ################\n",
        "  x=tf.keras.layers.Concatenate()([x1,x2])\n",
        "  x=Dense(512)(x)\n",
        "  arc_layer=ARCFACE_LAYER()\n",
        "  x=arc_layer([x,ins])\n",
        "  outs=tf.keras.layers.Softmax()(x)\n",
        "  model=Model(inputs=({\"input_ids\":input_ids,\"attention_mask\":attention_mask,\n",
        "                 \"token_type_ids\":token_type_ids},\n",
        "                 img_trained.input,ins),outputs=outs)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QACOI4yDDYZ0",
        "outputId": "6968c1e4-894e-4d91-d1d3-8cdc967bf6cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing utils/dataloaders.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils/dataloaders.py\n",
        "\"\"\"\n",
        "Data loaders for the models\n",
        "\n",
        "\"\"\"\n",
        "import albumentations as A\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "class IMG_DATA_LOADER(tf.keras.utils.Sequence):\n",
        "  def __init__(self,dataframe,image_size,batch_size,aug,shuffle,inference=False):\n",
        "    self.data=dataframe\n",
        "    self.batch_size=batch_size\n",
        "    self.shuffle=shuffle\n",
        "    self.image_size=image_size\n",
        "    self.aug=aug\n",
        "    self.inference=inference\n",
        "    self.n=0\n",
        "    self.max_=self.__len__()\n",
        "    self.indexes=np.arange(self.data.shape[0])\n",
        "    self.temp_indexes=np.arange(self.data.shape[0])\n",
        "    if not self.inference:\n",
        "      self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.ceil(self.data.shape[0]/self.batch_size))\n",
        "  \n",
        "  def on_epoch_end(self):\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.temp_indexes)\n",
        "  \n",
        "  def next(self):\n",
        "    if self.n>self.max_:\n",
        "      self.n=0\n",
        "      result=self.__getitem__(self.n)\n",
        "      self.n+=1\n",
        "    else:\n",
        "      result=self.__getitem__(self.n)\n",
        "      self.n+=1\n",
        "    return result\n",
        "  \n",
        "  def Augment_images(self,image):\n",
        "    transformer=A.Compose([A.Rotate(limit=30,p=0.8),\n",
        "          A.HorizontalFlip(),\n",
        "          #A.CoarseDropout(max_height=0.25,max_width=0.25,),\n",
        "          A.ShiftScaleRotate(shift_limit=0.09,scale_limit=0.2,rotate_limit=0),\n",
        "          A.RandomBrightnessContrast()\n",
        "          ])\n",
        "    image=transformer(image=image)['image']\n",
        "    return image\n",
        "\n",
        "  def __getitem__(self,batch):\n",
        "    curr_temp_indexes=self.temp_indexes[batch*self.batch_size:(batch+1)*self.batch_size]\n",
        "    curr_batch=list(self.indexes[i] for i in curr_temp_indexes)\n",
        "    IMAGES=np.zeros((len(curr_batch),self.image_size[0],self.image_size[1],3))\n",
        "    if not self.inference:\n",
        "      Y=np.zeros((len(curr_batch),))      \n",
        "    for i,idx in enumerate(curr_batch):\n",
        "      img_name=self.data.iloc[idx]['image_path']\n",
        "      labels=self.data.iloc[idx]['label_group']\n",
        "      img=tf.keras.preprocessing.image.load_img(img_name,target_size=self.image_size)\n",
        "      img=tf.keras.preprocessing.image.img_to_array(img)/255.0\n",
        "      if self.aug:\n",
        "        img=self.Augment_images(img)\n",
        "      IMAGES[i,]=img\n",
        "      if not self.inference:\n",
        "        Y[i,]=labels\n",
        "    if not self.inference:\n",
        "      return (IMAGES,Y),Y\n",
        "    else:\n",
        "      return IMAGES\n",
        "\n",
        "\n",
        "class TEXT_DATA_LOADER(tf.keras.utils.Sequence):\n",
        "  def __init__(self,dataframe,max_length,pre_trained_name,batch_size,shuffle,inference=False):\n",
        "    self.data=dataframe\n",
        "    self.batch_size=batch_size\n",
        "    self.shuffle=shuffle\n",
        "    self.max_length=max_length\n",
        "    self.pre_trained_name=pre_trained_name\n",
        "    self.inference=inference\n",
        "    self.tokenizer=BertTokenizer.from_pretrained(self.pre_trained_name)\n",
        "    self.n=0\n",
        "    self.max_=self.__len__()\n",
        "    self.indexes=np.arange(self.data.shape[0])\n",
        "    self.temp_indexes=np.arange(self.data.shape[0])\n",
        "    if not self.inference:\n",
        "      self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.ceil(self.data.shape[0]/self.batch_size))\n",
        "  \n",
        "  def on_epoch_end(self):\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.temp_indexes)\n",
        "  \n",
        "  def next(self):\n",
        "    if self.n>self.max_:\n",
        "      self.n=0\n",
        "      result=self.__getitem__(self.n)\n",
        "      self.n+=1\n",
        "    else:\n",
        "      result=self.__getitem__(self.n)\n",
        "      self.n+=1\n",
        "    return result\n",
        "  \n",
        "  def __getitem__(self,batch):\n",
        "    curr_temp_indexes=self.temp_indexes[batch*self.batch_size:(batch+1)*self.batch_size]\n",
        "    curr_batch=list(self.indexes[i] for i in curr_temp_indexes)\n",
        "    INPUT_IDS=np.zeros((len(curr_batch),self.max_length),dtype=np.int32)\n",
        "    ATTENTION_MASK=np.zeros((len(curr_batch),self.max_length),dtype=np.int32)\n",
        "    TOKEN_TYPE_IDS=np.zeros((len(curr_batch),self.max_length),dtype=np.int32)\n",
        "    if not self.inference:\n",
        "      Y=np.zeros((len(curr_batch),))\n",
        "    for i,idx in enumerate(curr_batch):\n",
        "      title=self.data.iloc[idx]['title']\n",
        "      labels=self.data.iloc[idx]['label_group']\n",
        "      tokenized_title=self.tokenizer.encode_plus(title,padding=\"max_length\",\n",
        "                                                truncation=\"longest_first\",max_length=self.max_length)\n",
        "      \n",
        "      INPUT_IDS[i,]=tokenized_title['input_ids']\n",
        "      ATTENTION_MASK[i,]=tokenized_title['attention_mask']\n",
        "      TOKEN_TYPE_IDS[i,]=tokenized_title['token_type_ids']\n",
        "      if not self.inference:\n",
        "        Y[i,]=labels\n",
        "    if not self.inference:\n",
        "      return ({\"input_ids\":INPUT_IDS,\"attention_mask\":ATTENTION_MASK,\n",
        "              \"token_type_ids\": TOKEN_TYPE_IDS},Y),Y\n",
        "    else:\n",
        "      return {\"input_ids\":INPUT_IDS,\"attention_mask\":ATTENTION_MASK,\n",
        "              \"token_type_ids\": TOKEN_TYPE_IDS}\n",
        "\n",
        "class BOTH_DATA_LOADER(tf.keras.utils.Sequence):\n",
        "  def __init__(self,dataframe,image_size,batch_size,max_length,text_pre_trained_name,aug,shuffle,inference=False):\n",
        "    self.data=dataframe\n",
        "    self.batch_size=batch_size\n",
        "    self.shuffle=shuffle\n",
        "    self.inference=inference\n",
        "    self.image_size=image_size\n",
        "    self.aug=aug\n",
        "    self.max_length=max_length\n",
        "    self.pre_trained_name=text_pre_trained_name\n",
        "    self.tokenizer=BertTokenizer.from_pretrained(self.pre_trained_name)\n",
        "    self.n=0\n",
        "    self.max_=self.__len__()\n",
        "    self.indexes=np.arange(self.data.shape[0])\n",
        "    self.temp_indexes=np.arange(self.data.shape[0])\n",
        "    if not self.inference:\n",
        "      self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.ceil(self.data.shape[0]/self.batch_size))\n",
        "  \n",
        "  def on_epoch_end(self):\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.temp_indexes)\n",
        "  \n",
        "  def next(self):\n",
        "    if self.n>self.max_:\n",
        "      self.n=0\n",
        "      result=self.__getitem__(self.n)\n",
        "      self.n+=1\n",
        "    else:\n",
        "      result=self.__getitem__(self.n)\n",
        "      self.n+=1\n",
        "    return result\n",
        "  \n",
        "  def Augment_images(self,image):\n",
        "    transformer=A.Compose([A.Rotate(limit=30,p=0.8),\n",
        "          A.HorizontalFlip(),\n",
        "          #A.CoarseDropout(max_height=0.25,max_width=0.25,),\n",
        "          A.ShiftScaleRotate(shift_limit=0.09,scale_limit=0.2,rotate_limit=0),\n",
        "          A.RandomBrightnessContrast()\n",
        "          ])\n",
        "    image=transformer(image=image)['image']\n",
        "    return image\n",
        "\n",
        "  def __getitem__(self,batch):\n",
        "    curr_temp_indexes=self.temp_indexes[batch*self.batch_size:(batch+1)*self.batch_size]\n",
        "    curr_batch=list(self.indexes[i] for i in curr_temp_indexes)\n",
        "    IMAGES=np.zeros((len(curr_batch),self.image_size[0],self.image_size[1],3))\n",
        "    INPUT_IDS=np.zeros((len(curr_batch),self.max_length),dtype=np.int32)\n",
        "    ATTENTION_MASK=np.zeros((len(curr_batch),self.max_length),dtype=np.int32)\n",
        "    TOKEN_TYPE_IDS=np.zeros((len(curr_batch),self.max_length),dtype=np.int32)\n",
        "    if not self.inference:\n",
        "      Y=np.zeros((len(curr_batch),))\n",
        "    for i,idx in enumerate(curr_batch):\n",
        "      img_name=self.data.iloc[idx]['image_path']\n",
        "      labels=self.data.iloc[idx]['label_group']\n",
        "      img=tf.keras.preprocessing.image.load_img(img_name,target_size=self.image_size)\n",
        "      img=tf.keras.preprocessing.image.img_to_array(img)/255.0\n",
        "      if self.aug:\n",
        "        img=self.Augment_images(img)\n",
        "      IMAGES[i,]=img\n",
        "      #############################\n",
        "      title=self.data.iloc[idx]['title']\n",
        "      tokenized_title=self.tokenizer.encode_plus(title,padding=\"max_length\",\n",
        "                                                truncation=\"longest_first\",max_length=self.max_length)\n",
        "      \n",
        "      INPUT_IDS[i,]=tokenized_title['input_ids']\n",
        "      ATTENTION_MASK[i,]=tokenized_title['attention_mask']\n",
        "      TOKEN_TYPE_IDS[i,]=tokenized_title['token_type_ids']\n",
        "      if not self.inference:\n",
        "        Y[i,]=labels\n",
        "    if not self.inference:\n",
        "      return ({\"input_ids\":INPUT_IDS,\"attention_mask\":ATTENTION_MASK,\n",
        "            \"token_type_ids\": TOKEN_TYPE_IDS},IMAGES,Y),Y\n",
        "    else:\n",
        "      return ({\"input_ids\":INPUT_IDS,\"attention_mask\":ATTENTION_MASK,\n",
        "            \"token_type_ids\": TOKEN_TYPE_IDS},IMAGES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwwCAuA3T-C9",
        "outputId": "fc571f87-5c70-464f-fc00-7929195a812d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing training.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile training.py\n",
        "\"\"\"\n",
        "It is the training function for different types of models\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from utils.models import *\n",
        "from utils.randomness import *\n",
        "from utils.dataloaders import *\n",
        "from params import HYPERPARAMETERS\n",
        "\n",
        "\n",
        "def CE(y_true,y_pred):\n",
        "  '''\n",
        "  loss function = y*log(y_hat)\n",
        "  '''\n",
        "  y_true=tf.cast(y_true,dtype=tf.int32)\n",
        "  y_true=tf.one_hot(y_true,depth=11014)\n",
        "  y_true=tf.cast(y_true,dtype=y_pred.dtype)\n",
        "  ce_loss=y_true*tf.keras.backend.log(y_pred+1e-5)\n",
        "  batch_loss=tf.reduce_sum(ce_loss,axis=-1)\n",
        "  return -1*tf.reduce_mean(batch_loss)\n",
        "\n",
        "def one_cycle(epoch,lr_min=1e-5,lr_max=2e-4):\n",
        "  if epoch<5:\n",
        "    lr=(lr_max-lr_min)/5 *(epoch) + lr_min\n",
        "  elif epoch==5:\n",
        "    lr=lr_max\n",
        "  else:\n",
        "    lr= (lr_max-lr_min) * 0.8**(epoch-5) +lr_min\n",
        "  return lr\n",
        "\n",
        "def TRAINING(args):\n",
        "  df=pd.read_csv(args.data_path)\n",
        "  for fold in range(5):\n",
        "    train_data=df.loc[df['gfold']!=fold].drop(\"gfold\",axis=1).reset_index(drop=True)\n",
        "    test_data=df.loc[df['gfold']==fold].drop(\"gfold\",axis=1).reset_index(drop=True)\n",
        "\n",
        "    if args.model_type==\"image\":\n",
        "      model=IMAGE_MODEL(image_size=HYPERPARAMETERS[\"image\"][\"image_size\"],unfreeze_layers_number=HYPERPARAMETERS[\"image\"]['unfreeze'])\n",
        "      train_dataloader=IMG_DATA_LOADER(dataframe=train_data,image_size=HYPERPARAMETERS[\"image\"]['image_size'],\n",
        "                                       batch_size=args.batch_size,aug=True,shuffle=True)\n",
        "      test_dataloader=IMG_DATA_LOADER(dataframe=test_data,image_size=HYPERPARAMETERS[\"image\"]['image_size'],\n",
        "                                      batch_size=args.batch_size,aug=False,shuffle=False)\n",
        "\n",
        "    elif args.model_type==\"text\":\n",
        "      model=TEXT_MODEL(pre_trained_name=HYPERPARAMETERS[\"text\"][\"pre_trained_name\"],max_length=HYPERPARAMETERS[\"text\"][\"max_length\"])\n",
        "      train_dataloader=TEXT_DATA_LOADER(dataframe=train_data,max_length=HYPERPARAMETERS[\"text\"][\"max_length\"],\n",
        "                                        pre_trained_name=HYPERPARAMETERS[\"text\"][\"pre_trained_name\"],batch_size=args.batch_size,shuffle=True)\n",
        "      test_dataloader=TEXT_DATA_LOADER(dataframe=test_data,max_length=HYPERPARAMETERS[\"text\"][\"max_length\"],\n",
        "                                       pre_trained_name=HYPERPARAMETERS[\"text\"][\"pre_trained_name\"],batch_size=args.batch_size,shuffle=False)\n",
        "\n",
        "    else:\n",
        "      model=COMBINE_MODEL(max_length=HYPERPARAMETERS[\"text\"][\"max_length\"],image_size=HYPERPARAMETERS[\"image\"][\"image_size\"],\n",
        "                          unfreeze_layers_number=HYPERPARAMETERS[\"image\"]['unfreeze'])\n",
        "      train_dataloader=BOTH_DATA_LOADER(dataframe=train_data,batch_size=args.batch_size,\n",
        "                                        image_size=HYPERPARAMETERS[\"image\"]['image_size'],\n",
        "                                        max_length=HYPERPARAMETERS[\"text\"][\"max_length\"],\n",
        "                                        text_pre_trained_name=HYPERPARAMETERS[\"text\"][\"pre_trained_name\"],aug=True,shuffle=True)\n",
        "      test_dataloader=BOTH_DATA_LOADER(dataframe=test_data,batch_size=args.batch_size,\n",
        "                                       image_size=HYPERPARAMETERS[\"image\"]['image_size'],\n",
        "                                       max_length=HYPERPARAMETERS[\"text\"][\"max_length\"],\n",
        "                                       text_pre_trained_name=HYPERPARAMETERS[\"text\"][\"pre_trained_name\"],aug=False,shuffle=False)\n",
        "      \n",
        "    model.compile(\"Adam\",loss=CE)\n",
        "    up_down=tf.keras.callbacks.LearningRateScheduler(lambda epoch: one_cycle(epoch),verbose=1)\n",
        "    reduce_plat=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",mode=\"min\",\n",
        "                                                    patience=5,verbose=1,cooldown=2,\n",
        "                                                    min_lr=1e-6)\n",
        "    early=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",mode=\"min\",verbose=1)\n",
        "    saver=tf.keras.callbacks.ModelCheckpoint(filepath=args.save_model_path+f\"{fold}.h5\",\n",
        "                                             monitor=\"val_loss\",mode=\"min\",save_best_only=True,\n",
        "                                             save_weights_only=True)\n",
        "    if fold==0:\n",
        "      print(model.summary())\n",
        "    model.fit(train_dataloader,validation_data=test_dataloader,epochs=args.epochs,\n",
        "              callbacks=[early,saver,up_down] if args.lr_callback==\"one_cycle\" \\\n",
        "                         else [early,saver,reduce_plat] if args.lr_callback==\"reduce_lr_plateau\" \\\n",
        "              else [early,saver]\n",
        "              )\n",
        "    \n",
        "    print(f\"model training for {fold} is done\")\n",
        "    del model\n",
        "    import gc\n",
        "    gc.collect()\n",
        "  \n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  parser=argparse.ArgumentParser(description=\"training the models\")\n",
        "  parser.add_argument(\"--data_path\",help=\"path to the data file\", type=pathlib.Path,required = True)\n",
        "  parser.add_argument(\"--model_type\",help=\"type of model\", choices=[\"image\",\"text\",\"both\"],type=str,required = True)\n",
        "  parser.add_argument(\"--batch_size\",help=\"batch size for the model\", type=int, default=32,required = True)\n",
        "  parser.add_argument(\"--save_model_path\",help=\"model path along with name where to save it\", type=str,required = True)\n",
        "  parser.add_argument(\"--epochs\",help=\"number of epochs\", type=int,default=30,required = True)\n",
        "  parser.add_argument(\"--lr_callback\",help=\"type of lr scheduler\", choices=[\"one_cycle\",\"reduce_lr_plateau\",\"None\"],\n",
        "                      required=True,type=str)\n",
        "  args=parser.parse_args()\n",
        "  set_randomness()\n",
        "  TRAINING(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AS-K5MB78fO",
        "outputId": "a82e06a2-bc97-4427-beea-427f6113ba6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n"
          ]
        }
      ],
      "source": [
        "!git init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0_3z3tPgANh",
        "outputId": "09d0f73c-19f4-4dab-a883-3cfa6370beb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing .gitignore\n"
          ]
        }
      ],
      "source": [
        "%%writefile .gitignore\n",
        "train_images/\n",
        "test_images/\n",
        "sample_data/\n",
        "sample_submission.csv\n",
        "shopee-product-matching.zip\n",
        "*.csv\n",
        ".config/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6ovwnU1Kfd3U"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "warning: LF will be replaced by CRLF in latest_py_files.ipynb.\n",
            "The file will have its original line endings in your working directory\n"
          ]
        }
      ],
      "source": [
        "!git add ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6IZQYGIgasy",
        "outputId": "0c54833c-a15d-41c0-f2e0-74ef2dc7bf85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "\n",
            "No commits yet\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git rm --cached <file>...\" to unstage)\n",
            "\tnew file:   .gitignore\n",
            "\tnew file:   EDA.py\n",
            "\tnew file:   create_fold.py\n",
            "\tnew file:   dvc.yaml\n",
            "\tnew file:   latest_py_files.ipynb\n",
            "\tnew file:   params.py\n",
            "\tnew file:   params.yaml\n",
            "\tnew file:   training.py\n",
            "\tnew file:   utils/dataloaders.py\n",
            "\tnew file:   utils/models.py\n",
            "\tnew file:   utils/randomness.py\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dk1ipkc8fd3U"
      },
      "outputs": [],
      "source": [
        "!git config --global user.name \"RavitejaBadugu\"\n",
        "!git config --global user.email \"ravi14ashwin@gmail.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGXF5QFXfd3U",
        "outputId": "5dfc09d4-c1f7-4dae-b674-47376b053027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[main (root-commit) de0b264] initial files\n",
            " 11 files changed, 1732 insertions(+)\n",
            " create mode 100644 .gitignore\n",
            " create mode 100644 EDA.py\n",
            " create mode 100644 create_fold.py\n",
            " create mode 100644 dvc.yaml\n",
            " create mode 100644 latest_py_files.ipynb\n",
            " create mode 100644 params.py\n",
            " create mode 100644 params.yaml\n",
            " create mode 100644 training.py\n",
            " create mode 100644 utils/dataloaders.py\n",
            " create mode 100644 utils/models.py\n",
            " create mode 100644 utils/randomness.py\n"
          ]
        }
      ],
      "source": [
        "!git commit -m \"initial files\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kbzMFVtnfd3V"
      },
      "outputs": [],
      "source": [
        "!git branch -M main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD1seU5efd3V",
        "outputId": "25d243f5-fcab-4e87-e15b-bed527bbb1cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "error: remote origin already exists.\n"
          ]
        }
      ],
      "source": [
        "!git remote add origin git@github.com:RavitejaBadugu/shop_duplicate.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J1AqqxJfd3V",
        "outputId": "9f9f7b46-0ae7-428b-e597-d7673076ce34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "To https://github.com/RavitejaBadugu/shop_duplicate.git\n",
            " * [new branch]      main -> main\n"
          ]
        }
      ],
      "source": [
        "!git push -u origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRVC7q5tfd3V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "latest-py-files.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f1270e6ce26af4109576f957535bad1f64509504c6d98ff147f498f2d893c152"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('qa-labelling')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
